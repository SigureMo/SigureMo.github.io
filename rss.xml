<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>时雨梦之零</title><description>一个小透明的透明世界</description><link>https://nyakku.moe/</link><language>zh_CN</language><item><title>Python 3.11 核心加速原理——指令特化</title><link>https://nyakku.moe/posts/python311-instruction-specializing/</link><guid isPermaLink="true">https://nyakku.moe/posts/python311-instruction-specializing/</guid><pubDate>Sun, 27 Aug 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;近期在做一些 Python 3.11 的适配工作，结果 Python 3.11 的改动实在是太多了，针对一个一个问题解决并不利于理解 Python 3.11 改动的本质，因此这里稍微花了点时间来调研和整理 Python 3.11 的核心变化。&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;Faster CPython——不断加速的 CPython&lt;/h2&gt;
&lt;p&gt;自从几年前 &lt;a href=&quot;https://github.com/faster-cpython&quot;&gt;Faster CPython&lt;/a&gt; 发起以来，CPython 的开发者们一直致力于提升 CPython 的性能，而 Python 3.11 则是 Faster CPython 的一个里程碑，在 &lt;a href=&quot;https://github.com/python/pyperformance&quot;&gt;pyperformance&lt;/a&gt; benchmark 上平均比 Python 3.10 快 25%。&lt;/p&gt;
&lt;p&gt;从 &lt;a href=&quot;https://docs.python.org/3/whatsnew/3.11.html#faster-cpython&quot;&gt;Python 3.11 Release Notes - Faster CPython&lt;/a&gt; 一节中我们能找到 Python 3.11 中主要的加速点，Release Notes 中将其分为「启动加速」和「运行时加速」两部分。&lt;/p&gt;
&lt;p&gt;「启动加速」主要就是将核心模块进行「frozen」，我们可以通过分别打印 Python 3.10 和 Python 3.11 的部分核心模块来对比：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import os

print(os)
# Output in Python 3.10
# &amp;lt;module &apos;os&apos; from &apos;/path/to/os.py&apos;&amp;gt;

# Output in Python 3.11
# &amp;lt;module &apos;os&apos; (frozen)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 Python 3.11 的 &lt;code&gt;os&lt;/code&gt; 模块已经是 frozen 的了。&lt;/p&gt;
&lt;p&gt;关于「运行时加速」，主要包含如下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;更加轻量和 Lazy 的 frame&lt;/strong&gt;。简单来说就是 Python 3.11 的 frame 是更加精简的数据结构，其中去掉了调试信息和异常堆栈，因为在大多数情况下这些信息是没有必要的，如果需要原来的 FrameObject 则可以 lazy 地创建，而&lt;a href=&quot;https://devguide.python.org/internals/interpreter/#exception-table-format&quot;&gt;异常信息&lt;/a&gt;则是在编译时通过分析生成了（CodeObject 的 &lt;code&gt;co_exceptiontable&lt;/code&gt;），运行时则是近乎零成本（只需要在发生异常时查表，而不需要维护异常堆栈）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Inline 函数调用&lt;/strong&gt;。在 Python 3.11 之前，每发生一次 Python 函数调用的同时也会创建一个 C 函数调用，这导致了 Python 函数调用会消耗 C 的调用栈。而在 Python 3.11 中，在发生 Python 函数调用时，在创建一个新的 Frame 后，会「跳转」到解释器的开始，而不是创建一个新的 C 函数调用。这里的「跳转」在代码实现中就是一个 &lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Python/ceval.c#L4764&quot;&gt;goto&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特化的自适应解释器&lt;/strong&gt;（&lt;a href=&quot;https://peps.python.org/pep-0659/&quot;&gt;PEP 659: Specializing Adaptive Interpreter&lt;/a&gt;），从标题就可以看出，这是本文要描述的重点，那么我们接下来逐渐展开吧～&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;指令特化&lt;/h2&gt;
&lt;p&gt;特化是一种常见的 JIT 加速手段，对于动态语言而言，每一条看似简单的指令都可能对应着多种不同的实现，比如一个简简单单的 &lt;code&gt;+&lt;/code&gt;（&lt;code&gt;BINARY_ADD&lt;/code&gt;，在 Python 3.11 则是 &lt;code&gt;BINARY_OP +&lt;/code&gt;），对于不同的类型，其实现是完全不同的，可能是 &lt;code&gt;int&lt;/code&gt; 加，可能是 &lt;code&gt;float&lt;/code&gt; 加，甚至可能执行用户自定义的 &lt;code&gt;__add__&lt;/code&gt;，而判断具体执行什么的过程则带来了不小的运行时开销。&lt;/p&gt;
&lt;p&gt;虽然动态语言的查找是不可避免的，但是对于大多数字节码来说，其往往只对应了一种具体实现，比如 &lt;code&gt;a.b + c&lt;/code&gt;，假如 &lt;code&gt;a.b&lt;/code&gt; 和 &lt;code&gt;c&lt;/code&gt; 都为 &lt;code&gt;int&lt;/code&gt;，那么其实大概率其类型是不会变的，这被称为「类型稳定性」。虽然我们不能保证之后 &lt;code&gt;a.b&lt;/code&gt; 和 &lt;code&gt;c&lt;/code&gt; 类型不会变，但我们可以根据这个信息来决策之后优先选择 &lt;code&gt;int&lt;/code&gt; 加这一实现，这便是特化的思想。&lt;/p&gt;
&lt;p&gt;Python 3.11 在解释器中引入了特化的思想，不过值得注意的是其是在字节码层面进行的，而没有编译成机器码，因此并不是 JIT（见 &lt;a href=&quot;https://docs.python.org/3/whatsnew/3.11.html#is-there-a-jit-compiler&quot;&gt;Is there a JIT compiler?&lt;/a&gt;），但毫无疑问这借鉴了 JIT 的思想。&lt;/p&gt;
&lt;h2&gt;额外信息的存储——Inline Cache&lt;/h2&gt;
&lt;p&gt;特化需要运行时的统计信息，Python 3.11 将这些信息存储在字节码中，即为 Inline Cache。与 Python 3.10 不同，Python 3.11 的字节码序列中为特化指令预留了 Inline Cache 的位置，比如 &lt;code&gt;BINARY_OP&lt;/code&gt; 除去操作码和操作数 2 bytes 以外，还包含 2 bytes 的 Inline Cache，我们可以通过如下实验来验证：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import dis


def foo(a, b):
    return a + b


dis.dis(foo)

# Output in Python 3.10
#   5           0 LOAD_FAST                0 (a)
#               2 LOAD_FAST                1 (b)
#               4 BINARY_ADD
#               6 RETURN_VALUE

# Output in Python 3.11
#   4           0 RESUME                   0
#
#   5           2 LOAD_FAST                0 (a)
#               4 LOAD_FAST                1 (b)
#               6 BINARY_OP                0 (+)
#              10 RETURN_VALUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到 Python 3.10 每个字节码都占据 2 bytes，而 Python 3.11 中 &lt;code&gt;BINARY_OP&lt;/code&gt; 则占据了 4 bytes，这其中就包含了 2 bytes 的 Inline Cache。&lt;/p&gt;
&lt;p&gt;Python 3.11 全部的特化指令如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Include/internal/pycore_opcode.h#L41-L53
const uint8_t _PyOpcode_Caches[256] = {
    [BINARY_SUBSCR] = 4,
    [STORE_SUBSCR] = 1,
    [UNPACK_SEQUENCE] = 1,
    [STORE_ATTR] = 4,
    [LOAD_ATTR] = 4,
    [COMPARE_OP] = 2,
    [LOAD_GLOBAL] = 5,
    [BINARY_OP] = 1,
    [LOAD_METHOD] = 10,
    [PRECALL] = 1,
    [CALL] = 4,
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然其实这里展示的是 CPython 各个指令的 Inline Cache 长度，Inline Cache 以 &lt;code&gt;_Py_CODEUNIT&lt;/code&gt; 为基本单元，&lt;code&gt;_Py_CODEUNIT&lt;/code&gt; 的大小则是 2 bytes，因此 &lt;code&gt;BINARY_OP&lt;/code&gt; 对应的 1 即代表其 Inline Cache 大小为 2 bytes。再以 &lt;code&gt;LOAD_ATTR&lt;/code&gt; 为例的话，其 Inline Cache 大小为 4*2=8 bytes，加上其本身共 10 bytes。&lt;/p&gt;
&lt;p&gt;关于 Inline Cache 的数据结构我们也可以在 &lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Include/internal/pycore_code.h&quot;&gt;cpython 3.11 pycore_code.h&lt;/a&gt; 中找到，这里同样以 &lt;code&gt;LOAD_ATTR&lt;/code&gt; 为例：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Include/internal/pycore_code.h#L55-L61
typedef struct {
    _Py_CODEUNIT counter;
    _Py_CODEUNIT version[2];
    _Py_CODEUNIT index;
} _PyAttrCache;

#define INLINE_CACHE_ENTRIES_LOAD_ATTR CACHE_ENTRIES(_PyAttrCache)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;可以看到它的 4 个 &lt;code&gt;_Py_CODEUNIT&lt;/code&gt; 分别为 &lt;code&gt;counter&lt;/code&gt;、&lt;code&gt;version[2]&lt;/code&gt;、&lt;code&gt;index&lt;/code&gt;，这里第一个字段固定表示计数器，对于所有特化指令是一致的，其它字段则视具体指令而定。&lt;/p&gt;
&lt;p&gt;从字节码布局来看是这样的：&lt;/p&gt;
&lt;p&gt;&amp;lt;div class=&quot;img-center&quot;&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/python311-instruction-specializing/inline-cache.drawio.png&quot; alt=&quot;Inline Cache&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;
&lt;p&gt;在编译结束阶段，CPython 会在 Inline Cache 的位置填充 0：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Python/compile.c#L205-L231
static void
write_instr(_Py_CODEUNIT *codestr, struct instr *instruction, int ilen)
{
    // ...
    while (caches--) {
        *codestr++ = _Py_MAKECODEUNIT(CACHE, 0);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中&lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Include/opcode.h#L11&quot;&gt;字节码 &lt;code&gt;CACHE&lt;/code&gt;&lt;/a&gt; 对应的值也是 0，因此每个 &lt;code&gt;_Py_CODEUNIT&lt;/code&gt; 相当于填充了 2 bytes 的 0。&lt;/p&gt;
&lt;p&gt;因此在编译结束后的字节码其实看起来是这样子的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  4           0 RESUME                   0

  5           2 LOAD_FAST                0 (self)
              4 LOAD_ATTR                0 (a)
              6     (CACHE)              0
              8     (CACHE)              0
             10     (CACHE)              0
             12     (CACHE)              0
             14 RETURN_VALUE
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里 &lt;code&gt;LOAD_ATTR&lt;/code&gt; 后紧紧跟随了独属于它的 4 个 Inline Cache，这些 Cache 会在运行时被填充。&lt;/p&gt;
&lt;h2&gt;字节码族——特化与自适应&lt;/h2&gt;
&lt;p&gt;为了实现特化，Python 3.11 在运行时会根据 Inline Cache 的信息来原位替换原有的字节码，不过替换的字节码必须是同一「族」（family）的。比如对于编译期产生的原始 &lt;code&gt;LOAD_ATTR&lt;/code&gt;，该族包含如下几条指令：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始指令：&lt;code&gt;LOAD_ATTR&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;自适应指令：&lt;code&gt;LOAD_ATTR_ADAPTIVE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;特化指令：
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LOAD_ATTR_INSTANCE_VALUE&lt;/code&gt;：一种常见的情况，其中属性存储在对象的值数组中，并且不被覆盖描述符遮蔽&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOAD_ATTR_MODULE&lt;/code&gt;：从模块 load 属性&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LOAD_ATTR_SLOT&lt;/code&gt;：从 &lt;code&gt;__slots__&lt;/code&gt; 加载属性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;原始指令到自适应指令的转换&lt;/h3&gt;
&lt;p&gt;原始指令 &lt;code&gt;LOAD_ATTR&lt;/code&gt; 仍然执行原来一样的操作，因此只执行原始指令是没有加速效果的，为了加速，Python 3.11 首先会将其替换成自适应指令 &lt;code&gt;LOAD_ATTR_ADAPTIVE&lt;/code&gt;，这一步是在运行时 &lt;code&gt;RESUME&lt;/code&gt; 指令做的，这也是 Python 3.11 函数第一条指令总是 &lt;code&gt;RESUME&lt;/code&gt; 的原因&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Python/ceval.c#L1776-L1779
        TARGET(RESUME) {
            _PyCode_Warmup(frame-&amp;gt;f_code);
            JUMP_TO_INSTRUCTION(RESUME_QUICK);
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;RESUME&lt;/code&gt; 指令会调用 &lt;code&gt;_PyCode_Warmup&lt;/code&gt; 增加 warmup 计数器 &lt;code&gt;co_warmup&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Include/internal/pycore_code.h#L95-L111
#define QUICKENING_WARMUP_DELAY 8

/* We want to compare to zero for efficiency, so we offset values accordingly */
#define QUICKENING_INITIAL_WARMUP_VALUE (-QUICKENING_WARMUP_DELAY)

void _PyCode_Quicken(PyCodeObject *code);

static inline void
_PyCode_Warmup(PyCodeObject *code)
{
    if (code-&amp;gt;co_warmup != 0) {
        code-&amp;gt;co_warmup++;
        if (code-&amp;gt;co_warmup == 0) {
            _PyCode_Quicken(code);
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里 &lt;code&gt;co_warmup&lt;/code&gt; 初始值为 &lt;code&gt;QUICKENING_INITIAL_WARMUP_VALUE&lt;/code&gt; 即 &lt;code&gt;-8&lt;/code&gt;，也就是说在经过 8 次 &lt;code&gt;RESUME&lt;/code&gt; 之后，&lt;code&gt;co_warmup&lt;/code&gt; 会变为 0，这时候就会调用 &lt;code&gt;_PyCode_Quicken&lt;/code&gt; 来进行加速。（这里只是简化说明，实际上不止 &lt;code&gt;RESUME&lt;/code&gt; 会调用 &lt;code&gt;_PyCode_Warmup&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Python/specialize.c#L258-L319
// Insert adaptive instructions and superinstructions. This cannot fail.
void
_PyCode_Quicken(PyCodeObject *code)
{
    _Py_QuickenedCount++;
    int previous_opcode = -1;
    _Py_CODEUNIT *instructions = _PyCode_CODE(code);
    for (int i = 0; i &amp;lt; Py_SIZE(code); i++) {
        int opcode = _Py_OPCODE(instructions[i]);
        uint8_t adaptive_opcode = _PyOpcode_Adaptive[opcode];
        if (adaptive_opcode) {
            _Py_SET_OPCODE(instructions[i], adaptive_opcode);
            // Make sure the adaptive counter is zero:
            assert(instructions[i + 1] == 0);
            previous_opcode = -1;
            i += _PyOpcode_Caches[opcode];
        }
        else {
            assert(!_PyOpcode_Caches[opcode]);
            switch (opcode) {
                case EXTENDED_ARG:
                    _Py_SET_OPCODE(instructions[i], EXTENDED_ARG_QUICK);
                    break;
                case JUMP_BACKWARD:
                    _Py_SET_OPCODE(instructions[i], JUMP_BACKWARD_QUICK);
                    break;
                case RESUME:
                    _Py_SET_OPCODE(instructions[i], RESUME_QUICK);
                    break;
                case LOAD_FAST:
                    switch(previous_opcode) {
                        case LOAD_FAST:
                            _Py_SET_OPCODE(instructions[i - 1],
                                           LOAD_FAST__LOAD_FAST);
                            break;
                        case STORE_FAST:
                            _Py_SET_OPCODE(instructions[i - 1],
                                           STORE_FAST__LOAD_FAST);
                            break;
                        case LOAD_CONST:
                            _Py_SET_OPCODE(instructions[i - 1],
                                           LOAD_CONST__LOAD_FAST);
                            break;
                    }
                    break;
                case STORE_FAST:
                    if (previous_opcode == STORE_FAST) {
                        _Py_SET_OPCODE(instructions[i - 1],
                                       STORE_FAST__STORE_FAST);
                    }
                    break;
                case LOAD_CONST:
                    if (previous_opcode == LOAD_FAST) {
                        _Py_SET_OPCODE(instructions[i - 1],
                                       LOAD_FAST__LOAD_CONST);
                    }
                    break;
            }
            previous_opcode = opcode;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里算是一个小的「pass」，遍历全部字节码进行了替换：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果该指令是可特化的，则将该指令替换为自适应版本，比如 &lt;code&gt;LOAD_ATTR&lt;/code&gt; 将会被原位替换为 &lt;code&gt;LOAD_ATTR_ADAPTIVE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果该指令是 &lt;code&gt;EXTENDED_ARG&lt;/code&gt;、&lt;code&gt;JUMP_BACKWARD&lt;/code&gt;、&lt;code&gt;RESUME&lt;/code&gt; 之一，则将其转为相应的 quick 版本，比如 &lt;code&gt;RESUME&lt;/code&gt; 将会被原位替换为 &lt;code&gt;RESUME_QUICK&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果该指令和下一条指令可以 combine 在一起，则这两条指令 combine 成一条超指令（super instruction），比如 &lt;code&gt;LOAD_FAST&lt;/code&gt; + &lt;code&gt;LOAD_FAST&lt;/code&gt; 将会被原位替换为 &lt;code&gt;LOAD_FAST__LOAD_FAST&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;之后解释器再解释执行的就是自适应指令了。&lt;/p&gt;
&lt;h3&gt;自适应指令&lt;/h3&gt;
&lt;p&gt;仍然以 &lt;code&gt;LOAD_ATTR&lt;/code&gt; 为例，其自适应指令 &lt;code&gt;LOAD_ATTR_ADAPTIVE&lt;/code&gt; 的实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        TARGET(LOAD_ATTR_ADAPTIVE) {
            assert(cframe.use_tracing == 0);
            _PyAttrCache *cache = (_PyAttrCache *)next_instr;
            if (ADAPTIVE_COUNTER_IS_ZERO(cache)) {
                PyObject *owner = TOP();
                PyObject *name = GETITEM(names, oparg);
                next_instr--;
                if (_Py_Specialize_LoadAttr(owner, next_instr, name) &amp;lt; 0) {
                    next_instr++;
                    goto error;
                }
                DISPATCH_SAME_OPARG();
            }
            else {
                STAT_INC(LOAD_ATTR, deferred);
                DECREMENT_ADAPTIVE_COUNTER(cache);
                JUMP_TO_INSTRUCTION(LOAD_ATTR);
            }
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里两个分支分别表示&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果自适应计数器减到 0，则尝试调用 &lt;code&gt;_Py_Specialize_LoadAttr&lt;/code&gt; 进行特化&lt;/li&gt;
&lt;li&gt;否则自适应计数器减 1（计数器字段 - 1，而不是整个数值 - 1），然后跳转到原始指令 &lt;code&gt;LOAD_ATTR&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自适应计数器字段与原始状态和特化状态并不相同，它的 16 bit 被分割成了两部分，其中高 12 bit 才是计数器（counter），低 4 bit 为回退指数（backoff exponent）。计数器总是会被初始化为 $2^{backoff} - 1$，比如回退指数为 0 时，计数器初始值为 0，回退指数为 3 时，计数器初始值为 7，以此类推。（详见 &lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Include/internal/pycore_code.h#L488-L529&quot;&gt;cpython 3.11 pycore_code.h&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;下面我们看看 &lt;code&gt;_Py_Specialize_LoadAttr&lt;/code&gt; 中实际发生了什么：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Python/specialize.c#L655-L755
int
_Py_Specialize_LoadAttr(PyObject *owner, _Py_CODEUNIT *instr, PyObject *name)
{
    assert(_PyOpcode_Caches[LOAD_ATTR] == INLINE_CACHE_ENTRIES_LOAD_ATTR);
    _PyAttrCache *cache = (_PyAttrCache *)(instr + 1);
    if (PyModule_CheckExact(owner)) {
        // LOAD_ATTR_MODULE 特化尝试
        int err = specialize_module_load_attr(owner, instr, name, LOAD_ATTR,
                                              LOAD_ATTR_MODULE);
        if (err) {
            goto fail;
        }
        goto success;
    }
    PyTypeObject *type = Py_TYPE(owner);
    if (type-&amp;gt;tp_dict == NULL) {
        if (PyType_Ready(type) &amp;lt; 0) {
            return -1;
        }
    }
    PyObject *descr;
    DescriptorClassification kind = analyze_descriptor(type, name, &amp;amp;descr, 0);
    switch(kind) {
        case OVERRIDING:
            SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_ATTR_OVERRIDING_DESCRIPTOR);
            goto fail;
        case METHOD:
            SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_ATTR_METHOD);
            goto fail;
        case PROPERTY:
            SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_ATTR_PROPERTY);
            goto fail;
        case OBJECT_SLOT:
        {
            PyMemberDescrObject *member = (PyMemberDescrObject *)descr;
            struct PyMemberDef *dmem = member-&amp;gt;d_member;
            Py_ssize_t offset = dmem-&amp;gt;offset;
            if (!PyObject_TypeCheck(owner, member-&amp;gt;d_common.d_type)) {
                SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_EXPECTED_ERROR);
                goto fail;
            }
            if (dmem-&amp;gt;flags &amp;amp; PY_AUDIT_READ) {
                SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_ATTR_AUDITED_SLOT);
                goto fail;
            }
            if (offset != (uint16_t)offset) {
                SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_OUT_OF_RANGE);
                goto fail;
            }
            assert(dmem-&amp;gt;type == T_OBJECT_EX);
            assert(offset &amp;gt; 0);
            cache-&amp;gt;index = (uint16_t)offset;
            write_u32(cache-&amp;gt;version, type-&amp;gt;tp_version_tag);
            // 特化 LOAD_ATTR 为 LOAD_ATTR_SLOT
            _Py_SET_OPCODE(*instr, LOAD_ATTR_SLOT);
            goto success;
        }
        case DUNDER_CLASS:
        {
            Py_ssize_t offset = offsetof(PyObject, ob_type);
            assert(offset == (uint16_t)offset);
            cache-&amp;gt;index = (uint16_t)offset;
            write_u32(cache-&amp;gt;version, type-&amp;gt;tp_version_tag);
            // 特化 LOAD_ATTR 为 LOAD_ATTR_SLOT
            _Py_SET_OPCODE(*instr, LOAD_ATTR_SLOT);
            goto success;
        }
        case OTHER_SLOT:
            SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_ATTR_NON_OBJECT_SLOT);
            goto fail;
        case MUTABLE:
            SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_ATTR_MUTABLE_CLASS);
            goto fail;
        case GETSET_OVERRIDDEN:
            SPECIALIZATION_FAIL(LOAD_ATTR, SPEC_FAIL_OVERRIDDEN);
            goto fail;
        case BUILTIN_CLASSMETHOD:
        case PYTHON_CLASSMETHOD:
        case NON_OVERRIDING:
        case NON_DESCRIPTOR:
        case ABSENT:
            break;
    }
    // LOAD_ATTR_INSTANCE_VALUE 特化尝试
    int err = specialize_dict_access(
        owner, instr, type, kind, name,
        LOAD_ATTR, LOAD_ATTR_INSTANCE_VALUE, LOAD_ATTR_WITH_HINT
    );
    if (err &amp;lt; 0) {
        return -1;
    }
    if (err) {
        goto success;
    }
fail:
    STAT_INC(LOAD_ATTR, failure);
    assert(!PyErr_Occurred());
    cache-&amp;gt;counter = adaptive_counter_backoff(cache-&amp;gt;counter);    // backoff + 1，根据 backoff 重设 counter
    return 0;
success:
    STAT_INC(LOAD_ATTR, success);
    assert(!PyErr_Occurred());
    cache-&amp;gt;counter = miss_counter_start();                        // 特化成功，设置特化计数器初始值（53）
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里有几处 &lt;code&gt;_Py_SET_OPCODE&lt;/code&gt; 即是特化成功时将当前指令替换为特化指令的逻辑。我们注意一下 &lt;code&gt;fail&lt;/code&gt; 和 &lt;code&gt;success&lt;/code&gt;，即特化失败和特化成功的返回逻辑：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果发生特化失败，则会将 &lt;code&gt;backoff&lt;/code&gt; + 1，并根据其设置计数器的初始值，显然失败次数越多，计数器初始值越大，就越不容易触发特化，从而有效避免了频繁触发特化失败。&lt;/li&gt;
&lt;li&gt;如果特化成功，此时指令已经被替换成相应的特化指令，此时会将计数器设置为特化计数器初始值 &lt;code&gt;53&lt;/code&gt;，该值来源见 &lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Python/specialize.c#L321-L332&quot;&gt;cpython 3.11 specialize.c - miss_counter_start&lt;/a&gt;（简单说就是 cpython 团队发现 50 左右是一个合适的值，就在 50 左右找了一个合适的质数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意从 &lt;code&gt;RESUME&lt;/code&gt; warmup 得来的计数器本就是 0，因此自适应指令最开始就会尝试特化，而没有额外的 warmup 过程。而从特化指令发生去优化（de-optimization）退化为自适应指令时，则会设置一个适中的初始值 31（$2^5 - 1$，见 &lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Include/internal/pycore_code.h#L514-L518&quot;&gt;cpython 3.11 pycore_code.h - adaptive_counter_start&lt;/a&gt;），以免频繁发生去优化。&lt;/p&gt;
&lt;h3&gt;特化指令的执行逻辑&lt;/h3&gt;
&lt;p&gt;这里以 &lt;code&gt;LOAD_ATTR_INSTANCE_VALUE&lt;/code&gt; 为例看一下特化指令的执行逻辑：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// https://github.com/python/cpython/blob/3.11/Python/ceval.c#L1489
#define DEOPT_IF(cond, instname) if (cond) { goto miss; }

// https://github.com/python/cpython/blob/3.11/Python/ceval.c#L3496-L3517
        TARGET(LOAD_ATTR_INSTANCE_VALUE) {
            assert(cframe.use_tracing == 0);
            PyObject *owner = TOP();
            PyObject *res;
            PyTypeObject *tp = Py_TYPE(owner);
            _PyAttrCache *cache = (_PyAttrCache *)next_instr;
            uint32_t type_version = read_u32(cache-&amp;gt;version);
            assert(type_version != 0);
            DEOPT_IF(tp-&amp;gt;tp_version_tag != type_version, LOAD_ATTR);
            assert(tp-&amp;gt;tp_dictoffset &amp;lt; 0);
            assert(tp-&amp;gt;tp_flags &amp;amp; Py_TPFLAGS_MANAGED_DICT);
            PyDictValues *values = *_PyObject_ValuesPointer(owner);
            DEOPT_IF(values == NULL, LOAD_ATTR);
            res = values-&amp;gt;values[cache-&amp;gt;index];
            DEOPT_IF(res == NULL, LOAD_ATTR);
            STAT_INC(LOAD_ATTR, hit);
            Py_INCREF(res);
            SET_TOP(res);
            Py_DECREF(owner);
            JUMPBY(INLINE_CACHE_ENTRIES_LOAD_ATTR);
            DISPATCH();
        }

// https://github.com/python/cpython/blob/3.11/Python/ceval.c#L5701-L5720
/* Specialization misses */
miss:
    {
        STAT_INC(opcode, miss);
        opcode = _PyOpcode_Deopt[opcode];
        STAT_INC(opcode, miss);
        /* The counter is always the first cache entry: */
        _Py_CODEUNIT *counter = (_Py_CODEUNIT *)next_instr;
        *counter -= 1;
        if (*counter == 0) {
            int adaptive_opcode = _PyOpcode_Adaptive[opcode];
            assert(adaptive_opcode);
            _Py_SET_OPCODE(next_instr[-1], adaptive_opcode);
            STAT_INC(opcode, deopt);
            *counter = adaptive_counter_start();
        }
        next_instr--;
        DISPATCH_GOTO();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里出现了几次 &lt;code&gt;DEOPT_IF&lt;/code&gt;，即去优化逻辑，如果并不满足当前特化逻辑时，将会将计数器 - 1，并执行原始指令。当计数器减到 0 时，会将当前指令替换为自适应指令，并重置计数器为初始值（即上面提到的 31）。&lt;/p&gt;
&lt;h3&gt;指令特化流程回顾&lt;/h3&gt;
&lt;p&gt;至此，整个「原始指令」→「自适应指令」↔「特化指令」的转换关系基本清晰了～现在我们总结回顾下～&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/python311-instruction-specializing/specializing-overview.drawio.png&quot; alt=&quot;Inline Cache&quot; /&gt;&lt;/p&gt;
&lt;p&gt;值得注意的是，其中的虚线表示字节码层面不变，只是逻辑上 fallback 到原始指令 / 自适应指令，而实线则是代表字节码发生了原位替换，即图中的「warmup」、「specializing」、「de-optimization」&lt;/p&gt;
&lt;h2&gt;Faster CPython 的未来&lt;/h2&gt;
&lt;p&gt;PEP 659 为 Faster CPython 做了一个良好的开端，它让我们看到了 CPython 在利用非 JIT 的方式在运行时获得更多的加速，Faster CPython 目前也在做着更多的改进：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更多的指令特化，Python 3.12 已经&lt;a href=&quot;https://github.com/faster-cpython/ideas/blob/main/3.12/interpreter_definition.md&quot;&gt;实现了一个 DSL&lt;/a&gt;，用来方便实现解释器逻辑（&lt;code&gt;ceval.c&lt;/code&gt;），新的解释器逻辑使用 DSL 写在了 &lt;a href=&quot;https://github.com/python/cpython/blob/3.12/Python/bytecodes.c&quot;&gt;bytecodes.c&lt;/a&gt;，之后会根据其编译成 &lt;a href=&quot;https://github.com/python/cpython/blob/3.12/Python/generated_cases.c.h&quot;&gt;generated_cases.c.h&lt;/a&gt;（就是原来 &lt;code&gt;ceval.c&lt;/code&gt; 里的非常大的 switch-case），可以更加方便地编写指令特化、去优化、超指令等逻辑&lt;/li&gt;
&lt;li&gt;第二层优化器（&lt;a href=&quot;https://github.com/faster-cpython/ideas/blob/main/3.12/tier2.md&quot;&gt;Tier 2 Optimizer for CPython -- Early design&lt;/a&gt;），该提案基于第一层优化器，即本文所述的 PEP 659，本文所述的优化器仅仅会针对单条指令，而 Tier 2 Optimizer 则会考虑更大的优化范围，将会为未来构建 JIT 提供坚实的基础&lt;/li&gt;
&lt;li&gt;等等……（其他的我暂时还不清楚）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么暂时先这样啦，以后有什么新的有趣的优化再整理～一些关于 Python 3.11 其他改动的适配文档已经在之前整理在了 &lt;a href=&quot;https://github.com/PaddlePaddle/PaddleSOT/tree/develop/docs/compat/python311&quot;&gt;PaddleSOT/docs/compat/python311&lt;/a&gt;，有兴趣也可以参考下～&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://peps.python.org/pep-0659/&quot;&gt;PEP 659 – Specializing Adaptive Interpreter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/python/cpython/tree/3.11&quot;&gt;CPython 3.11 Source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/faster-cpython/ideas&quot;&gt;Faster CPython Ideas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://devguide.python.org/internals/interpreter/#&quot;&gt;The Bytecode Interpreter (3.11)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/python/cpython/blob/3.11/Python/adaptive.md&quot;&gt;Adding or extending a family of adaptive instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=MipEJ3XzZjU&quot;&gt;How we are making Python 3.11 faster (CPython project)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>哇，好复杂的 TorchDynamo，我们拆开看看吧～</title><link>https://nyakku.moe/posts/decomposing-torch-dynamo/</link><guid isPermaLink="true">https://nyakku.moe/posts/decomposing-torch-dynamo/</guid><pubDate>Sat, 22 Apr 2023 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip
最近这一周负责调研 TorchDynamo，唔，也是很久没写博客了嘛，所以就浅记录下，顺便梳理下 Dynamo 中的各个流程和部分细节～&lt;/p&gt;
&lt;p&gt;注意本文最初的动机是调研，因此内容排布上可能对新手不是很友好。因为一直没时间整理优化，暂时先这样了。
:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;什么是 TorchDynamo&lt;/h2&gt;
&lt;p&gt;TorchDynamo 是一个 Python JIT 编译器，可以提高 PyTorch 代码的运行速度。那，它是怎么做到的呢？&lt;/p&gt;
&lt;h3&gt;TorchDynamo 总览&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/decomposing-torch-dynamo/dynamo-overview.png&quot; alt=&quot;TorchDynamo Overview&quot; /&gt;&lt;/p&gt;
&lt;p&gt;这里本想自己画一个流程图的，不过最后发现 Torch 文档里的这张图本身已经足够说明 TorchDynamo 的工作流程了，所以这里就直接用啦～&lt;/p&gt;
&lt;p&gt;对于一个 Python 函数来说，默认当然就是直接用 Python 解释器来执行了，或者更严谨一点来说会将此时的 Frame 会交给 Python 解释器来 Eval。而 &lt;a href=&quot;https://peps.python.org/pep-0523/&quot;&gt;PEP 523&lt;/a&gt; 为我们提供了一个修改 Python 解释器 Eval Frame 行为的方法，让我们能够可以自己来解释执行 Frame。TorchDynamo 便是基于此原理来实现的。&lt;/p&gt;
&lt;p&gt;对于同样一个 Python 函数，TorchDynamo 会在 Eval Frame 时通过编译将原始的 Frame 转换成一个新的 Frame，两者主要差异在于字节码上，这个新的 Frame 同样会交给 Python 解释器来执行，也就是说 TorchDynamo 的主要工作是在 Eval Frame 初期的字节码变换过程。&lt;/p&gt;
&lt;p&gt;图中我们会看到有一个 Guards，它是用来保护 Cache 中直接获取的 CodeObject 的，对于同一个函数的 CodeObject，并不是说编译一次对于之后所有的输入都是可用的，因为 TorchDynamo 的编译过程强依赖于输入类型和值等信息，因此第一次编译后的 CodeObject 可能对于第二次输入是不适用的，Guard 便是用来检查此项的，当 Guard 检查失败时，就会触发重新编译。&lt;/p&gt;
&lt;h3&gt;TorchDynamo 编译过程&lt;/h3&gt;
&lt;p&gt;TorchDynamo 在编译过程中会逐字节码进行模拟执行，相当于实现了一个简版的 Python 解释器，在这个过程中会收集所有栈上变量的信息，以及其相关的操作，这也是为什么图中会写「dynamic bytecode analysis」，区别于静态分析，TorchDynamo 可以从 Frame 的 &lt;code&gt;f_locals&lt;/code&gt; 字段里找到函数的输入，进而将整个函数运行过程模拟出来。&lt;/p&gt;
&lt;p&gt;在模拟执行的过程中，如果 TorchDynamo 遇到了 Tensor，就会创建一个 FX Proxy，开始 FX Graph 组网过程，即开始 trace。&lt;/p&gt;
&lt;p&gt;在模拟执行结束时，首先会从 FX Graph 生成 Python 函数，并将其挂载到 globals 里。之后在生成的字节码里先将这个函数 LOAD 到栈里，然后将所有输入也 LOAD 到栈上，之后 CALL 这个函数。当然，仅仅凭借如此是无法把全部操作都还原的，对于一些 Python 的 SideEffects，还需要在最后生成相关代码来处理。&lt;/p&gt;
&lt;p&gt;这里真正起到加速作用的是 FX Graph，FX Graph 是可以交给各种后端进行编译加速的，比如默认的 TorchInductor 会将 FX Graph 编译到 Triton（GPU）或 C++/OpenMP（CPU）。&lt;/p&gt;
&lt;h2&gt;Eval Frame 原理和执行流程&lt;/h2&gt;
&lt;h3&gt;FrameObject 和 CodeObject&lt;/h3&gt;
&lt;p&gt;CodeObject 是指 Python 经过编译后产生的代码对象，它主要包含了 Python 字节码及其相关信息，比如常量表、变量名表等。&lt;/p&gt;
&lt;p&gt;FrameObject 是指在函数运行时的栈帧，包含编译时产生的 CodeObject 以及一些运行时的参数信息等。&lt;/p&gt;
&lt;p&gt;简单来说，CodeObject 是一个编译时的产物，而 FrameObject 时一个运行时的概念，同一个函数多次运行会产生多个 FrameObject，而其对应的 CodeObject 是同一个。&lt;/p&gt;
&lt;h3&gt;PEP 523&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://peps.python.org/pep-0523/&quot;&gt;PEP 523&lt;/a&gt; 的标题是 Adding a frame evaluation API to CPython，即为 CPython 添加一个用来 Eval Frame 的 API。这个提案为 JIT 编译提供了可能，允许 JIT 编译器在 Eval Frame 时执行自己的一些操作，比如重新编译原有 CodeObject 生成新的 CodeObject 等。&lt;/p&gt;
&lt;p&gt;因此该提案在 &lt;code&gt;PyInterpreterState&lt;/code&gt; 上增加了一个 &lt;code&gt;eval_frame&lt;/code&gt; 字段，即在 Eval Frame 时会调用的函数。其默认值即是直接调用 Python 解释器默认行为 &lt;code&gt;_PyEval_EvalFrameDefault&lt;/code&gt; 函数。而我们可以通过修改它来实现 Eval Frame 行为的自定义，&lt;/p&gt;
&lt;p&gt;此外，该提案还在 CodeObject 上添加了一个 &lt;code&gt;co_extra&lt;/code&gt; 字段，以便 JIT 编译器在编译时将一些额外的信息存储在 CodeObject 中，比如编译后的 CodeObject 等。&lt;/p&gt;
&lt;h3&gt;Eval Frame 流程&lt;/h3&gt;
&lt;p&gt;原理基本都介绍完啦，下面说一下 TorchDynamo 在 Eval Frame 时发生的具体过程。&lt;/p&gt;
&lt;p&gt;对于使用 &lt;code&gt;torch.compile&lt;/code&gt; 装饰的函数 &lt;code&gt;fn&lt;/code&gt;，torch 会生成一个 &lt;code&gt;callback&lt;/code&gt;，用于编译 Frame 生成新的 CodeObject，同时这个函数会被装饰成如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@functools.wraps(fn)
def _fn(*args, **kwargs):
   prior = set_eval_frame(callback)
   try:
      return fn(*args, **kwargs)
   finally:
      set_eval_frame(prior)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在调用 &lt;code&gt;set_eval_frame&lt;/code&gt; 时，Dynamo 会将通过 &lt;code&gt;tstate-&amp;gt;interp-&amp;gt;eval_frame = &amp;amp;custom_eval_frame_shim;&lt;/code&gt; 来将 Eval Frame 行为替换成自己的 &lt;code&gt;custom_eval_frame_shim&lt;/code&gt;。这样之后调用的 &lt;code&gt;fn&lt;/code&gt; 便是由 Dynamo 自己的 &lt;code&gt;custom_eval_frame_shim&lt;/code&gt; 来执行的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/decomposing-torch-dynamo/dynamo-eval-frame.drawio.png&quot; alt=&quot;Dynamo Eval Frame&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;custom_eval_frame_shim&lt;/code&gt; 的源码分析图如上，我们看一下它具体是如何工作的。&lt;/p&gt;
&lt;p&gt;首先，对于 Eval Frame 来说，当然是可以获取到 FrameObject 的，同样也可以从中获取 CodeObject。根据 PEP 523，我们可以在 &lt;code&gt;co_extra&lt;/code&gt; 字段里存储一些 Cache，这里便会存储 Dynamo 编译后的 CodeObject，值得注意的是，这里 &lt;code&gt;CacheEntry&lt;/code&gt; 是同时包含 &lt;code&gt;check_fn&lt;/code&gt; 和 &lt;code&gt;code&lt;/code&gt; 字段的，&lt;code&gt;check_fn&lt;/code&gt; 即是用于检查一个编译后的 CodeObject 是否可用的，&lt;code&gt;check_fn&lt;/code&gt; 会作用于 &lt;code&gt;f_locals&lt;/code&gt;（即 &lt;code&gt;check_fn(f_locals)&lt;/code&gt;）来检查该 Cache 是否可用。这主要分为以下三种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其中 CacheEntry 是一个链表，默认最大长度为 64，如果查找全部 Cache 都不可用时，就会认为是 cache miss；&lt;/li&gt;
&lt;li&gt;而当 &lt;code&gt;check_fn(f_locals)&lt;/code&gt; 检查成功时，就会认为 cache hit；&lt;/li&gt;
&lt;li&gt;此外还有一种情况，是 cache 里存储的是 &lt;code&gt;SKIP_CODE&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外，Dynamo 会根据 callback 的情况分别执行如下操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当 callback 为 &lt;code&gt;Py_None&lt;/code&gt; 时，会直接跑原生字节码，即直接由 &lt;code&gt;eval_frame_default&lt;/code&gt; 来执行；&lt;/li&gt;
&lt;li&gt;当 callback 为 &lt;code&gt;Py_False&lt;/code&gt; 时，表示只运行但不 compile，即如果 cache hit 就跑 &lt;code&gt;eval_custom_code&lt;/code&gt;，cache miss 就跑 &lt;code&gt;eval_frame_default&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;当 callback 为一个 callable 函数时，表示运行且 compile，同样在 cache hit 时直接跑 &lt;code&gt;eval_custom_code&lt;/code&gt;，而当 cache miss 时，会先调用 &lt;code&gt;callback&lt;/code&gt; 编译出新的 CodeObject，然后将其存入 cache，最后再跑 &lt;code&gt;eval_custom_code&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;值得注意的是，如果调用 &lt;code&gt;callback&lt;/code&gt; 返回的是 &lt;code&gt;None&lt;/code&gt; 时，那么就表示编译失败，此时会将 cache 设置为 &lt;code&gt;SKIP_CODE&lt;/code&gt;，并且直接跑 &lt;code&gt;eval_frame_default&lt;/code&gt;，而且之后所有的调用都会直接跑 &lt;code&gt;eval_frame_default&lt;/code&gt;。即只要有一次编译失败，该函数的之后所有的调用都会直接跑原生字节码。不过这明显是合理的，因为对于一个函数而言，编译失败大概率意味着这个函数是不适合编译加速的，那么之后即便是不同的输入也不会再编译了。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;eval_custom_code&lt;/code&gt; 的实现很简单，就是基于原有 FrameObject 创建一个新的，在创建时使用编译后的 CodeObject 即可，最后会将新的 FrameObject 传入 &lt;code&gt;eval_frame_default&lt;/code&gt; 来执行。&lt;/p&gt;
&lt;p&gt;也就是说 Dynamo 的 Eval Frame 只会做 CodeObject 的转换，最后还是会让 Python 解释器来实际执行。&lt;/p&gt;
&lt;h2&gt;字节码模拟执行&lt;/h2&gt;
&lt;p&gt;那么在 callback 里具体是如何去进行字节码变换的呢？Dynamo 是通过模拟执行 + Codegen 的方式来实现的。在模拟执行时，Dynamo 会收集需要的信息，以在 Codegen 时尽可能地还原 Python 的行为。&lt;/p&gt;
&lt;h3&gt;compile 流程&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/decomposing-torch-dynamo/dynamo-compile.drawio.png&quot; alt=&quot;Dynamo Compile&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Dynamo 在 compile 时（也就是 callback）会将逐字节码地模拟执行，在执行过程中如果遇到无法编译的情况，就会抛出 &lt;code&gt;SkipFrame&lt;/code&gt;，并在 callback 处返回 &lt;code&gt;None&lt;/code&gt;，以标记该 CodeObject 不适合编译。&lt;/p&gt;
&lt;p&gt;若模拟执行成功，那么会根据编译得到的 OutputGraph 来生成 &lt;code&gt;check_fn&lt;/code&gt;，与 Codegen 得到的 &lt;code&gt;code&lt;/code&gt; 共同组成 &lt;code&gt;GuardedCode&lt;/code&gt; 返回给 Eval Frame。&lt;/p&gt;
&lt;h3&gt;模拟执行流程&lt;/h3&gt;
&lt;p&gt;模拟执行是 Dynamo 的核心，它的所有行为是由 &lt;code&gt;InstructionTranslator&lt;/code&gt; 来定义的。&lt;/p&gt;
&lt;p&gt;为了能够尽可能真实地模拟 Python 解释器的行为，&lt;code&gt;InstructionTranslator&lt;/code&gt; 在初始化的时候同时初始化了模拟运行栈 &lt;code&gt;stack&lt;/code&gt;、PC &lt;code&gt;instruction_pointer&lt;/code&gt;、模拟块栈 &lt;code&gt;block_stack&lt;/code&gt;、模拟 locals &lt;code&gt;symbolic_locals&lt;/code&gt;、模拟 globals &lt;code&gt;symbolic_globals&lt;/code&gt; 等诸多属性，在之后的模拟运行过程中，会不断与这些状态进行交互。&lt;/p&gt;
&lt;p&gt;由于是模拟执行，执行过程中是不会对原有数据进行修改的，为了做到这一点，Dynamo 会将所有栈上数据包装成 &lt;code&gt;VariableTracker&lt;/code&gt;，之后所有的操作都会被 &lt;code&gt;VariableTracker&lt;/code&gt; 所记录。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;symbolic_locals&lt;/code&gt; 在初始化的时候便会从 &lt;code&gt;f_locals&lt;/code&gt; 包装成 &lt;code&gt;VariableTracker&lt;/code&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;self.symbolic_locals = collections.OrderedDict(
   (
      k,
      VariableBuilder(self, LocalSource(k))(f_locals[k]),
   )
   for k in vars
   if k in f_locals
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;因此模拟执行的操作基本都是对 &lt;code&gt;VariableTracker&lt;/code&gt; 子类实例的操作，不会影响原始数据。&lt;/p&gt;
&lt;p&gt;在调用 &lt;code&gt;InstructionTranslator.run&lt;/code&gt; 时，Dynamo 会逐步根据字节码 opname 分发到对应的函数，比如 &lt;code&gt;LOAD_CONST&lt;/code&gt; 的实现如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def LOAD_CONST(self, inst):
   # For empty tuples, create empty TupleVariable
   if isinstance(inst.argval, tuple) and not inst.argval:
      self.push(TupleVariable([]))
   else:
      self.push(ConstantVariable(value=inst.argval))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里很简单地将包装后的常量压入了模拟运行栈 &lt;code&gt;stack&lt;/code&gt; 中。&lt;/p&gt;
&lt;p&gt;之后看一下稍微复杂一点的 &lt;code&gt;BINARY_ADD&lt;/code&gt; 的实现：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;BINARY_ADD = stack_op(operator.add)

def stack_op(fn: typing.Callable[..., object]):
   nargs = len(inspect.signature(fn).parameters)
   fn_var = BuiltinVariable(fn)

   @functools.wraps(fn)
   def impl(self: &quot;InstructionTranslatorBase&quot;, inst: Instruction):
      self.push(fn_var.call_function(self, self.popn(nargs), {}))

   return impl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里先用 builtin 函数（这里是 &lt;code&gt;operator.add&lt;/code&gt;）创建 &lt;code&gt;BuiltinVariable&lt;/code&gt;，然后弹栈两个操作数，传入新的 Variable 调用 &lt;code&gt;call_function&lt;/code&gt;，并将结果压栈。&lt;/p&gt;
&lt;p&gt;那么这里 &lt;code&gt;call_function&lt;/code&gt; 做了什么呢？由于这里的实现细节比较多，这里只考虑几种简单的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当两个参数都是常量（&lt;code&gt;ConstantVariable&lt;/code&gt;），并且可以常量折叠，则直接返回折叠后的 &lt;code&gt;ConstantVariable&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果有参数是 Tensor（&lt;code&gt;TensorVariable&lt;/code&gt;），那么创建 FX Proxy，开始 FX Graph 组网&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比如对于如下的代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import torch


@torch.compile
def foo(x: torch.Tensor, y: int):
   x = x + 1
   y = y - 1
   x = x + y
   return x


x = torch.as_tensor(1)
y = 2
print(foo(x, y))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;实际模拟执行可能会类似于下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/decomposing-torch-dynamo/dynamo-simulate-execution.drawio.png&quot; alt=&quot;Dynamo Simulate Execution&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在执行 &lt;code&gt;BINARY_ADD&lt;/code&gt; 前后，&lt;code&gt;stack&lt;/code&gt; 弹出两个 Variable，并放入一个新的 Variable，同时 FX Graph 也进行了组网。&lt;/p&gt;
&lt;p&gt;由于 &lt;code&gt;BuiltinVariable&lt;/code&gt; 表示一个 builtin 操作，是有很多操作是会构建此 Variable 的，比如各种魔法函数，当然 &lt;code&gt;print&lt;/code&gt; 也是，但是 &lt;code&gt;call_function&lt;/code&gt; 时并没有 &lt;code&gt;print&lt;/code&gt; 的处理方式，因此会抛出 &lt;code&gt;Unsupported&lt;/code&gt; 异常打断子图。&lt;/p&gt;
&lt;h3&gt;子图打断&lt;/h3&gt;
&lt;p&gt;在整个代码运行过程中，主要有以下三种情况会打断子图，触发子图编译：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当遇到 &lt;code&gt;RETURN_VALUE&lt;/code&gt; 时&lt;/li&gt;
&lt;li&gt;当遇到跳转指令时，且跳转条件是 Tensor（&lt;code&gt;TensorVariable&lt;/code&gt;）时&lt;/li&gt;
&lt;li&gt;当内部任意时刻抛出 &lt;code&gt;Unsupported&lt;/code&gt; Error 时&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于遇到 &lt;code&gt;Unsupported&lt;/code&gt; Error 时，Dynamo 会将当前的子图打断，并将之后的代码抽到一个新的函数中，即交由下一个 Frame 来处理。&lt;/p&gt;
&lt;h3&gt;跳转指令的处理&lt;/h3&gt;
&lt;p&gt;跳转指令的处理会稍微复杂一些，Dynamo 会在遇到 JUMP 指令，且跳转条件是 Tensor 的时候，触发子图编译，并将跳转分支分别提取成两个函数，分别对原有的两个分支进行替换。&lt;/p&gt;
&lt;p&gt;下面直接通过例子来说明一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@torch.compile
def foo(x, y):
   if x &amp;gt; 0:
      y += 1
   else:
      y -= 1
   return y

print(foo(torch.as_tensor([5]), torch.as_tensor([0])))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于如上代码来说，由于跳转条件是一个 Tensor，因此是会发生子图打断的，对于函数 &lt;code&gt;foo&lt;/code&gt; 而言，编译前后的字节码分别如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Before:

 42           0 LOAD_FAST                0 (x)
              2 LOAD_CONST               1 (0)
              4 COMPARE_OP               4 (&amp;gt;)
              6 POP_JUMP_IF_FALSE       10 (to 20)

 43           8 LOAD_FAST                1 (y)
             10 LOAD_CONST               2 (1)
             12 INPLACE_ADD
             14 STORE_FAST               1 (y)

 46          16 LOAD_FAST                1 (y)
             18 RETURN_VALUE

 45     &amp;gt;&amp;gt;   20 LOAD_FAST                1 (y)
             22 LOAD_CONST               2 (1)
             24 INPLACE_SUBTRACT
             26 STORE_FAST               1 (y)

 46          28 LOAD_FAST                1 (y)
             30 RETURN_VALUE

After:

 40           0 LOAD_GLOBAL              0 (__compiled_fn_0)
              2 LOAD_FAST                0 (x)
              4 CALL_FUNCTION            1
              6 UNPACK_SEQUENCE          1
              8 POP_JUMP_IF_FALSE        9 (to 18)
             10 LOAD_GLOBAL              1 (__resume_at_8_1)
             12 LOAD_FAST                1 (y)
             14 CALL_FUNCTION            1
             16 RETURN_VALUE
        &amp;gt;&amp;gt;   18 LOAD_GLOBAL              2 (__resume_at_20_2)
             20 LOAD_FAST                1 (y)
             22 CALL_FUNCTION            1
             24 RETURN_VALUE

__resume_at_8_1:

 42           0 JUMP_ABSOLUTE            5 (to 10)
              2 LOAD_FAST                1 (x)
              4 LOAD_CONST               1 (0)
              6 COMPARE_OP               4 (&amp;gt;)
              8 POP_JUMP_IF_FALSE       11 (to 22)

 43     &amp;gt;&amp;gt;   10 LOAD_FAST                0 (y)
             12 LOAD_CONST               2 (1)
             14 INPLACE_ADD
             16 STORE_FAST               0 (y)

 46          18 LOAD_FAST                0 (y)
             20 RETURN_VALUE

 45     &amp;gt;&amp;gt;   22 LOAD_FAST                0 (y)
             24 LOAD_CONST               2 (1)
             26 INPLACE_SUBTRACT
             28 STORE_FAST               0 (y)

 46          30 LOAD_FAST                0 (y)
             32 RETURN_VALUE

__resume_at_20_2:

 42           0 JUMP_ABSOLUTE           11 (to 22)
              2 LOAD_FAST                1 (x)
              4 LOAD_CONST               1 (0)
              6 COMPARE_OP               4 (&amp;gt;)
              8 POP_JUMP_IF_FALSE       11 (to 22)
             10 LOAD_FAST                0 (y)
             12 LOAD_CONST               2 (1)
             14 INPLACE_ADD
             16 STORE_FAST               0 (y)
             18 LOAD_FAST                0 (y)
             20 RETURN_VALUE

 45     &amp;gt;&amp;gt;   22 LOAD_FAST                0 (y)
             24 LOAD_CONST               2 (1)
             26 INPLACE_SUBTRACT
             28 STORE_FAST               0 (y)

 46          30 LOAD_FAST                0 (y)
             32 RETURN_VALUE

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;字节码上可能并不是很清晰，这里用一张图来说明下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/decomposing-torch-dynamo/dynamo-resume.drawio.png&quot; alt=&quot;Dynamo Resume&quot; /&gt;&lt;/p&gt;
&lt;p&gt;可以看到，生成的字节码中，一方面包含了子图编译的函数，另一方面，将是否跳转对应的两个分支抽取到了新的 resume 函数中，这样在这个函数，根据 Tensor 值来跳转的问题就解决了，下个分支的问题，交由下个 Frame 处理即可，这样问题就分解了。&lt;/p&gt;
&lt;p&gt;值得注意的是，在字节码层面，我们不应该去过分的苛求还原原有的分支结构，在这里我们只会注意跳转的与否，如果不跳转，就是走 BLOCK 1 + BLOCK 2，如果跳转，就是走 BLOCK 1，在字节码层面这是很清晰、很明确的事情。这样的话，我们就无需再去考虑它从代码层面是 if-else 还是 for/while-loop，因为在字节码层面他们都是 JUMP，都会归结成这一种模式。那嵌套的怎么办？嵌套在字节码层面本质就是多个 JUMP 指令，但对于我们来说，只需要关注第一个 JUMP 就可以了，第二个 JUMP 已经移交到下个 Frame 处理了。&lt;/p&gt;
&lt;h2&gt;代码生成&lt;/h2&gt;
&lt;p&gt;从端到端来说，整个 Dynamo 做的事就是 &lt;code&gt;code&lt;/code&gt; -&amp;gt; &lt;code&gt;code&lt;/code&gt;，也就是说整个过程一定是一种代码变换，而我们之前模拟执行的主要目的是收集信息，之后还需要 Codegen 来生成需要的代码。&lt;/p&gt;
&lt;p&gt;Dynamo 的代码生成部分大多都是非常简单易懂的，resume 部分生成的代码已经在上面展示过了，下面展示下子图编译的代码生成。&lt;/p&gt;
&lt;h3&gt;子图编译代码生成&lt;/h3&gt;
&lt;p&gt;子图编译时的代码生成主要包含以下几步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将 FX Graph 编译成函数，这个过程会调用用户提供的 compiler backend，并将该函数挂到 globals 里&lt;/li&gt;
&lt;li&gt;在生成字节码里加上从 globals 里 LOAD 刚刚编译好的函数的字节码&lt;/li&gt;
&lt;li&gt;在生成字节码里加上 LOAD 需要传入的参数，注意所有参数都是知道来源（Source）的，因此可以 Codegen 出需要的 LOAD 指令&lt;/li&gt;
&lt;li&gt;在生成字节码里加上 CALL_FUNCTION 指令，调用编译好的函数&lt;/li&gt;
&lt;li&gt;在生成字节码里加上 SideEffects 的处理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们从一个示例来看这个过程：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class A:
    def __init__(self, value):
        self.value = value

@torch.compile
def foo(x, y):
    x.value += 1
    return x.value + y.value

foo(A(3), A(torch.Tensor([4])))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;生成的代码大致如下（因为生成的代码是字节码层面的，这里手动还原成 Python 代码）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 这个函数只有字节码，没有 Python 源码，这是手动翻译过来的
def foo(x, y):
   out = compiled_fn(y.value)
   out[0] # 这里直接放在栈上没有取走，所以最后 return 的时候会 return 这个，这里尽可能还原字节码顺序，不把这个放在 return 后面
   x.value = 4 # SideEffects 生成的
   return # out[0]

# 这个函数是 FX graph 生成的
def compiled_fn(y_value):
   add = 4 + y_value
   return (add, )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;值得注意的是，这里两个函数里包含了常量 4，这个 4 是 &lt;code&gt;x.value += 1&lt;/code&gt; 生成的，也就是说这个输入已经硬编码在输出的代码里了，为了保证其正确性，Dynamo 在 Guard 里包含了 &lt;code&gt;L[&apos;x&apos;].value == 3&lt;/code&gt; 的检查项，也就是说只要 &lt;code&gt;x.value != 3&lt;/code&gt; 就会触发重新编译。&lt;/p&gt;
&lt;h3&gt;Source 管理&lt;/h3&gt;
&lt;p&gt;在上面的代码生成过程中，我们提到了 Source，我们可以利用它来重新生成 LOAD 参数的代码，这里看一下 Source 是如何管理的。&lt;/p&gt;
&lt;p&gt;在模拟执行的初期，我们从 &lt;code&gt;f_locals&lt;/code&gt; 构建 &lt;code&gt;symbolic_locals&lt;/code&gt; 的时候，就会设置生成的 VariableTracker，使其 Source 为 LocalSource，这样就可以知道这些栈上元素最初是从 &lt;code&gt;f_locals&lt;/code&gt; 里得到的，当然我们就可以生成直接从 &lt;code&gt;f_locals&lt;/code&gt; 里 LOAD 它的指令了。&lt;/p&gt;
&lt;p&gt;对于一些复合操作，比如 &lt;code&gt;x.y&lt;/code&gt;，在 VariableTracker 的构建过程中，会将 Source 属性进行传播，比如这里 &lt;code&gt;x.y&lt;/code&gt; 对应的 VariableTracker 的 Source 可能就是 &lt;code&gt;AttrSource(base=LocalSource(local_name=&apos;x&apos;), member=&apos;y&apos;)&lt;/code&gt;，我们同样也是可以很方便地通过它来生成这个 getattr 操作对应的 Bytecode。&lt;/p&gt;
&lt;h3&gt;Guard 管理&lt;/h3&gt;
&lt;p&gt;为了保护生成的代码在下一次调用时是可用的，Dynamo 会为每个生成的代码都加上一个 Guard，这个 Guard 是一个 lambda 函数，形式大概类似 &lt;code&gt;lambda L: ___guarded_code.valid and not ___are_deterministic_algorithms_enabled() and ___check_tensors(L[&apos;x&apos;], L[&apos;y&apos;])&lt;/code&gt;，在 Eval Frame 部分我们已经知道了，这个函数会将 &lt;code&gt;f_locals&lt;/code&gt; 作为参数，因此，这里的 &lt;code&gt;L[&apos;x&apos;]&lt;/code&gt;、&lt;code&gt;L[&apos;y&apos;]&lt;/code&gt; 即表示输入参数中的 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;比如对于如下代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class A:
    def __init__(self, value):
        self.value = value


@torch.compile
def foo(x, y):
    if x.value &amp;gt; 3:
        y += 1
    else:
        y -= 1
    return y

print(foo(A(5), torch.as_tensor([0])))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;最后会生成如下的 Guard：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lambda L: ___guarded_code.valid and ___check_type_id(L[&apos;x&apos;], 4882921328) and ___check_type_id(L[&apos;x&apos;].value, 4299954872) and L[&apos;x&apos;].value == 5 and not ___are_deterministic_algorithms_enabled() and ___check_tensors(L[&apos;y&apos;])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里主要检查了如下几项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt; 类型是 &lt;code&gt;A&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x.value&lt;/code&gt; 类型是 &lt;code&gt;int&lt;/code&gt;，这里 &lt;code&gt;x.value&lt;/code&gt; 的代码同样可以从 Source 生成&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x.value&lt;/code&gt; 值为 5&lt;/li&gt;
&lt;li&gt;关于 &lt;code&gt;y&lt;/code&gt; 的一系列 Tensor 检查，这包含了 &lt;code&gt;dtype&lt;/code&gt;、&lt;code&gt;device&lt;/code&gt;、&lt;code&gt;requires_grad&lt;/code&gt;、&lt;code&gt;ndim&lt;/code&gt; 等属性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Guard 是有传播机制的，比如 &lt;code&gt;z = x + y&lt;/code&gt;，新生成的 &lt;code&gt;z&lt;/code&gt; 的 Guard 是 &lt;code&gt;x&lt;/code&gt; 和 &lt;code&gt;y&lt;/code&gt; 是 Guard 的总和，这可以通过 &lt;code&gt;VariableTracker.propagate&lt;/code&gt; 在不同 VariableTracker 之间进行传播，这就确保了值的依赖关系是可以保持的。&lt;/p&gt;
&lt;h3&gt;SideEffects 管理&lt;/h3&gt;
&lt;p&gt;由于在模拟执行过程中，我们是可以跟踪任意时刻对于任何变量的操作的，因此任何副作用都是可追踪的，在遇到存在副作用的操作时，我们只需要将其记录下来，并在最终生成的代码里生成相应的副作用代码即可。&lt;/p&gt;
&lt;p&gt;比如对于如下明显有副作用的代码：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@torch.compile
def foo(x):
   x.append(1)
   return x[0] + 1


x = [torch.Tensor([1])]
print(foo(x))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;生成的代码大概如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def foo(x):
   out = compiled_fn(x[0])
   out[0]
   x[:] = [x[0], 1] # SideEffects
   return # out[0]

def compiled_fn(x_0):
   add = x_0 + 1
   return (add, )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中 &lt;code&gt;x[:] = [x[0], 1]&lt;/code&gt; 即恢复副作用影响的代码，Dynamo 会将原来的 &lt;code&gt;x&lt;/code&gt; inplace 地全部替换成新的结果 &lt;code&gt;[x[0], 1]&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://peps.python.org/pep-0523/&quot;&gt;PEP 523 – Adding a frame evaluation API to CPython&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TorchDynamo Source: &lt;a href=&quot;https://github.com/pytorch/pytorch/tree/main/torch/csrc/dynamo&quot;&gt;C side&lt;/a&gt;、&lt;a href=&quot;https://github.com/pytorch/pytorch/tree/main/torch/_dynamo&quot;&gt;Python side&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://pytorch.org/docs/stable/dynamo/guards-overview.html&quot;&gt;TorchDynamo Overview - Guards Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://nanguage.gitbook.io/inside-python-vm-cn/&quot;&gt;深入理解 Python 虚拟机&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>让 Paddle 更可爱——开发者体验提升计划</title><link>https://nyakku.moe/posts/moefy-paddle-dx-improvements/</link><guid isPermaLink="true">https://nyakku.moe/posts/moefy-paddle-dx-improvements/</guid><pubDate>Wed, 21 Sep 2022 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;乍一看这标题什么鬼嘛？PaddlePaddle 不是一个深度学习框架嘛？这还能强行变可爱嘛？嘿嘿，怎么说呢，目前 Paddle 相对于很多大型开源项目在代码规范上是有一定欠缺的，之前也有尝试过参与一些相关的优化，但如此庞大的一个 Codebase 并不是说随随便便改改就好的啦，所以，便有了本「计划」。（嘿嘿，咱的 &lt;a href=&quot;https://github.com/moefyit&quot;&gt;moefyit&lt;/a&gt; 计划可以在 Paddle 社区开展了呢～）&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;常见开发工作流及工具&lt;/h2&gt;
&lt;h3&gt;开发工作流&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/moefy-paddle-dx-improvements/workflow.drawio.png&quot; alt=&quot;workflow&quot; /&gt;&lt;/p&gt;
&lt;p&gt;想必熟悉开发流程的同学们对工作流中的几个阶段也都非常了解了。一般情况下我们首先会在编辑器或者 IDE 上开发，然后通过 git 来进行一系列源代码的管理，之后推送到远程仓库，往往最后会触发相关的 CI/CD 来进行一些自动化测试、部署等操作。&lt;/p&gt;
&lt;p&gt;我们在编辑器上进行开发时，往往会配置一些 Linter 或者 Formatter 工具，它们可以为我们及时地提供错误反馈及建议，使我们能够在开发过程中就解决大多数的格式等问题。当然，我们也可以手动在 Terminal 运行相应的 CLI 工具，来手动进行一些格式化等操作。&lt;/p&gt;
&lt;p&gt;之后利用 git 进行 commit、push 等等操作时，由于 git 在这些生命周期是可以注入一些 hook 的，因此我们也可以利用这个阶段来完成一些自动格式化、代码检查等操作。目前各个生态也都有比较成熟的 hook 管理工具，比如 Python 生态下的 &lt;a href=&quot;https://pre-commit.com/&quot;&gt;pre-commit&lt;/a&gt;，Node.js 生态下的 &lt;a href=&quot;https://github.com/typicode/husky&quot;&gt;husky&lt;/a&gt; 等等。利用这些工具可以轻松配置一些实用的 hook，提高工作流的自动化程度。&lt;/p&gt;
&lt;p&gt;最后就是 CI 啦，CI 是整个工作流的最后一步，这一步往往有最完整的代码检查，这样即便开发者本地编辑器没有进行相关配置，或者本地没有安装 pre-commit，在这一步都能够检查出来，保证了合并到主线上的代码是没有相关问题的。&lt;/p&gt;
&lt;h3&gt;Python 常见开发工具链&lt;/h3&gt;
&lt;p&gt;相比于一些新兴的语言来说，Python 的工具链一直处于非常落后的状态，Python 官方提供的工具链是非常不完善的，或者说是不「现代」的。因此可以看到 Python 的项目结构往往配置地形态各异，也使得参与开发的人需要对项目有一定熟悉程度才能上手。这里会简单介绍一些常见的工具。&lt;/p&gt;
&lt;p&gt;如果要说完整的工具链的话，那么环境、依赖管理工具、Linter、Formatter、测试套件这些都是必不可少的啦。不过本文的关注的重点是 Linter 和 Formatter。&lt;/p&gt;
&lt;h4&gt;Formatter&lt;/h4&gt;
&lt;p&gt;Formatter 主要用于自动格式化代码，使得项目代码风格统一，避免项目协作时因为格式的调整而出现一些没必要的改动。合格的 Formatter 是不会对代码语义进行任何更改的，可以认为格式化是一个非常安全且可靠的操作，因此我们可以放心地在任何时刻运行它，而不必担心代码修改后出现问题。&lt;/p&gt;
&lt;p&gt;目前常见的格式化工具包括了 yapf、black、autopep8 等，还有一些只针对某些特定场景进行格式化的工具，比如 isort，就是只格式化 import 语句的顺序的。&lt;/p&gt;
&lt;p&gt;yapf 是 Google 开发的格式化工具，它非常像 clang-format，有着非常多的配置项，可以配置出各种各样想要的代码风格。但是 yapf 的格式化力度并不高，同一段代码经过调整后它可以格式化出好多种代码格式。&lt;/p&gt;
&lt;p&gt;black 是一个不妥协的格式化工具，有点像 prettier 这样的 JS/TS 格式化工具，它可以保证相同的代码格式化出来的结构是一致的，不会因为代码稍微调整出现代码风格的突变，在视觉上也非常的统一。唯一可能的缺点是因为它基本不可配置，因此如果你不喜欢 black 格式化后某一段代码的风格，基本是没办法调整的，除非使用 &lt;code&gt;# fmt: off&lt;/code&gt; 禁止该区域代码的格式化。&lt;/p&gt;
&lt;p&gt;autopep8 是一个非常简单的格式化工具，没啥格式化力度，也正如其名字，就是个自动修复 &lt;a href=&quot;https://peps.python.org/pep-0008/&quot;&gt;PEP 8&lt;/a&gt; 中所描述的代码风格问题的工具而已。在某些问题的修复方案上甚至会改变代码的语义，因此我认为它不算是「合格」的格式化工具。&lt;/p&gt;
&lt;h4&gt;Linter&lt;/h4&gt;
&lt;p&gt;Linter 主要用于给开发者提示代码中存在的格式问题、语法问题和一些潜在的逻辑问题。与 Formatter 不一样的是，Linter 往往是不进行自动修复的，最多只会给出一个修改建议，提示开发者手动对问题进行修复。当然，由于 Linter 会给出一些潜在的逻辑问题，对于这些问题也只能手动修复，当然，Linter 相比于 Formatter 所拥有最大的价值也在于提示这些逻辑问题。&lt;/p&gt;
&lt;p&gt;目前常见的 Linter 工具主要包含了 Flake8、Pylint 等，此外还有些静态类型检查工具，比如 Mypy、Pytype、Pyright 等。&lt;/p&gt;
&lt;p&gt;Flake8 是 pycodestyle、pyflakes 和 mccabe 三个工具的集合，它们分别用于检查代码风格、语法错误和循环复杂度。此外，Flake8 还支持插件，这使得 Flake8 可以做到各种各样的检查项。&lt;/p&gt;
&lt;p&gt;Pylint 我没有用过，也没有去调研，因此不做评判。&lt;/p&gt;
&lt;p&gt;Pyright 是 VS Code 推荐的扩展 Pylance 的后端，它不仅仅可以提供静态类型检查，而且还能提供少许代码风格和代码逻辑上的检查，并且凭借着 Pylance 扩展，为 VS Code 提供了非常棒的 Python 开发体验。&lt;/p&gt;
&lt;h4&gt;个人推荐&lt;/h4&gt;
&lt;p&gt;我个人非常喜欢使用 black + isort + VS Code Pylance 扩展的组合，black 在自动格式化的过程中可以解决大多数格式问题，isort 为 import 顺序进行自动重排，而 Pylance（Pyright）则会给出一些类型上、逻辑上的建议，基本上可以满足大多数日常开发需求。&lt;/p&gt;
&lt;p&gt;前段时间尝试在一个我长期使用该组合进行开发的项目中尝试使用 Flake8 进行检测，结果仅仅只有不到 10 个 Flake8 问题，而且这些问题基本上都是一些无用的建议，即便引入 Flake8，我也只会在那些地方加上 &lt;code&gt;# noqa&lt;/code&gt; 而已。&lt;/p&gt;
&lt;p&gt;如果要说环境、依赖管理工具和测试套件的话，我比较推荐 Poetry 和 pytest，但这里就不赘述了。&lt;/p&gt;
&lt;h3&gt;将工具引入工作流的各个阶段&lt;/h3&gt;
&lt;p&gt;当然，这些工具都是要用的嘛，用的时机也就是之前所说的那几个阶段啦～&lt;/p&gt;
&lt;h4&gt;Editor / IDE&lt;/h4&gt;
&lt;p&gt;由于 Linter 往往会给出各式各样的提示，在开发中出现问题的频率是非常高的，因此在编辑器中配置 Linter 来进行实时提示往往是非常重要的，这样可以给开发人员一个最及时的反馈。&lt;/p&gt;
&lt;p&gt;Formatter 往往则并不需要那么高运行的频率，一般情况下配置成在保存时进行格式化即可。&lt;/p&gt;
&lt;p&gt;如果编辑器配置的好的话，能够给开发人员最佳的开发体验。但由于每个人的喜好不同，选择的编辑器往往也不一样，因此编辑器的配置统一也是一件非常麻烦的事情，在文档中提供相关说明是非常必要的。&lt;/p&gt;
&lt;h4&gt;git hooks&lt;/h4&gt;
&lt;p&gt;在 git 生命周期里，&lt;code&gt;pre-commit&lt;/code&gt; 是最常使用的一个生命周期阶段，在这个阶段衍生出各式各样的工具。如果是 Python 的话，pre-commit 是不二选择，pre-commit 有着非常丰富的生态，而且允许通过非常简单的方式自定义一个新的 hook。我们可以通过 pre-commit 添加各式各样的检查，比如 Linter 的问题检查、Formatter 的是否已经格式化过的检查等等。&lt;/p&gt;
&lt;h4&gt;CI / CD&lt;/h4&gt;
&lt;p&gt;CI 本质也很简单，就是一个统一的环境，运行各种各样的命令，因此我们当然可以配置 Linter、Formatter 等工具来进行检查。当然，CI 往往还会包含一些比如单元测试、文档部署等的一些操作。&lt;/p&gt;
&lt;p&gt;如果一些工具已经集成在 pre-commit 里了，那么我们也可以直接在 CI 上运行 pre-commit，以保证这些工具都是可以检查通过的。&lt;/p&gt;
&lt;h4&gt;配置方式&lt;/h4&gt;
&lt;p&gt;这里各种各样的工具往往都是有一些配置项的，比如 Linter 所需要检查的错误项、Formatter 的最大行宽等，如果我们在每个阶段分别对这些工具配置的话，很容易造成不同阶段工具使用方式的不一致。比如编辑器里设置了 black 最大行宽 120，而 CI 里设置了 80，这样就会造成 CI 检查不通过的情况。&lt;/p&gt;
&lt;p&gt;不过大多数工具都是支持读取配置文件的方式的，我们可以将配置文件放到项目的根目录，这样在项目中运行这些工具时就会自动读取这些配置文件，不用再担心配置不一致的问题了。&lt;/p&gt;
&lt;p&gt;由于现在大多数工具都支持在 &lt;a href=&quot;https://peps.python.org/pep-0518/&quot;&gt;PEP 518&lt;/a&gt; 提出的 &lt;code&gt;pyproject.toml&lt;/code&gt; 里进行配置，因此也是非常建议将这些工具的配置都放在这一个文件中的。当然，&lt;a href=&quot;https://github.com/PyCQA/flake8/issues/234&quot;&gt;除了 Flake8&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;除此之外，个人非常推荐一个跨编辑器配置文件 &lt;a href=&quot;https://editorconfig.org/&quot;&gt;&lt;code&gt;.editorconfig&lt;/code&gt;&lt;/a&gt;，这个文件可以配置编辑器的一些通用配置，比如缩进、换行符等，这样就不用考虑各式各样编辑器下格式配置不统一的问题了。我个人也是非常庆幸在刚刚接触开源时就了解到了这个配置文件，让我在这几年开发过程中基本没有遇到格式上的问题，因为一切都在源头（编辑器）上就解决了。&lt;/p&gt;
&lt;h2&gt;这些工具咋实现的？&lt;/h2&gt;
&lt;h3&gt;直接在纯文本上做&lt;/h3&gt;
&lt;p&gt;前面说了这么多的工具，不过这些工具都是如何实现的呢？首先考虑一种非常简单的方式，文本搜索和替换。虽然是一个最简单的方式，但也有不少工具也确实是这么做的，比如 &lt;a href=&quot;https://github.com/pre-commit/pre-commit-hooks/blob/main/pre_commit_hooks/end_of_file_fixer.py&quot;&gt;end-of-file-fixer&lt;/a&gt;、&lt;a href=&quot;https://github.com/Lucas-C/pre-commit-hooks/blob/master/pre_commit_hooks/remove_tabs.py&quot;&gt;remove-tabs&lt;/a&gt; 这些简单的代码格式修复工具等。&lt;/p&gt;
&lt;p&gt;一些稍微复杂的需求的话当然是可以利用正则来进行搜索替换的啦，比如我之前做的自动在中英文间加空格的 &lt;a href=&quot;https://github.com/ShigureLab/dochooks&quot;&gt;insert-whitespace-between-cn-and-en-char&lt;/a&gt; 就是使用正则实现的。&lt;/p&gt;
&lt;p&gt;但如果有些更加复杂的需求的话，可能就需要手写一些复杂的规则进行处理了，但一般情况下这种需求并不多，而且大多数文本都是有一定的语法规则的，这些拥有语法规则的文本直接在 AST 上处理是更好的方式。&lt;/p&gt;
&lt;h3&gt;进一步在词法单元上进行分析&lt;/h3&gt;
&lt;p&gt;如果一个工具需要专门分析某种语言一些格式上的问题的话，在词法上分析 Token Stream 是比较合适的，不过这样的需求一般也不会太多，目前我了解到的也只有 pycodestyle 这一个工具使用的是这种方式。大多数工具都是在进一步经过语法分析处理成的语法树上进行操作的。&lt;/p&gt;
&lt;h3&gt;再进一步直接在 AST 上操作&lt;/h3&gt;
&lt;p&gt;经过语法分析后，我们就可以得到语法树啦。语法树包含具象语法树和抽象语法树（AST，Abstract Syntax Tree），抽象语法树相比于具象语法树省略了部分细节，因此在处理时会更加方便。这里将之前我在进行&lt;a href=&quot;https://github.com/PaddlePaddle/community/blob/master/rfcs/CodeStyle/20220805_code_style_improvement_for_unittest.md&quot;&gt;单测报错信息优化&lt;/a&gt;时的一个简单的例子来说明一下 AST 的结构。&lt;/p&gt;
&lt;p&gt;首先说明下当时的一个需求，是将 &lt;code&gt;self.assertTrue(np.allclose(x, y, rtol=rtol, atol=atol), msg=msg)&lt;/code&gt; 形式的代码处理成 &lt;code&gt;np.testing.assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=msg)&lt;/code&gt; 形式的代码。乍一看可能会想到使用正则进行处理，不过稍微一想就会发现有很多坑，比如括号匹配的问题。但既然是处理符合 Python 语法的文本，我们直接交给最专业的 Python 语法分析工具肯定是最合适的啦～&lt;/p&gt;
&lt;p&gt;利用 Python built-in 的 ast 模块就可以将一段 Python 文本代码处理成一个 AST 结构，比如下面这段 Python 代码，在经过处理后即可得到一棵如下图所示的 AST：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;self.assertTrue(
   np.allclose(
      res[0],
      feed_add,
      rtol=1e-5),
   msg=&apos;blabla((((()()((xxxdfdf(&apos;
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/moefy-paddle-dx-improvements/ast.drawio.png&quot; alt=&quot;ast&quot; /&gt;&lt;/p&gt;
&lt;p&gt;我们可以从叶子结点上隐约看出原来的文本代码结构。&lt;/p&gt;
&lt;p&gt;对 AST 进行处理会比直接对文本处理方便得多，比如我们可以通过遍历这个 AST 来找到我们需要的模式，然后对部分结点进行替换重构，形成新的 AST。这个过程中使用的往往是访问者模式，由于之前已经说过访问者模式了，这里就不赘述了。在 AST 上处理过后，我们最后还是要将新的 AST 转换成文本代码，这样就完成了整个处理过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/moefy-paddle-dx-improvements/ast-transform.drawio.png&quot; alt=&quot;ast-transform&quot; /&gt;&lt;/p&gt;
&lt;p&gt;整体流程也如上图所示，是一个从文本到 AST，经过若干处理后再转回文本的过程。&lt;/p&gt;
&lt;p&gt;利用 AST 的工具不在少数，formatter 自不必说，linter 也有很大一部分也是在 AST 上进行语法结构匹配和分析的。&lt;/p&gt;
&lt;h3&gt;一个推荐的工具 ast-grep&lt;/h3&gt;
&lt;p&gt;前面也说了，如果想要利用 AST 进行搜索替换的话，往往需要先将代码转换成 AST，并同时需要匹配的模式转换为 AST 进行匹配，之后再经过若干处理步骤后转回文本，整体做起来非常繁琐。&lt;/p&gt;
&lt;p&gt;在做单测报错信息优化的时候我就有写一个基于文本模式进行搜索替换的工具的想法。当时的设想是能够传入一段文本和文本的模式，提供类似正则的语法进行搜索替换，避免手写 AST 处理代码。不过因为暂时没有更多的需求，就先搁置下来了。&lt;/p&gt;
&lt;p&gt;不过非常巧的是 &lt;a href=&quot;https://github.com/HerringtonDarkholme&quot;&gt;HerringtonDarkholme&lt;/a&gt; 就在前段时间开源了一个使用 Rust 写的基于 AST 的文本搜索替换工具 &lt;a href=&quot;https://github.com/ast-grep/ast-grep&quot;&gt;ast-grep&lt;/a&gt;，一些用法和我之前的想法基本上一致，当我看到这个工具的名字的时候其实就确定了。&lt;/p&gt;
&lt;p&gt;这个工具使用方式也是非常简单，直接传入待搜索的文本模式和需要输出的文本模式即可，比如下面这个例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cargo run -- --pattern &apos;self.assertTrue(np.allclose($A, $B, $$$REMAIN_ARGS), msg=$MSG)&apos; --rewrite &apos;np.testing.assert_allclose($A, $B, $$$REMAIN_ARGS, err_msg=$MSG)&apos; --lang py ut.py
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/moefy-paddle-dx-improvements/ast-grep.png&quot; alt=&quot;ast-grep&quot; /&gt;&lt;/p&gt;
&lt;p&gt;不过这个工具还处于非常早期的状态，问题还是蛮多的，我刚刚开始尝试这个工具的时候甚至对 Python 语言支持是有一点点问题的，因此就去提了个 PR 修复了下～&lt;/p&gt;
&lt;p&gt;此外，HerringtonDarkholme 还为 ast-grep 设计了一些巧妙的功能，比如配置一些规则，以起到 Linter 的作用，不过由于目前还只能做到简单的模式匹配，因此还是有很多限制的。&lt;/p&gt;
&lt;h2&gt;如何引入新工具？&lt;/h2&gt;
&lt;h3&gt;解决存量代码中的问题&lt;/h3&gt;
&lt;p&gt;诶？说了这么多，好像都和 Paddle 没什么关系嘛！更别说让 Paddle 更可爱了！了解工具原理有啥用捏？难道我们还真要实现个工具不成？&lt;/p&gt;
&lt;p&gt;嘿嘿，也许真的会有些需求是需要我们自己动手写各种各样的工具的，比如我们有一些定制化的重构需求，或者在引入新的工具的时候。&lt;/p&gt;
&lt;p&gt;如果想要引入新的工具的话，当前代码库中的现存问题一定是要考虑的，不然如果仅仅引入工具而不去修复存量问题的话，之后的开发者在改动一个文件后可能要对这个文件中所有存量问题都解决一番，这样不仅浪费了开发者的时间，还会使得 review 时出现很多无关改动。&lt;/p&gt;
&lt;p&gt;如果引入工具是个 Formatter 的话，那么自然是直接一键格式化即可。但如果引入的是 Linter 的话，我们可以首先看看有没有一些现成的修复工具，当然，有很多问题的修复其实是不可靠的，有可能修改代码的语义，因此我们还是需要人工去 review 修复后的代码。当然，如果没有相关工具的话，就只能自己编写工具或者手动进行修复了。&lt;/p&gt;
&lt;h3&gt;配置新工具，引入到工作流中的几个阶段&lt;/h3&gt;
&lt;p&gt;在解决存量问题后，就可以在代码库中对工具进行配置了，也正如最开始所说的，即将工具配置到工作流的各个阶段即可。&lt;/p&gt;
&lt;p&gt;对于比较成熟的工具，我们直接利用它们提供的 pre-commit-hooks 即可同时将其引入到 pre-commit 和 CI 两个阶段，在编辑器阶段的话，最好提供说明文档来告知开发者所使用的工具及相关的配置指南。&lt;/p&gt;
&lt;p&gt;如果有一些使用频率不高的检查项的话，我们直接在 CI 上写一个检查脚本即可。&lt;/p&gt;
&lt;h2&gt;那，我们都可以做些什么呢？&lt;/h2&gt;
&lt;p&gt;能做的可太多了……比如目前我正在进行 &lt;a href=&quot;https://github.com/PaddlePaddle/Paddle/issues/46039&quot;&gt;Flake8 引入&lt;/a&gt;的计划，在这个过程中我也有计划同时引入 isort 等工具。由于目前 Paddle 使用的格式化工具 yapf 存在许多问题，而且可能会存在大量 Flake8 错误码需要手动修复，因此目前也有计划将 Paddle 的格式化工具从 yapf 切换到 black。&lt;/p&gt;
&lt;p&gt;此外，Paddle 中文文档目前使用的是 reStructureText 编写的，目前存在各种各样的格式问题，其实对于这种文档来说 rst 并不是一种好的存储格式，我和&lt;a href=&quot;https://github.com/Liyulingyue&quot;&gt;笠雨聆月&lt;/a&gt;也有一个重写文档生成流程的初步计划，当然，至于什么时候开始做什么时候能做完，那我只能说：「咕咕咕」(๑&amp;gt;؂&amp;lt;๑）&lt;/p&gt;
&lt;p&gt;我在之前还有尝试给 Paddle 开发一个 &lt;a href=&quot;https://peps.python.org/pep-0561/&quot;&gt;PEP 561&lt;/a&gt; 中描述的 &lt;a href=&quot;https://github.com/cattidea/paddlepaddle-stubs&quot;&gt;stub only 的 package&lt;/a&gt;，这对于 Paddle 目前缺失的类型提示也是非常有帮助的，不过这个包目前也是在开发的早期，啥时候能用我也不知道……当然，如果将来有机会我是希望 Paddle 内部能直接集成类型提示的，这样不仅能够提供最好的类型提示效果，而且也能为 Paddle 开发者提供类型提示和验证效果，大大减少一些类型错误的发生。&lt;/p&gt;
&lt;h2&gt;结束了？&lt;/h2&gt;
&lt;p&gt;想多了诶！这才哪到哪啊，这才是《让 Paddle 更可爱》第一期《开发者体验提升计划》中的一小部分好吧～&lt;/p&gt;
&lt;p&gt;开溜～&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/PaddlePaddle/community/blob/master/pfcc/meetings/2022/2022-09-08-meeting-minutes.md#%E5%BC%80%E5%8F%91%E8%80%85%E4%BD%93%E9%AA%8C%E6%8F%90%E5%8D%87%E8%AE%A1%E5%88%92python-%E5%B7%A5%E5%85%B7%E9%93%BE&quot;&gt;PFCC 2022-09-08 分享内容《开发者体验提升计划——Python 工具链》&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://peps.python.org/pep-0008/&quot;&gt;PEP 8&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/ast-grep/ast-grep&quot;&gt;ast-grep&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>用 Rust 和 LLVM 写一个计算器吧～</title><link>https://nyakku.moe/posts/lets-make-a-calculator-using-rust-and-llvm/</link><guid isPermaLink="true">https://nyakku.moe/posts/lets-make-a-calculator-using-rust-and-llvm/</guid><pubDate>Fri, 21 Jan 2022 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;嘻嘻，因为可能之后要做一些编译相关的东西，所以准备先熟悉一下 LLVM 和 Rust。在 Rust 里有一个比较好用的 Rust 的 safely binding inkwell，在查找 inkwell 的示例时候找到了一个很多功能未完成的 &lt;a href=&quot;https://michael-f-bryan.github.io/calc/book/html/intro.html&quot;&gt;Rusty Calc&lt;/a&gt;，因此这次就参考它写一个简简单单的计算器吧～&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;做个什么样的计算器呢？&lt;/h2&gt;
&lt;p&gt;唔，使用编译原理的话写一个计算器实在是太简单了，毕竟计算器只有简简单单的&lt;strong&gt;表达式&lt;/strong&gt;，而没有那些复杂的&lt;strong&gt;语句&lt;/strong&gt;之类的。虽说简单，但制作一个计算器也是包括了编译的完整流程的，因此拿来练手还是挺合适的～不过重点不是这些，这次我主要的目的是熟悉下 Rust 并了解下 LLVM 的使用方式。&lt;/p&gt;
&lt;p&gt;那……要做一个什么样的计算器才合适呢？在开始之前我们首先制定一下计划：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它可以运算一些数学表达式，它包含一些常用一元和二元运算符，比如 &lt;code&gt;5 * (6 + 7) / -8&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;它可以访问一些预定义的常量，比如 &lt;code&gt;2 * PI&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;它可以使用一些预定义的函数，比如 &lt;code&gt;log(2, 4)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;我们可以为其自定义变量，不过为了简单，我们不需要从文本中专门增加这样一个语句来实现它，而是通过程序 API 在运算前调用实现，比如 &lt;code&gt;define_variable(&quot;a&quot;, 0.1)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;同样的，我们也可以通过程序里的 API 定义一些函数，比如 &lt;code&gt;define_function(&quot;add&quot;, |x, y| x + y)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以很轻松写出满足该条件的语法 BNF：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;expr ::= &amp;lt;expr&amp;gt; &quot;+&quot; &amp;lt;term&amp;gt;
      | &amp;lt;expr&amp;gt; &quot;-&quot; &amp;lt;term&amp;gt;
      | &amp;lt;term&amp;gt;
term ::=  &amp;lt;term&amp;gt; &quot;*&quot; &amp;lt;term&amp;gt;
      | &amp;lt;term&amp;gt; &quot;/&quot; &amp;lt;term&amp;gt;
      | &amp;lt;factor-with-unary-op&amp;gt;
factor-with-unary-op ::= &quot;+&quot; &amp;lt;factor-with-unary-op&amp;gt;
                     | &quot;-&quot; &amp;lt;factor-with-unary-op&amp;gt;
                     | &amp;lt;factor-with-unary-op&amp;gt; &quot;!&quot;
                     | &amp;lt;factor&amp;gt;
factor ::= &amp;lt;number&amp;gt;
      | &amp;lt;function-call&amp;gt;
      | &amp;lt;identifier&amp;gt;
      | &quot;(&quot; &amp;lt;expr&amp;gt; &quot;)&quot;
function-call ::= &amp;lt;identifier&amp;gt; &quot;(&quot; &amp;lt;arg-list&amp;gt; &quot;)&quot;
arg-list ::= &amp;lt;empty&amp;gt;
          | &amp;lt;expr&amp;gt; (&quot;,&quot; &amp;lt;expr&amp;gt;)*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里 expr 就是我们的文法开始符号了，也就是说我们只支持表达式，并通过 term 和 factor 确保乘除优先级高于加减法。为了支持最高优先级的各种一元运算符，因此中间插入了一个 factor-with-unary-op。&lt;/p&gt;
&lt;h2&gt;设计一下 AST 结构&lt;/h2&gt;
&lt;p&gt;语法已经基本完成，现在我们根据它设计一下 AST 的结构。&lt;/p&gt;
&lt;h3&gt;数字与变量&lt;/h3&gt;
&lt;p&gt;我们的语法里除了运算符里有两个终结符，分别是 number 和 identifier，我们将它们全放进 Atom 里。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#[derive(Debug, PartialEq, Clone)]
pub enum Atom {
    Ident(String),
    Number(f64),
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;运算符&lt;/h3&gt;
&lt;p&gt;我们的 Atom 之间是通过一些运算符结合在一起的，我们将这里的运算符定义为 Op，而结合后的节点定义为 Arithmetic。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#[derive(Debug, PartialEq, Clone)]
pub enum BinaryOp {
    Add,
    Sub,
    Mul,
    Div,
}

#[derive(Debug, PartialEq, Clone)]
pub struct BinaryArithmetic {
    pub op: BinaryOp,
    pub lhs: Expr,
    pub rhs: Expr,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然我们既包含一元运算又包含二元运算，但代码基本上是一致的，一元运算就不赘述啦～&lt;/p&gt;
&lt;h3&gt;函数调用&lt;/h3&gt;
&lt;p&gt;除去这些，我们还有一个 FunctionCall 结点用于表示函数调用，它包含了函数名和函数参数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#[derive(Debug, PartialEq, Clone)]
pub struct FunctionCall {
    pub name: String,
    pub args: Vec&amp;lt;Expr&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;表达式结点&lt;/h3&gt;
&lt;p&gt;当然，最后别忘了我们的顶层表达式结点 Expr&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#[derive(Debug, PartialEq, Clone)]
pub enum Expr {
    BinaryArithmetic(Box&amp;lt;BinaryArithmetic&amp;gt;),
    UnaryArithmetic(Box&amp;lt;UnaryArithmetic&amp;gt;),
    Atom(Atom),
    FunctionCall(FunctionCall),
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;为了方便，我们为各个结点都实现 &lt;code&gt;Into&amp;lt;Expr&amp;gt;&lt;/code&gt; 这一 trait，并为需要的结点实现自己的工厂函数 new&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;impl BinaryArithmetic {
    pub fn new(op: BinaryOp, lhs: Expr, rhs: Expr) -&amp;gt; Self {
        BinaryArithmetic { op, lhs, rhs }
    }
}

impl Into&amp;lt;Expr&amp;gt; for BinaryArithmetic {
    fn into(self) -&amp;gt; Expr {
        Expr::BinaryArithmetic(Box::new(self))
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;用 peg 同时完成词法、语法分析&lt;/h2&gt;
&lt;p&gt;下面我们便开始编写我们的计算器吧～让我想想，编译需要哪些步骤来着？词法分析、语法分析、语义分析、中间代码生成……啊……虽说手写个递归下降分析器也是分分钟的事，但总归还是麻烦，需要写大量重复的代码。而且手写递归下降的话总归还是要面临左递归和左公共因子，所以文法还是需要稍微修改下，可读性可能会因此而降低许多……&lt;/p&gt;
&lt;p&gt;嘛，为了解决这些问题，我去找了些 Rust 里的相关 crate，最终决定使用 peg 来做词法、语法分析。&lt;/p&gt;
&lt;p&gt;至于为什么用 peg 嘛，主要是它可以直接利用宏直接嵌入在代码里，通过宏自动展开成 rust 代码，而不需要额外编译，另外直接嵌入代码带来最大的优势就是可以实时代码高亮和类型提示。再就是由于 peg 以 PEG 方式解析，因此可以在不改变文法的情况下写左递归和含有左公共表达式的文法。&lt;/p&gt;
&lt;p&gt;让我们对照着之前写的 BNF，写一个 peg 的 parser ～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;peg::parser! {
    pub grammar calc_parser() for str {
        use super::Expr;

        #[cache_left_rec]
        pub rule expr() -&amp;gt; Expr
            = a:expr() _ &quot;+&quot; _ b:term() { BinaryArithmetic::new(BinaryOp::Add, a, b).into() }
            / a:expr() _ &quot;-&quot; _ b:term() { BinaryArithmetic::new(BinaryOp::Sub, a, b).into() }
            / term()

        #[cache_left_rec]
        pub rule term() -&amp;gt; Expr
            = a:term() _ &quot;*&quot; _ b:factor_with_unary_op() { BinaryArithmetic::new(BinaryOp::Mul, a, b).into() }
            / a:term() _ &quot;/&quot; _ b:factor_with_unary_op() { BinaryArithmetic::new(BinaryOp::Div, a, b).into() }
            / factor_with_unary_op()

        #[cache_left_rec]
        pub rule factor_with_unary_op() -&amp;gt; Expr
            = &quot;+&quot; _ a:factor_with_unary_op() { UnaryArithmetic::new(UnaryOp::Pos, a).into() }
            / &quot;-&quot; _ a:factor_with_unary_op() { UnaryArithmetic::new(UnaryOp::Neg, a).into() }
            / a:factor_with_unary_op() &quot;!&quot; { UnaryArithmetic::new(UnaryOp::Fac, a).into() }
            / factor()

        #[cache]
        pub rule factor() -&amp;gt; Expr
            = number()
            / function_call()
            / identifier()
            / &quot;(&quot; _ e:expr() _ &quot;)&quot; { e }

        pub rule function_call() -&amp;gt; Expr
            = id:identifier() _ v:bracketed(&amp;lt;commasep(&amp;lt;expr()&amp;gt;)&amp;gt;) {
                FunctionCall::new (
                    if let Expr::Atom(Atom::Ident(x)) = id { x } else { &quot;&quot;.to_owned() },
                    v
                ).into()
            }

        pub rule number() -&amp;gt; Expr
            = n:$(&quot;-&quot;? (&quot;0&quot; / [&apos;1&apos;..=&apos;9&apos;][&apos;0&apos;..=&apos;9&apos;]*) (&quot;.&quot; [&apos;0&apos;..=&apos;9&apos;]+)?) { Atom::Number(n.parse::&amp;lt;f64&amp;gt;().unwrap()).into() }

        pub rule identifier() -&amp;gt; Expr
            = id:$([&apos;a&apos;..=&apos;z&apos; | &apos;A&apos;..=&apos;Z&apos; | &apos;_&apos;] [&apos;a&apos;..=&apos;z&apos; | &apos;A&apos;..=&apos;Z&apos; | &apos;0&apos;..=&apos;9&apos; | &apos;_&apos;]*) { Atom::Ident(id.to_owned()).into() }

        rule commasep&amp;lt;T&amp;gt;(x: rule&amp;lt;T&amp;gt;) -&amp;gt; Vec&amp;lt;T&amp;gt; = v:(x() ** ( _ &quot;,&quot; _ ) ) &quot;,&quot;? { v }
        rule bracketed&amp;lt;T&amp;gt;(x: rule&amp;lt;T&amp;gt;) -&amp;gt; T = &quot;(&quot; _  v:x() _ &quot;)&quot; { v }
        rule _ = &quot; &quot;*
        rule __ = (&quot; &quot; / &quot;\n&quot; / &quot;\r&quot;)*
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;emm，和原来的 BNF 基本没有区别嘛，也就多了些生成 AST 的代码。&lt;/p&gt;
&lt;p&gt;这样，我们通过 &lt;code&gt;calc_parser::expr&lt;/code&gt; 就可以将字符串解析为一棵 AST 了喔～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;assert_eq!(
   calc_parser::expr(&quot;1 + 9 / 10&quot;),
   Ok(BinaryArithmetic::new(
         BinaryOp::Add,
         Atom::Number(1 as f64).into(),
         BinaryArithmetic::new(
            BinaryOp::Div,
            Atom::Number(9 as f64).into(),
            Atom::Number(10 as f64).into(),
         )
         .into()
   )
   .into())
);
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;为 AST 实现 visitor&lt;/h2&gt;
&lt;p&gt;唔，既然已经得到一棵 AST 了，理所当然我们首先会想如何去遍历它，啊……当然遍历方法是递归啦，其实问题是我们如何去组织这个遍历的代码～&lt;/p&gt;
&lt;p&gt;比如我们稍后对各个结点进行 print、check、compile 等等操作，啊这显而易见嘛，既然大家都需要实现这三个函数，那么我们让他们都实现同一个 trait 就好了，这个 trait 要求所有结点都实现这三个函数就 OK 了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/lets-make-a-calculator-using-rust-and-llvm/visitor-01.drawio.png&quot; alt=&quot;visitor-01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;emmm，我们最后实现的代码可能会像上图这样。唔，这样做倒确实可以完成我们的需求啦，但是这样做造成了相同逻辑代码分散在不同的结构体中，所以无论是实现新的逻辑还是修改现有逻辑，我们都得同时修改多个文件……&lt;/p&gt;
&lt;p&gt;所以说这种代码组织方式在这里并不是很合适啦，那我们稍微改一下，把每个逻辑放在一起，我们将每个逻辑的集合体称为 Visitor，它将会实现 visit 各种 Node 的方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/lets-make-a-calculator-using-rust-and-llvm/visitor-02.drawio.png&quot; alt=&quot;visitor-02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;就像上图这样，我们的代码是不是看起来会好很多呢？&lt;/p&gt;
&lt;p&gt;那么对于我们的代码，如何实现这样一个 Visitor 也是显而易见了～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub trait Visitor&amp;lt;T&amp;gt; {
    fn visit_expr(&amp;amp;mut self, e: &amp;amp;Expr) -&amp;gt; T;
    fn visit_unary(&amp;amp;mut self, u: &amp;amp;UnaryArithmetic) -&amp;gt; T;
    fn visit_binary(&amp;amp;mut self, b: &amp;amp;BinaryArithmetic) -&amp;gt; T;
    fn visit_function(&amp;amp;mut self, f: &amp;amp;FunctionCall) -&amp;gt; T;
    fn visit_atom(&amp;amp;mut self, a: &amp;amp;Atom) -&amp;gt; T;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们实现一个简单的能够帮我们打印树状结构 PrettyPrinter 吧～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub struct PrettyPrinter {
    indent_level: u32,
    indent: u32,
}

impl PrettyPrinter {
    pub fn new(indent: u32) -&amp;gt; Self {
        PrettyPrinter {
            indent_level: 0,
            indent,
        }
    }

    fn get_indent(&amp;amp;self) -&amp;gt; usize {
        (self.indent_level * self.indent) as usize
    }
}

impl Visitor&amp;lt;()&amp;gt; for PrettyPrinter {
    fn visit_expr(&amp;amp;mut self, e: &amp;amp;Expr) {
        let indent = &quot; &quot;.repeat(self.get_indent());
        println!(&quot;{indent}Expr&quot;);
        self.indent_level += 1;
        match e {
            Expr::UnaryArithmetic(ref u) =&amp;gt; self.visit_unary(u),
            Expr::BinaryArithmetic(ref b) =&amp;gt; self.visit_binary(b),
            Expr::FunctionCall(ref f) =&amp;gt; self.visit_function(f),
            Expr::Atom(ref a) =&amp;gt; self.visit_atom(a),
        }
        self.indent_level -= 1;
    }

    fn visit_unary(&amp;amp;mut self, u: &amp;amp;UnaryArithmetic) {
        let indent = &quot; &quot;.repeat(self.get_indent());
        match u.op {
            UnaryOp::Pos =&amp;gt; println!(&quot;{indent}Pos&quot;),
            UnaryOp::Neg =&amp;gt; println!(&quot;{indent}Neg&quot;),
            UnaryOp::Fac =&amp;gt; println!(&quot;{indent}Fac&quot;),
        }
        println!(&quot;{indent}Unary&quot;);
        self.indent_level += 1;
        self.visit_expr(&amp;amp;u.value);
        self.indent_level -= 1;
    }

    fn visit_binary(&amp;amp;mut self, b: &amp;amp;BinaryArithmetic) {
        let indent = &quot; &quot;.repeat(self.get_indent());
        match b.op {
            BinaryOp::Add =&amp;gt; println!(&quot;{indent}Add&quot;),
            BinaryOp::Sub =&amp;gt; println!(&quot;{indent}Sub&quot;),
            BinaryOp::Mul =&amp;gt; println!(&quot;{indent}Mul&quot;),
            BinaryOp::Div =&amp;gt; println!(&quot;{indent}Div&quot;),
        }
        self.indent_level += 1;
        self.visit_expr(&amp;amp;b.lhs);
        self.visit_expr(&amp;amp;b.rhs);
        self.indent_level -= 1;
    }

    fn visit_function(&amp;amp;mut self, f: &amp;amp;FunctionCall) {
        let indent = &quot; &quot;.repeat(self.get_indent());
        let func_name = &amp;amp;f.name;
        println!(&quot;{indent}Function {func_name}&quot;);
        self.indent_level += 1;
        for arg in &amp;amp;f.args {
            self.visit_expr(arg);
        }
        self.indent_level -= 1;
    }

    fn visit_atom(&amp;amp;mut self, a: &amp;amp;Atom) {
        let indent = &quot; &quot;.repeat(self.get_indent());
        match a {
            Atom::Ident(ref id) =&amp;gt; println!(&quot;{indent}Identifier {id}&quot;),
            Atom::Number(ref n) =&amp;gt; println!(&quot;{indent}Number {n}&quot;),
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;嗯，就是这么简单啦，这样我们就可以通过 &lt;code&gt;PrettyPrinter::new(2).visit_expr(ast)&lt;/code&gt; 来打印一棵 AST 了～&lt;/p&gt;
&lt;p&gt;当然，我们接下来的 Visitor 和这处理方式很相似，其实我们现在距离结束已经非常近啦～&lt;/p&gt;
&lt;h2&gt;简简单单解释器&lt;/h2&gt;
&lt;p&gt;我们有了 AST，也知道如何去遍历它，那么我们就随时可以求得它的结果啦～&lt;/p&gt;
&lt;p&gt;也就是说，我们可以直接针对 AST 通过 rust 代码解释执行，就直接得到结果啦～&lt;/p&gt;
&lt;h3&gt;小小符号表&lt;/h3&gt;
&lt;p&gt;这其实很简单，其本身没什么可说的，但值得注意的是我们可能需要一个符号表用来存放变量相关信息，由于我们的变量都是事先已知的常量，所以符号表里直接存放对应的值就好。同样的，由于我们的变量只能预先定义，所以也不需要考虑变量作用域的问题，都看作全局变量就好。所以我们的符号表实现起来是非常简单的～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;use std::collections::HashMap;

#[derive(Debug)]
pub struct SymbolTable&amp;lt;T&amp;gt; {
    map: HashMap&amp;lt;String, T&amp;gt;,
}

#[derive(Debug, PartialEq)]
pub enum SymbolError {
    ReDefinition,
    UnDefinition,
}

impl&amp;lt;T&amp;gt; SymbolTable&amp;lt;T&amp;gt;
where
    T: Copy,
{
    pub fn new() -&amp;gt; Self {
        SymbolTable {
            map: HashMap::new(),
        }
    }

    pub fn define(&amp;amp;mut self, name: &amp;amp;String, value: T) -&amp;gt; Result&amp;lt;(), SymbolError&amp;gt; {
        if self.map.contains_key(name) {
            return Err(SymbolError::ReDefinition);
        }
        self.map.insert(name.clone(), value);
        Ok(())
    }

    pub fn get(&amp;amp;mut self, name: &amp;amp;String) -&amp;gt; Result&amp;lt;T, SymbolError&amp;gt; {
        if !self.map.contains_key(name) {
            return Err(SymbolError::UnDefinition);
        }
        Ok(*self.map.get(name).unwrap())
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;开始解释吧～&lt;/h3&gt;
&lt;p&gt;现在我们来实现这个简单的解释器吧～&lt;/p&gt;
&lt;p&gt;不过这里实现相对于解释器，其实更像是编译时的常量折叠，因为我们所有叶子结点都是常量，所以常量折叠后就是我们需要的计算结果，但把它看作是针对于 AST 的解释器其实也是无伤大雅的～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub type Func&amp;lt;T&amp;gt; = fn(Vec&amp;lt;T&amp;gt;) -&amp;gt; T;

#[derive(Debug)]
pub struct Calculator {
    variables: SymbolTable&amp;lt;f64&amp;gt;,
    functions: SymbolTable&amp;lt;Func&amp;lt;f64&amp;gt;&amp;gt;,
    operand_stack: Vec&amp;lt;f64&amp;gt;,
}

#[derive(Debug)]
pub enum CalculatorError {
    StackEmpty,
    StackNotEmpty,
}

impl Calculator {
    pub fn new() -&amp;gt; Self {
        Calculator {
            variables: SymbolTable::new(),
            functions: SymbolTable::new(),
            operand_stack: Vec::new(),
        }
    }

    pub fn result(&amp;amp;mut self) -&amp;gt; Result&amp;lt;f64, CalculatorError&amp;gt; {
        let value = match self.operand_stack.pop() {
            Some(value) =&amp;gt; Ok(value),
            None =&amp;gt; Err(CalculatorError::StackEmpty),
        };
        if !self.operand_stack.is_empty() {
            return Err(CalculatorError::StackNotEmpty);
        }
        value
    }
}

impl Visitor&amp;lt;()&amp;gt; for Calculator {
    fn visit_expr(&amp;amp;mut self, e: &amp;amp;Expr) {
        match e {
            Expr::UnaryArithmetic(ref u) =&amp;gt; self.visit_unary(u),
            Expr::BinaryArithmetic(ref b) =&amp;gt; self.visit_binary(b),
            Expr::FunctionCall(ref f) =&amp;gt; self.visit_function(f),
            Expr::Atom(ref a) =&amp;gt; self.visit_atom(a),
        }
    }

    fn visit_unary(&amp;amp;mut self, u: &amp;amp;UnaryArithmetic) {
        self.visit_expr(&amp;amp;u.value);
        match u.op {
            UnaryOp::Pos =&amp;gt; (),
            UnaryOp::Neg =&amp;gt; {
                let value = self.operand_stack.pop();
                self.operand_stack.push(-value.unwrap());
            }
            UnaryOp::Fac =&amp;gt; {
                let value = self.operand_stack.pop();
                self.operand_stack
                    .push(factorial(value.unwrap() as u64) as f64);
            }
        }
    }

    fn visit_binary(&amp;amp;mut self, b: &amp;amp;BinaryArithmetic) {
        self.visit_expr(&amp;amp;b.lhs);
        self.visit_expr(&amp;amp;b.rhs);

        let rhs = self.operand_stack.pop().unwrap();
        let lhs = self.operand_stack.pop().unwrap();
        match b.op {
            BinaryOp::Add =&amp;gt; self.operand_stack.push(lhs + rhs),
            BinaryOp::Sub =&amp;gt; self.operand_stack.push(lhs - rhs),
            BinaryOp::Mul =&amp;gt; self.operand_stack.push(lhs * rhs),
            BinaryOp::Div =&amp;gt; self.operand_stack.push(lhs / rhs),
        }
    }

    fn visit_function(&amp;amp;mut self, f: &amp;amp;FunctionCall) {
        let argc = f.args.len();
        for arg in &amp;amp;f.args {
            self.visit_expr(arg);
        }
        let func_name = &amp;amp;f.name;
        let func = self.functions.get(func_name).unwrap();
        let mut argv = Vec::new();
        for _ in 0..argc {
            argv.push(self.operand_stack.pop().unwrap());
        }
        argv.reverse();
        self.operand_stack.push(func(argv));
    }

    fn visit_atom(&amp;amp;mut self, a: &amp;amp;Atom) {
        match a {
            Atom::Ident(ref id) =&amp;gt; self.operand_stack.push(self.variables.get(id).unwrap()),
            Atom::Number(ref n) =&amp;gt; self.operand_stack.push(*n),
        }
    }
}

fn factorial(num: u64) -&amp;gt; u64 {
    match (1..=num).reduce(|accum, item| accum * item) {
        Some(x) =&amp;gt; x,
        None =&amp;gt; num,
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里我们通过一个操作数栈来存放计算结果，每次计算得到结果就进行压栈，在遇到运算符时从栈顶取得操作数运算后重新压栈。&lt;/p&gt;
&lt;p&gt;当然不用操作数栈直接使用返回值也是可以的，但那太简单啦，就不试啦～（我才不会承认当时没想到利用泛型让 Vistor 实现不同类型的返回值呜呜）&lt;/p&gt;
&lt;p&gt;唔，最后实现一下我们当初设计的自定义变量和函数 API ～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;impl Calculator {
    pub fn define_variable(&amp;amp;mut self, name: &amp;amp;String, value: f64) -&amp;gt; Result&amp;lt;(), SymbolError&amp;gt; {
        self.variables.define(name, value)
    }

    pub fn define_function(&amp;amp;mut self, name: &amp;amp;String, value: Func&amp;lt;f64&amp;gt;) -&amp;gt; Result&amp;lt;(), SymbolError&amp;gt; {
        self.functions.define(name, value)
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在我们就可以通过下面的方式来自定义变量和函数了～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;calculator.define_variable(&amp;amp;&quot;a&quot;.into(), 222.0).unwrap();
calculator
    .define_function(&amp;amp;&quot;mul&quot;.into(), |args| args[0] * args[1])
    .unwrap();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;嗯，这样我们就可以完成很多很多事情啦～比如预先定义 PI 的值，再比如预先定义 log、sin、cos 等数学函数，这样我们就可以计算各种各样的结果啦～&lt;/p&gt;
&lt;p&gt;我们把代码组装一下，现在就可以完成一个非常不错的计算器啦～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn Error&amp;gt;&amp;gt; {
   let input = &quot;log(2, 8) - sin(2 * PI)&quot;;
   match calc_parser::expr(&amp;amp;input) {
      Ok(parsed_input) =&amp;gt; {
         let mut calculator = Calculator::new();
         calculator.preset().unwrap();
         calculator.define_variable(&amp;amp;&quot;PI&quot;.into(), consts::PI).unwrap();
         calculator.define_function(&amp;amp;&quot;log&quot;.into(), |argv| f64::log(argv[1], argv[0])).unwrap();
         calculator.visit_expr(&amp;amp;parsed_input);
         let result = calculator.result().unwrap();
         println!(&quot;Calculator Interpret result: {result}&quot;);
      }
      Err(e) =&amp;gt; {
            let (err_line, err_col) = (e.location.line, e.location.column);
            let error_line = input.split(&quot;\n&quot;).collect::&amp;lt;Vec&amp;lt;_&amp;gt;&amp;gt;()[err_line - 1];
            println!(
               &quot;Unexpected char `{}` at line {}, column {}:&quot;,
               error_line.chars().nth(err_col - 1).unwrap(),
               err_line,
               err_col
            );
            println!(&quot;{}&quot;, error_line);
            println!(&quot;{}{}&quot;, &quot; &quot;.repeat(err_col - 1), &quot;^&quot;);
            println!(&quot;Excepct chars: {:?}&quot;, e.expected);
            Ok(())
      }
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面代码最后应当能够计算得到正确的结果 &lt;code&gt;3.0000000000000004&lt;/code&gt;～&lt;/p&gt;
&lt;p&gt;啊，完事啦完事啦～我们这就做完一个计算器啦～～～&lt;/p&gt;
&lt;p&gt;诶？等会，好像忘了点东西啊，我们的主角 LLVM 呢？？？&lt;/p&gt;
&lt;h2&gt;用 LLVM 来 JIT 编译一下吧～&lt;/h2&gt;
&lt;p&gt;当然，如果只是一个计算器的话，解释执行完全足够了，编译完全是没必要的，但目的是练手嘛～所以 LLVM 这时候就要强行登场啦～&lt;/p&gt;
&lt;p&gt;不过此前我对 LLVM 是基本不了解的，所以代码基本都是直接参考的 inkwell 里的 example 和 Rusty Calc，剩下的是看文档猜的……&lt;/p&gt;
&lt;h3&gt;inkwell 的基本结构&lt;/h3&gt;
&lt;p&gt;首先我们先把一些基本的属性确定下来，比如 LLVM 里的 context、module、builder 什么的。然后，我们实现一个只能计算数字常量最简 JIT 编译器，这个直接参考 inkwell 的 JIT example 就可以写出来～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub type CalcMain = unsafe extern &quot;C&quot; fn() -&amp;gt; f64;
pub const CALC_ENTRYPOINT: &amp;amp;str = &quot;calc_main&quot;;

#[derive(Debug)]
pub struct CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    context: &amp;amp;&apos;ctx Context,
    module: Module&amp;lt;&apos;ctx&amp;gt;,
    builder: Builder&amp;lt;&apos;ctx&amp;gt;,
    execution_engine: ExecutionEngine&amp;lt;&apos;ctx&amp;gt;,
}

impl&amp;lt;&apos;ctx&amp;gt; CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    pub fn new(context: &amp;amp;&apos;ctx Context) -&amp;gt; Self {
        let module = context.create_module(&quot;calc&quot;);
        let execution_engine = module
            .create_jit_execution_engine(OptimizationLevel::None)
            .unwrap();
        CalculatorJIT {
            context: &amp;amp;context,
            module,
            builder: context.create_builder(),
            execution_engine,
        }
    }

    #[inline]
    fn double(&amp;amp;self) -&amp;gt; FloatType&amp;lt;&apos;ctx&amp;gt; {
        self.context.f64_type()
    }

    pub fn compile(&amp;amp;mut self, ast: &amp;amp;Expr) -&amp;gt; Option&amp;lt;JitFunction&amp;lt;CalcMain&amp;gt;&amp;gt; {
        let sig = self.double().fn_type(&amp;amp;[], false);
        let func = self.module.add_function(CALC_ENTRYPOINT, sig, None);
        let basic_block = self.context.append_basic_block(func, &quot;entry&quot;);

        self.builder.position_at_end(basic_block);

        let ret = self.visit_expr(ast);
        self.builder.build_return(Some(&amp;amp;ret));

        unsafe { self.execution_engine.get_function(CALC_ENTRYPOINT).ok() }
    }
}

impl&amp;lt;&apos;ctx&amp;gt; Visitor&amp;lt;FloatValue&amp;lt;&apos;ctx&amp;gt;&amp;gt; for CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    fn visit_expr(&amp;amp;mut self, e: &amp;amp;Expr) -&amp;gt; FloatValue&amp;lt;&apos;ctx&amp;gt; {
        match e {
            Expr::UnaryArithmetic(ref u) =&amp;gt; self.visit_unary(u),
            Expr::BinaryArithmetic(ref b) =&amp;gt; self.visit_binary(b),
            Expr::FunctionCall(ref f) =&amp;gt; self.visit_function(f),
            Expr::Atom(ref a) =&amp;gt; self.visit_atom(a),
        }
    }

    fn visit_atom(&amp;amp;mut self, a: &amp;amp;Atom) -&amp;gt; FloatValue&amp;lt;&apos;ctx&amp;gt; {
        match a {
            Atom::Ident(ref id) =&amp;gt; unimplemented!(),
            Atom::Number(ref n) =&amp;gt; self.double().const_float(*n),
        }
    }
}

fn main() -&amp;gt; Result&amp;lt;(), Box&amp;lt;dyn Error&amp;gt;&amp;gt; {
    let input = &quot;1.1&quot;;
    match calc_parser::expr(&amp;amp;input) {
        Ok(parsed_input) =&amp;gt; {
            let context = Context::create();
            let mut calculator_jit = CalculatorJIT::new(&amp;amp;context);
            let calc_main = calculator_jit.compile(&amp;amp;parsed_input).unwrap();
            let result = unsafe { calc_main.call() };

            println!(&quot;JIT compile result: &quot;);
        }
        Err(e) =&amp;gt; unimplemented!(),
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不出意外，上面的代码是可以直接计算得到结果 1.1 的。&lt;/p&gt;
&lt;p&gt;那我们 JIT 编译到底有什么用呢？其实这里我们编译得到的 calc_main 以后是可以重复调用的，不必每次都从 AST 解释计算。&lt;/p&gt;
&lt;h3&gt;用 builder 构建运算&lt;/h3&gt;
&lt;p&gt;下面我们逐渐完善计算相关的代码&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;impl&amp;lt;&apos;ctx&amp;gt; Visitor&amp;lt;FloatValue&amp;lt;&apos;ctx&amp;gt;&amp;gt; for CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    fn visit_unary(&amp;amp;mut self, u: &amp;amp;UnaryArithmetic) -&amp;gt; FloatValue&amp;lt;&apos;ctx&amp;gt; {
        let value = self.visit_expr(&amp;amp;u.value);

        match u.op {
            UnaryOp::Pos =&amp;gt; value,
            UnaryOp::Neg =&amp;gt; self.builder.build_float_neg(value, &quot;neg&quot;),
            UnaryOp::Fac =&amp;gt; unimplemented!(),
        }
    }

    fn visit_binary(&amp;amp;mut self, b: &amp;amp;BinaryArithmetic) -&amp;gt; FloatValue&amp;lt;&apos;ctx&amp;gt; {
        let lhs = self.visit_expr(&amp;amp;b.lhs);
        let rhs = self.visit_expr(&amp;amp;b.rhs);
        match b.op {
            BinaryOp::Add =&amp;gt; self.builder.build_float_add(lhs, rhs, &quot;add&quot;),
            BinaryOp::Sub =&amp;gt; self.builder.build_float_sub(lhs, rhs, &quot;sub&quot;),
            BinaryOp::Mul =&amp;gt; self.builder.build_float_mul(lhs, rhs, &quot;mul&quot;),
            BinaryOp::Div =&amp;gt; self.builder.build_float_div(lhs, rhs, &quot;div&quot;),
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一元运算二元运算都很简单，直接通过 builder 里的操作构建相关的代码就好，不过阶乘这样复杂的操作暂时是没办法完成的。&lt;/p&gt;
&lt;p&gt;嗯，现在我们应该能做一些复杂的运算了，比如 &lt;code&gt;1 * 2 / -4&lt;/code&gt; 等等。&lt;/p&gt;
&lt;h3&gt;定义全局变量&lt;/h3&gt;
&lt;p&gt;下面我们支持一下变量吧，由于我们的变量都是预先定义好的，因此可看作全局变量，其地址可存在符号表之中，&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#[derive(Debug)]
pub struct CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    // 增加变量符号表属性
    variables: SymbolTable&amp;lt;PointerValue&amp;lt;&apos;ctx&amp;gt;&amp;gt;,
}

impl&amp;lt;&apos;ctx&amp;gt; CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    pub fn define_variable(&amp;amp;mut self, name: &amp;amp;String, value: f64) -&amp;gt; Result&amp;lt;(), SymbolError&amp;gt; {
        let var = self
            .module
            .add_global(self.double(), Some(AddressSpace::Global), name);

        // 赋初值
        let initial_value = self.double().const_float(value);
        var.set_initializer(&amp;amp;initial_value);

        // 获取地址
        let alloca = var.as_pointer_value();
        self.variables.define(name, alloca)?;
        Ok(())
    }

    fn get_variable(&amp;amp;mut self, name: &amp;amp;String) -&amp;gt; Result&amp;lt;FloatValue&amp;lt;&apos;ctx&amp;gt;, SymbolError&amp;gt; {
        // 直接从符号表取得地址
        let alloca = self.variables.get(name)?;
        let var = self
            .builder
            .build_load(alloca, name.as_str())
            .into_float_value();

        Ok(var)
    }
}

impl&amp;lt;&apos;ctx&amp;gt; Visitor&amp;lt;FloatValue&amp;lt;&apos;ctx&amp;gt;&amp;gt; for CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    fn visit_atom(&amp;amp;mut self, a: &amp;amp;Atom) -&amp;gt; FloatValue&amp;lt;&apos;ctx&amp;gt; {
        match a {
            // 增加变量的处理
            Atom::Ident(ref id) =&amp;gt; self.get_variable(id).unwrap(),
            Atom::Number(ref n) =&amp;gt; self.double().const_float(*n),
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;定义函数&lt;/h3&gt;
&lt;p&gt;函数的定义也很相似，这里同样为了方便定义函数，也使用闭包的形式，不过为了方便闭包里构建各种操作，所以把 builder 也一并传入。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pub type FuncLLVM&amp;lt;&apos;a, T&amp;gt; = fn(Vec&amp;lt;T&amp;gt;, &amp;amp;Builder&amp;lt;&apos;a&amp;gt;) -&amp;gt; T;

impl&amp;lt;&apos;ctx&amp;gt; CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    pub fn define_function(
        &amp;amp;mut self,
        name: &amp;amp;String,
        argc: usize,
        func: FuncLLVM&amp;lt;&apos;ctx, FloatValue&amp;lt;&apos;ctx&amp;gt;&amp;gt;,
    ) -&amp;gt; Result&amp;lt;(), SymbolError&amp;gt; {
        let ret_type = self.double();
        let args_types = std::iter::repeat(ret_type)
            .take(argc)
            .map(|f| f.into())
            .collect::&amp;lt;Vec&amp;lt;BasicMetadataTypeEnum&amp;gt;&amp;gt;();
        let args_types = args_types.as_slice();

        let fn_type = self.double().fn_type(args_types, false);
        let fn_val = self.module.add_function(name.as_str(), fn_type, None);
        let entry = self.context.append_basic_block(fn_val, &quot;entry&quot;);
        self.builder.position_at_end(entry);

        let mut args = Vec::with_capacity(argc);
        for i in 0..argc as u32 {
            args.push(fn_val.get_nth_param(i).unwrap().into_float_value())
        }

        let ret_val = func(args, &amp;amp;self.builder);

        self.builder.build_return(Some(&amp;amp;ret_val));

        Ok(())
    }

    pub fn get_function(&amp;amp;mut self, name: &amp;amp;String) -&amp;gt; Result&amp;lt;FunctionValue&amp;lt;&apos;ctx&amp;gt;, SymbolError&amp;gt; {
        match self.module.get_function(name) {
            Some(func) =&amp;gt; Ok(func),
            None =&amp;gt; Err(SymbolError::UnDefinition),
        }
    }
}

impl&amp;lt;&apos;ctx&amp;gt; Visitor&amp;lt;FloatValue&amp;lt;&apos;ctx&amp;gt;&amp;gt; for CalculatorJIT&amp;lt;&apos;ctx&amp;gt; {
    fn visit_function(&amp;amp;mut self, f: &amp;amp;FunctionCall) -&amp;gt; FloatValue&amp;lt;&apos;ctx&amp;gt; {
        let argc = f.args.len();
        let func = self.get_function(&amp;amp;f.name).unwrap();
        let mut argv = Vec::with_capacity(argc);

        for i in 0..argc {
            argv.push(self.visit_expr(&amp;amp;f.args[i]))
        }

        let argsv: Vec&amp;lt;BasicMetadataValueEnum&amp;gt; =
            argv.iter().by_ref().map(|&amp;amp;val| val.into()).collect();

        let ret_val = self
            .builder
            .build_call(func, argsv.as_slice(), &quot;tmp&quot;)
            .try_as_basic_value()
            .left()
            .unwrap();

        ret_val.into_float_value()
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;嘛，虽然看着挺麻烦的，不过参考 example 还是很容易写出来的～&lt;/p&gt;
&lt;p&gt;现在我们就可以自己定义常量和函数啦～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;calculator_jit.define_variable(&amp;amp;&quot;a&quot;.into(), 222.0).unwrap();
calculator_jit
    .define_function(&amp;amp;&quot;mul&quot;.into(), 2, |args, builder| {
        let a = args[0];
        let b = args[1];
        builder.build_float_mul(a, b, &quot;mul&quot;)
    })
    .unwrap();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不过实现 log、sin 这种函数还是不太行啦，只能实现一些非常简单的函数。&lt;/p&gt;
&lt;p&gt;总算是完成啦，到此为止我们不仅快速实现了一个解释型的计算器，还实现了一个与其基本功能一致的 JIT 编译型的计算器～&lt;/p&gt;
&lt;p&gt;代码就扔到 &lt;a href=&quot;https://github.com/ShigureLab/rcalc&quot;&gt;ShigureLab/rcalc&lt;/a&gt; 咯～溜了溜了～&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://michael-f-bryan.github.io/calc/book/html/intro.html&quot;&gt;Rusty Calc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/TheDan64/inkwell&quot;&gt;inkwell examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/RReverser/building-fast-interpreters-in-rust&quot;&gt;building-fast-interpreters-in-rust&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>Proxy 以及 Vue3 中的响应式</title><link>https://nyakku.moe/posts/proxy-and-vue3-reactivity/</link><guid isPermaLink="true">https://nyakku.moe/posts/proxy-and-vue3-reactivity/</guid><pubDate>Wed, 10 Feb 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;呜，前两天看完对象那一章之后就开始看 Proxy 那一章了，虽然不难，但总觉得没啥用，难道会有人拿着代理去操作一番嘛？直接操作源数据不香嘛？所以我看了一半就溜了……结果这两天就发现 Vue3 的响应式就是通过 Proxy 实现的……&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;Proxy 与 Reflect&lt;/h2&gt;
&lt;h3&gt;Proxy 是个什么鬼&lt;/h3&gt;
&lt;p&gt;Proxy 就是代理啦，我们可以为一个对象创建一个代理对象，之后通过这个代理对象也可以访问目标对象了。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const target = {
   name: &apos;foo&apos;,
   age: 10,
   friend: {
      name: &apos;bar&apos;,
      age: 11,
   },
}

const proxy = new Proxy(target, {})
console.log(proxy.name) // &apos;foo&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里的 proxy 是以 target 为目标对象创建出来的代理对象，因此访问 proxy 就相当于访问 target 了，但……这有什么用嘛……别急，有用的在第二个参数。&lt;/p&gt;
&lt;p&gt;Proxy 构造函数第二个位置接受的是一个 ProxyHandler，以此修改通过 proxy 访问时的行为。&lt;/p&gt;
&lt;p&gt;那么就简单举个例子吧～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const handler = {
   get(target, property, receiver) {
      console.log(`有个坏人想访问 ${property} 但被我拒绝了～`)
      return &apos;哼！才不告诉你！&apos;
   },
}

const proxy = new Proxy(target, handler)
// 有个坏人想访问 name 但被我拒绝了～
console.log(proxy.name) // &apos;哼！才不告诉你！&apos;
// 有个坏人想访问 age 但被我拒绝了～
console.log(proxy.age) // &apos;哼！才不告诉你！&apos;
console.log(target.name) // &apos;foo&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里定义了一个拥有 get 方法的 handler，也就是说我们如果通过 proxy 来访问 target 并且执行的是 &lt;code&gt;[[GET]]&lt;/code&gt; 操作的话，那么便会执行该函数。很明显，我这样定义后通过 proxy 无论访问任何属性都只能返回「哼！才不告诉你！」。当然，target 对象本身并没有改变，我们仍然可以通过直接访问到任何属性。&lt;/p&gt;
&lt;p&gt;此时代理的功能就显而易见了，它相当于为我们增加了一个操作目标对象的方式，通过该方式操作对象会被 ProxyHandler 所接管，提高了对象的扩展性。另外由于 handler 是定义在 proxy 上的，所以对目标对象是没有任何「污染」的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/proxy-and-vue3-reactivity/proxy_01.drawio.png&quot; alt=&quot;proxy_01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;嘛，这么看其实和网络代理也很像嘛，当我们开启代理时就是经由代理获取网络数据，而关闭代理则是直连目的主机～&lt;/p&gt;
&lt;h3&gt;默认行为：Reflect&lt;/h3&gt;
&lt;p&gt;唔，不过我们要如何还原 &lt;code&gt;[[GET]]&lt;/code&gt; 时的行为呢？当然不定义 get 方法就好了……那如果定义了呢？ECMAScript 中还定义了一系列 Reflect API，它们可以看作是在我们不定义时的默认行为，比如下面这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const handler = {
   get(target, property, receiver) {
      return Reflect.get(target, property, receiver)
   },
}

const proxy = new Proxy(target, handler)
console.log(proxy.name) // &apos;foo&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时再使用 get 就相当于默认行为啦，当然我们也可以这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const handler = {
   get: Reflect.get,
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于 Reflect 定义了全部默认的 Handler，所以我们甚至可以像下面这样将全部 handler 都设为默认反射行为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const proxy = new Proxy(target, Reflect)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，效果和之前是一样的。&lt;/p&gt;
&lt;p&gt;有了 Reflect API 我们就可以做更多有趣的事情了，比如像下面这样在不影响结果的情况下监听 &lt;code&gt;[[GET]]&lt;/code&gt; 事件：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const handler = {
   get(target, property, receiver) {
      console.log(`[GET] ${property} 被访问`)
      return Reflect.get(target, property, receiver)
   },
}

const proxy = new Proxy(target, handler)
// [GET] name 被访问
console.log(proxy.name) // &apos;foo&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Vue3 响应式原理浅析&lt;/h2&gt;
&lt;h3&gt;响应式基础 API —— reactive&lt;/h3&gt;
&lt;p&gt;随便打印一个 Vue3 中的 reactive 返回的对象便可以发现是一个代理，既然如此，Vue3 的响应式的实现方式其实已经很容易猜到了。&lt;/p&gt;
&lt;p&gt;从 Vue3 源码可以得知，reactive 返回的代理对象代理了 get、set、deleteProperty、has、ownKeys 五种行为。很容易写出代理的方法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const handler: ProxyHandler&amp;lt;any&amp;gt; = {
   get(target, property, receiver) {
      return Reflect.get(target, property, receiver)
   },

   set(target, property, value, receiver) {
      return Reflect.set(target, property, value, receiver)
   },

   deleteProperty(target, property) {
      return Reflect.deleteProperty(target, property)
   },

   has(target, property) {
      return Reflect.has(target, property)
   },

   ownKeys(target) {
      return Reflect.ownKeys(target)
   },
}

function reactive&amp;lt;T extends object&amp;gt;(target: T): T
function reactive(target: object) {
   return new Proxy(target, handler)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然现在这只是默认行为，我们完全可以根据需要在其中添加代码。在 Vue3 源码中，我们可以发现在 get、has、ownKeys 这些不会对数据进行改变的「读取行为」 handler 中都会调用 track 这个方法，而 set、deleteProperty 这种明显会改变数据的「写入行为」中则会调用 trigger 方法。我们先不理会它们的作用，先尝试实现一下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function trigger(target: object, type: string, key: unknown) {
   console.log(`[Trigger] 执行了 ${type} 操作，目标属性为 ${key}`)
}

function track(target: object, type: string, key: unknown) {
   console.log(`[Track] 执行了 ${type} 操作，目标属性为 ${key}`)
}

const handler: ProxyHandler&amp;lt;any&amp;gt; = {
   get(target, property, receiver) {
      track(target, &apos;GET&apos;, property)
      return Reflect.get(target, property, receiver)
   },

   set(target, property, value, receiver) {
      const res = Reflect.set(target, property, value, receiver)
      trigger(target, &apos;SET&apos;, property)
      return res
   },

   deleteProperty(target, property) {
      const res = Reflect.deleteProperty(target, property)
      trigger(target, &apos;DELETE&apos;, property)
      return res
   },

   has(target, property) {
      track(target, &apos;HAS&apos;, property)
      return Reflect.has(target, property)
   },

   ownKeys(target) {
      track(target, &apos;OWN_KEYS&apos;, &apos;&apos;)
      return Reflect.ownKeys(target)
   },
}

function reactive&amp;lt;T extends object&amp;gt;(target: T): T
function reactive(target: object) {
   return new Proxy(target, handler)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们测试一下是否能够正确触发相关函数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const target = {
   name: &apos;foo&apos;,
   age: 10,
   friend: {
      name: &apos;bar&apos;,
      age: 11,
   },
}

const proxy = reactive(target)
console.log(proxy) // { name: &quot;foo&quot;, age: 10, friend: { name: &quot;bar&quot;, age: 11 } }
proxy.friend.name = &apos;baz&apos;
// [Track] 执行了 GET 操作，目标属性为 friend
console.log(proxy) // { name: &quot;foo&quot;, age: 10, friend: { name: &quot;baz&quot;, age: 11 } }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里 &lt;code&gt;proxy.friend&lt;/code&gt; 成功地触发了 get 里的 track，但 &lt;code&gt;friend.name = &apos;baz&apos;&lt;/code&gt; 却没有触发 set 里的 trigger，归根结底，是因为 &lt;code&gt;friend&lt;/code&gt; 并不是一个 proxy，自然也就不会被经过 handler 里的 set 方法。也就是说我们现在只实现了一个浅层的响应式，也就是 shallowReactive。&lt;/p&gt;
&lt;p&gt;那么如何让深层对象也能经过代理访问呢？一种方法就是在初始化时将目标对象中所有的对象修改为代理，另外如果新 set 的值是对象的话，也需要修改为代理，以保证我们的对象中只存在对象的代理，而不存在对象本身。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const isObject = (val: unknown): val is Record&amp;lt;any, any&amp;gt; =&amp;gt; val !== null &amp;amp;&amp;amp; typeof val === &apos;object&apos;

const handler: ProxyHandler&amp;lt;any&amp;gt; = {
   get(target, property, receiver) {
      track(target, &apos;GET&apos;, property)
      return Reflect.get(target, property, receiver)
   },

   set(target, property, value, receiver) {
      // 如果新值为 object，则获取其代理再存入
      if (isObject(value)) {
         value = reactive(value)
      }
      const res = Reflect.set(target, property, value, receiver)
      trigger(target, &apos;SET&apos;, property)
      return res
   },

   deleteProperty(target, property) {
      const res = Reflect.deleteProperty(target, property)
      trigger(target, &apos;DELETE&apos;, property)
      return res
   },

   has(target, property) {
      track(target, &apos;HAS&apos;, property)
      return Reflect.has(target, property)
   },

   ownKeys(target) {
      track(target, &apos;OWN_KEYS&apos;, &apos;&apos;)
      return Reflect.ownKeys(target)
   },
}

function reactive&amp;lt;T extends object, U extends keyof T&amp;gt;(target: T): T {
   for (const [key, value] of Object.entries(target)) {
      // 将所有为对象的 value 转化为其代理后存入
      if (isObject(value)) {
         target[key as U] = reactive(value) as T[U]
      }
   }
   return new Proxy(target, handler)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;emmm，简单测试即可发现深层响应式已经能够实现了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const proxy = reactive(target)
console.log(proxy) // { name: &quot;foo&quot;, age: 10, friend: { name: &quot;bar&quot;, age: 11 } }
proxy.friend.name = &apos;baz&apos;
// [Track] 执行了 GET 操作，目标属性为 friend
// [Trigger] 执行了 SET 操作，目标属性为 name
console.log(proxy) // { name: &quot;foo&quot;, age: 10, friend: { name: &quot;baz&quot;, age: 11 } }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;但……这样真的好吗？很明显，目标对象已经被「污染」了，代理得不够彻底啊～&lt;/p&gt;
&lt;p&gt;那……要怎么做呢？我们可以发现在 &lt;code&gt;proxy.friend&lt;/code&gt; 执行时已经触发了一个 get，此后才是 set 操作，那么……我们能否在 get 上做点手脚呢？其实很简单啦，只要 get 时返回代理就好啦，这样之后的 set 也是通过代理进行操作的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const isObject = (val: unknown): val is Record&amp;lt;any, any&amp;gt; =&amp;gt; val !== null &amp;amp;&amp;amp; typeof val === &apos;object&apos;

const handler: ProxyHandler&amp;lt;any&amp;gt; = {
   get(target, property, receiver) {
      track(target, &apos;GET&apos;, property)
      const res = Reflect.get(target, property, receiver)
      // 如果值为对象，则返回其代理
      if (isObject(res)) {
         return reactive(res)
      }
      return res
   },

   set(target, property, value, receiver) {
      const res = Reflect.set(target, property, value, receiver)
      trigger(target, &apos;SET&apos;, property)
      return res
   },

   deleteProperty(target, property) {
      const res = Reflect.deleteProperty(target, property)
      trigger(target, &apos;DELETE&apos;, property)
      return res
   },

   has(target, property) {
      track(target, &apos;HAS&apos;, property)
      return Reflect.has(target, property)
   },

   ownKeys(target) {
      track(target, &apos;OWN_KEYS&apos;, &apos;&apos;)
      return Reflect.ownKeys(target)
   },
}

function reactive&amp;lt;T extends object&amp;gt;(target: T): T
function reactive(target: object) {
   return new Proxy(target, handler)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;测试结果和上面一样，也解决了刚刚的问题，但是有一个新的小小的问题：这样岂不是每次访问一个值为对象的属性都创建一个新的代理对象？&lt;/p&gt;
&lt;p&gt;通过测试发现也确实如此：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;console.log(proxy.friend === proxy.friend) // false
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，Vue3 怎么会没想到这一点？解决方法也很简单，建立一个全局对象来存储已经创建过的 proxy 即可：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const proxyMap = new WeakMap&amp;lt;any&amp;gt;()

function reactive&amp;lt;T extends object&amp;gt;(target: T): T
function reactive(target: object) {
   const existingProxy = proxyMap.get(target)
   if (existingProxy) {
      return existingProxy
   }
   const proxy = new Proxy(target, handler)
   proxyMap.set(target, proxy)
   return proxy
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里采用的是 WeakMap，也就是说在运行时执行垃圾回收之前我们都可以复用。那么再来测试一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;console.log(proxy.friend === proxy.friend) // true
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时便不必再担心产生多余的 proxy 了。&lt;/p&gt;
&lt;h3&gt;ref API&lt;/h3&gt;
&lt;p&gt;reactive API 主要是将对象转化为响应式对象，因此，即便是基本数据类型的数据，我们也完全可以通过封装成对象后再使用 reactive API 形成响应式数据。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;template&amp;gt;
   &amp;lt;button type=&quot;button&quot; @click=&quot;onClick&quot;&amp;gt;count: {{ count.value }}&amp;lt;/button&amp;gt;
&amp;lt;/template&amp;gt;

&amp;lt;script lang=&quot;ts&quot;&amp;gt;
import { reactive, defineComponent } from &apos;vue&apos;
export default defineComponent({
   setup() {
      const count = reactive({
         value: 0,
      })

      const onClick = function () {
         count.value++
      }

      return {
         count,
         onClick,
      }
   },
})
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样当然可以实现响应式啦，不过在使用的时候手动地封装对象总觉得比较麻烦，毕竟我们明明在操作一个基本数据类型，却不得不使用对象的方式来操作。&lt;/p&gt;
&lt;p&gt;为了解决这一问题，ref API 应运而生，先看下使用方法：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;template&amp;gt;
   &amp;lt;button type=&quot;button&quot; @click=&quot;onClick&quot;&amp;gt;count: {{ count }}&amp;lt;/button&amp;gt;
&amp;lt;/template&amp;gt;

&amp;lt;script lang=&quot;ts&quot;&amp;gt;
import { ref, defineComponent } from &apos;vue&apos;
export default defineComponent({
   setup() {
      const count = ref(0)

      const onClick = function () {
         count.value++
      }

      return {
         count,
         onClick,
      }
   },
})
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其实只是初始化数据时候不需要自己定义新的对象与模板中不必使用 .value 而已，在 JS 代码中操作 Ref 仍然需要通过 .value 来访问。那么这个 .value 到底能不能去掉呢？答案是不可能，因为一个基本数据类型在传参时是只传值的，因此为了响应式就必然封装成对象，既然封装成了对象，那么就不可能直接访问这个数据，只能通过一个属性来间接访问数据。当然，如果有朝一日你 JS 支持指针、引用的话，也许这是可以做到的。&lt;/p&gt;
&lt;p&gt;既然基本使用方法已经了解了，其实其实现也能够猜个差不多了，除了再次封装为一个对象交由 reactive 处理外，我们还可以封装成对象后，重写 getter 和 setter 来实现；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;interface Ref&amp;lt;T = any&amp;gt; {
   _value: T
   value: T
}

function ref&amp;lt;T&amp;gt;(initValue: T): Ref&amp;lt;T&amp;gt; {
   return {
      _value: initValue,
      get value() {
         track(this, &apos;GET&apos;, &apos;value&apos;)
         return this._value
      },
      set value(newVal) {
         this._value = newVal
         trigger(this, &apos;SET&apos;, &apos;value&apos;)
      },
   }
}

const count = ref(0)
// [Track] 执行了 GET 操作，目标属性为 value
// [Trigger] 执行了 SET 操作，目标属性为 value
console.log(++count.value) // 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，在 get 和 set 中不要忘记 track 和 trigger。这样我们在调用 &lt;code&gt;++count.value&lt;/code&gt; 时便成功地调用了 &lt;code&gt;[[GET]]&lt;/code&gt; 与 &lt;code&gt;[[SET]]&lt;/code&gt; 方法咯～～～&lt;/p&gt;
&lt;p&gt;不过这样写的话，由于所有方法都是定义在对象其本身上的，所有在创建大量这样的对象时就会造成大量的空间浪费。这个问题的解决方案嘛，当然是通过原型链解决啦，不过我们既然会用语法糖 class 了当然就直接使用 class 咯。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;interface Ref&amp;lt;T = any&amp;gt; {
   value: T
}

class RefImpl&amp;lt;T&amp;gt; {
   private _value: T

   constructor(initValue: T) {
      this._value = initValue
   }

   get value() {
      track(this, &apos;GET&apos;, &apos;value&apos;)
      return this._value
   }

   set value(newVal) {
      this._value = newVal
      trigger(this, &apos;SET&apos;, &apos;value&apos;)
   }
}

function ref&amp;lt;T&amp;gt;(value: T): Ref&amp;lt;T&amp;gt; {
   return new RefImpl(value)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;效果呢？测试结果和刚刚完全一致，不必担心～&lt;/p&gt;
&lt;h3&gt;track、trigger 以及 effect&lt;/h3&gt;
&lt;p&gt;哼，这三个东西我起初是不打算了解的，直接看源码也确实没看懂要做些什么，随手搜了一下，就全都在说 track 在收集依赖，trigger 则是触发所有依赖于此的 effect，可是 effect 是个啥啊，什么时候用啊，基本没有一篇文章说清楚的……&lt;/p&gt;
&lt;p&gt;因此，起初我其实写完 reactive 就停手了的，但是之后实在是没忍住就又去查了一下，算是大概了解了他们的作用了……吧？&lt;/p&gt;
&lt;p&gt;为了更好地理解 track、trigger 以及 effect，我基于一定的猜想对整个模型进行绘制，所以不保证模型的准确性啦～&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/proxy-and-vue3-reactivity/vue3_reactivity_01.drawio.png&quot; alt=&quot;vue3_reactivity_01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;我们不妨认为整个视图是一个大拼图，其中不同部分依赖着不同的数据，这里 piece2、piece4、piece8 都依赖着数据 &lt;code&gt;data[key]&lt;/code&gt;，当然，这可能是文本插值：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;template&amp;gt;
   &amp;lt;div&amp;gt;{{ data[key] }}&amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;也可能是 v-bind 等指令绑定的数据：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;template&amp;gt;
   &amp;lt;div :class=&quot;data[key]&quot;&amp;gt;&amp;lt;/div&amp;gt;
&amp;lt;/template&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;等等等等……&lt;/p&gt;
&lt;p&gt;在这里，我们不妨先简单地认为首次渲染时分别执行了以下操作：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;View.render = () =&amp;gt; {
   View.piece2.render(data[key] + 1)
   View.piece4.render(data[key])
   View.piece8.render(data[key] - 1)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;嗯，很好，我们可以完成数据的首次渲染了，但……响应式呢？？？下次我们如何才能在 &lt;code&gt;data[key]&lt;/code&gt; 更新时重新渲染这三块拼图呢？&lt;/p&gt;
&lt;p&gt;首先，我们先要知道数据 &lt;code&gt;data[key]&lt;/code&gt; 都被哪几块拼图依赖了，我们要如何追踪这个依赖呢？其实不难发现，依赖 &lt;code&gt;data[key]&lt;/code&gt; 的拼图是要将 &lt;code&gt;data[key]&lt;/code&gt; 渲染到 View 上，那么就必然要获取 &lt;code&gt;data[key]&lt;/code&gt; 的值，也就是必定会执行 &lt;code&gt;[[GET]]&lt;/code&gt; 操作，因此我们应该在 handler 的 get 中执行相关依赖收集操作，而这个过程则被封装成了 track 函数。&lt;/p&gt;
&lt;p&gt;那么 track 函数如何实现对依赖进行收集呢？很简单，我们建立一个 map，用来存储这个依赖与 &lt;code&gt;data[key]&lt;/code&gt; 之间的依赖关系就好了。&lt;/p&gt;
&lt;p&gt;这里先建立全局的 &lt;code&gt;targetMap: WeakMap&lt;/code&gt;，&lt;code&gt;targetMap[data]&lt;/code&gt; 就是这个 &lt;code&gt;data&lt;/code&gt; 的相关依赖。由于不同 &lt;code&gt;key&lt;/code&gt; 也是拥有不同的依赖，所以再建立一层 &lt;code&gt;depsMap: Map&lt;/code&gt;，&lt;code&gt;targetMap[data][key]&lt;/code&gt; 存的就是全部依赖。由于依赖可能不止一条，所以它需要是个 Set。&lt;/p&gt;
&lt;p&gt;不过，Set 里要存的依赖是什么呀？emmm，先不用管，我们先只需要知道要存的是 &lt;code&gt;activeEffect&lt;/code&gt; 就好。那么就简单实现下吧：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;type Dep = Set&amp;lt;Function&amp;gt;
type KeyToDepMap = Map&amp;lt;any, Dep&amp;gt;
const targetMap = new WeakMap&amp;lt;any, KeyToDepMap&amp;gt;()

function track(target: object, type: string, key: unknown) {
   console.log(`[Track] 执行了 ${type} 操作，目标属性为 ${key}`)
   let depsMap = targetMap.get(target)
   if (!depsMap) {
      targetMap.set(target, (depsMap = new Map()))
   }
   let dep = depsMap.get(key)
   if (!dep) {
      depsMap.set(key, (dep = new Set()))
   }
   if (!dep.has(activeEffect)) {
      dep.add(activeEffect)
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码很简单，就是普通的建立两层 Map 和一层 Set 而已。&lt;/p&gt;
&lt;p&gt;但是 &lt;code&gt;activeEffect&lt;/code&gt; 是什么？&lt;/p&gt;
&lt;p&gt;其实不难理解，在渲染数据时，piece4 对应的渲染语句 &lt;code&gt;View.piece4.render(data[key])&lt;/code&gt; 其实就是下次数据发生变化时需要重新执行的语句，也就是说该语句依赖于 &lt;code&gt;data[key]&lt;/code&gt;，那么我们就把该语句存到 &lt;code&gt;targetMap[data][key]&lt;/code&gt; 中即可。当然，为了实现这一点，只需要把刚刚执行的那条渲染语句存到 &lt;code&gt;activeEffect&lt;/code&gt; 即可。&lt;/p&gt;
&lt;p&gt;由于依赖关系是在首次渲染时建立的，因此我们应当把首次渲染伪代码稍微修改下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;View.render = () =&amp;gt; {
   effect(() =&amp;gt; View.piece2.render(data[key] + 1))
   effect(() =&amp;gt; View.piece4.render(data[key]))
   effect(() =&amp;gt; View.piece8.render(data[key] - 1))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;那么 effect 中执行了什么呢？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;let activeEffect: Function | undefined
function effect(fn: Function) {
   const _effect = () =&amp;gt; {
      activeEffect = fn
      fn() // 执行渲染语句，如果该语句依赖于某个 data[key]，那么将会由于 get 而触发 track
      // track 中则会将 activeEffect 也就是 fn 存储到 data[key] 的依赖中
   }
   _effect()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其实很简单啦，无非就是将这个函数记录到全局变量 &lt;code&gt;activeEffect&lt;/code&gt;，并且执行一次（初次渲染）。&lt;/p&gt;
&lt;p&gt;在初次渲染时，如果该渲染项依赖于某个 &lt;code&gt;data[key]&lt;/code&gt;，那么在 get 时就会触发 track 函数，将 &lt;code&gt;activeEffect&lt;/code&gt; 存入 &lt;code&gt;data[key]&lt;/code&gt; 的依赖中，而 &lt;code&gt;activeEffect&lt;/code&gt; 这个全局变量刚刚被替换成了这条渲染语句，这样这条渲染语句就被存起来了。&lt;/p&gt;
&lt;p&gt;呼，总算存进去了，不过仔细一想就可以发现还是有一点问题的，那就是即便不是 effect 包裹的语句中，只要使用 get 都会触发 track 中的依赖收集，这是我们所不期望的。为了避免这一问题，我们再稍稍改造一下 track 与 effect 函数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;type Dep = Set&amp;lt;Function&amp;gt;
type KeyToDepMap = Map&amp;lt;any, Dep&amp;gt;
const targetMap = new WeakMap&amp;lt;any, KeyToDepMap&amp;gt;()

function track(target: object, type: string, key: unknown) {
   console.log(`[Track] 执行了 ${type} 操作，目标属性为 ${key}`)
   if (shouldTrack) {
      let depsMap = targetMap.get(target)
      if (!depsMap) {
         targetMap.set(target, (depsMap = new Map()))
      }
      let dep = depsMap.get(key)
      if (!dep) {
         depsMap.set(key, (dep = new Set()))
      }
      if (!dep.has(activeEffect)) {
         dep.add(activeEffect)
      }
   }
}

let activeEffect: Function | undefined
let shouldTrack: boolean = false

function effect(fn: Function) {
   const _effect = () =&amp;gt; {
      shouldTrack = true
      activeEffect = fn
      fn() // 只有 effect 中的语句才能进入 track 的依赖收集逻辑
      shouldTrack = false
   }
   _effect()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;嗯，再加一个全局变量来限制非 effect 中的 get 方法就好了。&lt;/p&gt;
&lt;p&gt;现在依赖应当是被正常收集了～&lt;/p&gt;
&lt;p&gt;那么，就差在 trigger 时把依赖都触发了，不过 trigger 中分为 &lt;code&gt;&quot;DELETE&quot;&lt;/code&gt;、&lt;code&gt;&quot;SET&quot;&lt;/code&gt; 和 &lt;code&gt;&quot;ADD&quot;&lt;/code&gt;（&lt;code&gt;[[SET]]&lt;/code&gt; 可能是修改一个属性，也可能是新增一个属性，所以分为 &lt;code&gt;&quot;SET&quot;&lt;/code&gt; 与 &lt;code&gt;&quot;ADD&quot;&lt;/code&gt; 两种）方法，比较复杂，这里就只实现最简单的 &lt;code&gt;&quot;SET&quot;&lt;/code&gt; 方法。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function trigger(target: object, type: string, key: unknown) {
   console.log(`[Trigger] 执行了 ${type} 操作，目标属性为 ${key}`)
   const depsMap = targetMap.get(target)
   if (!depsMap) {
      return
   }
   switch (type) {
      case &apos;SET&apos;:
         if (!depsMap.has(key)) {
            return
         }
         // 遍历 targetMap[data][key]，重新执行所有依赖于 data[key] 的语句
         for (const effect of depsMap.get(key)) {
            effect()
         }
         break
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里自然是不难理解啦，最后我们测试一下～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const count = ref(0)

effect(() =&amp;gt; {
   console.log(`render: ${count.value}`)
})
count.value++
count.value++
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;输出结果如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Track] 执行了 GET 操作，目标属性为 value
render: 0
[Track] 执行了 GET 操作，目标属性为 value
[Trigger] 执行了 SET 操作，目标属性为 value
[Track] 执行了 GET 操作，目标属性为 value
render: 1
[Track] 执行了 GET 操作，目标属性为 value
[Trigger] 执行了 SET 操作，目标属性为 value
[Track] 执行了 GET 操作，目标属性为 value
render: 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;前两行自然就是首次渲染，渲染结果是 0。&lt;/p&gt;
&lt;p&gt;3、4 行是 count++ 触发的 &lt;code&gt;[[GET]]&lt;/code&gt; 与 &lt;code&gt;[[SET]]&lt;/code&gt;，在 &lt;code&gt;[[SET]]&lt;/code&gt; 里又触发了语句的重新渲染。&lt;/p&gt;
&lt;p&gt;5、6 行便是重新渲染时的结果，重新渲染中触发了 &lt;code&gt;[[GET]]&lt;/code&gt;，渲染结果为 1。&lt;/p&gt;
&lt;p&gt;最后四行和 3、4、5、6 行完全一样，就不再赘述了……&lt;/p&gt;
&lt;p&gt;嘻嘻，完成啦～源码就先整理到&lt;a href=&quot;https://github.com/ShigureLab/vue-reactivity&quot;&gt;这里&lt;/a&gt;好了。&lt;/p&gt;
&lt;p&gt;呼，总算完事了，本来这次探索只是初学 Proxy 的一个延伸罢了，原来就想看看 reactive 的源码就算了，但实在是觉得探索了一半有点可惜，才把 track 等的作用也给分析了下。唔，不过分析的很浅啦，可能还有不少错误的地方，而且很多细节暂且都没有考虑……嗯，以后有机会再深度研读下 Vue3 源码吧，这次就到这里好了～&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;《JavaScript 高级程序设计（第四版）》 Matt Frisbie&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/vuejs/core/tree/main/packages/reactivity&quot;&gt;Vue3 源码 reactivity 部分&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://v3.cn.vuejs.org/api/basic-reactivity.html#reactive&quot;&gt;Vue3 文档&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>JavaScript 中的“类”与原型链</title><link>https://nyakku.moe/posts/javascript-prototype-chain/</link><guid isPermaLink="true">https://nyakku.moe/posts/javascript-prototype-chain/</guid><pubDate>Sun, 31 Jan 2021 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;虽然早有耳闻 ECMAScript 的“类”并不是真正的类，但此前我一直都是直接按其他面向对象语言的用法直接用来着，不过也没发现什么不同（毕竟其实也没怎么用过 JS 的说 2333）。&lt;/p&gt;
&lt;p&gt;唔，这两天刚好看到了《JavaScript 高级程序设计（第四版）》中的“对象”这一章，就简单整理一下啦～&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;实例、构造函数与原型对象&lt;/h2&gt;
&lt;p&gt;大多数面向对象的编程语言，在获取一个新对象时，都是首先定义一个 class，然后用这个 class 来实例化出来一个对象，而 ECMAScript 是没有类这个概念的，&lt;strong&gt;ECMAScript 中只有对象，所谓的类的继承机制也不过是通过 ECMAScript 的原型链机制实现的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在 ECMAScript 中，对象是通过构造函数 new 出来的，就像这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function Person(name) {
   this.name = name
}

const person = new Person(&apos;Nyakku&apos;)

console.log(person.name) // Nyakku
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于 Person 是一个函数，所以它当然也可以不用 new 直接调用：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function Person(name) {
   this.name = name
}

Person(&apos;Nyakku&apos;)

console.log(global.name) // Nyakku
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不使用 new 调用时，this 自然指向了全局对象 Global（视运行时而定，这里的 Node.js 使用的是 global，而 Deno 与众多浏览器中则使用的是 window），而使用 new 时 this 才会指向新对象（也就是前面的 person）。&lt;/p&gt;
&lt;p&gt;在使用 new 新建一个对象后，这个对象与其构造函数之间建立了一种奇妙的联系，可以通过几行代码了解一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function Person() {}

const person = new Person()

console.log(person instanceof Person)
console.log(person.__proto__ === Person.prototype)
console.log(Person.prototype.__proto__ === Object.prototype)
console.log(Person.prototype.__proto__.constructor === Object)
console.log(Person.prototype.__proto__.__proto__ === null)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，上面五个语句返回的都是 &lt;code&gt;true&lt;/code&gt;，第一个语句没什么可说的，之后的 &lt;code&gt;__proto__&lt;/code&gt; 是什么鬼？嘛，这就是一个对象用来获取其原型对象的一个属性，比如第二个语句表明了 &lt;code&gt;person&lt;/code&gt; 是以 &lt;code&gt;Person.prototype&lt;/code&gt; 为原型的。&lt;/p&gt;
&lt;p&gt;:::tip[关于 &lt;code&gt;__proto__&lt;/code&gt;]&lt;/p&gt;
&lt;p&gt;事实上并没有访问原型对象的标准方式，但某些运行时会将其暴露在 &lt;code&gt;__proto__&lt;/code&gt; 属性中，比如 Firefox、Safari、Chrome、Node.js。&lt;/p&gt;
&lt;p&gt;但是实践证明这种方式可能会导致一系列安全问题，Deno 和 Node.js 也分别在 &lt;a href=&quot;https://github.com/denoland/deno/issues/4324&quot;&gt;#4324&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/nodejs/node/issues/31951&quot;&gt;#31951&lt;/a&gt; 展开了讨论，前者直接删掉了 &lt;code&gt;__proto__&lt;/code&gt; 这一属性，而后者（v15.6.0）则是默认开启，通过 &lt;a href=&quot;https://nodejs.org/dist/latest-v15.x/docs/api/cli.html#cli_disable_proto_mode&quot;&gt;&lt;code&gt;--disable-proto=mode&lt;/code&gt; 选项&lt;/a&gt;可以设置在何种程度上禁用 &lt;code&gt;__proto__&lt;/code&gt; 属性。&lt;/p&gt;
&lt;p&gt;虽说现在各种运行时上的行为不一致，但为了方便，本文就直接使用 &lt;code&gt;__proto__&lt;/code&gt; 属性来获取原型对象啦。&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;这么多语句看起来有点复杂呢，我们画个图来整理一下吧～&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/javascript-prototype-chain/prototype_01.drawio.png&quot; alt=&quot;prototype01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;根据刚刚的关系可以轻松画出来这张图，我们可以看到 person 是以 Person.prototype 为原型，而 Person.prototype 则是以 Object.Prototype 为原型，形成了一条原型链，而原型链的终点就是 null。&lt;/p&gt;
&lt;p&gt;虽说这张图已经可以将实例、构造函数、原型对象之间的关系大致表示出来，但是细心的小伙伴一定已经发现了一个非常令人疑惑的点：person 是以 Person.prototype 为原型自然不难理解，毕竟 person 是用 Person new 出来的，但 Object.prototype 凭什么可以是 Person.prototype 的原型呢？&lt;/p&gt;
&lt;p&gt;稍安勿躁，我们继续往下看。&lt;/p&gt;
&lt;p&gt;这次考虑一个稍微复杂的例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function SuperType() {}
function SubType() {}

SubType.prototype = new SuperType()
SubType.prototype.constructor = SubType // 保证 constructor 属性正确
const sub = new SubType()

console.log(SubType.prototype.__proto__ === SuperType.prototype)
console.log(sub.__proto__ === SubType.prototype)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;毋庸置疑，这次返回的也是 ture，毕竟 SubType.prototype 是由 SuperType 所 new 出来的，所以 SuperType.prototype 自然是 SubType.prototype 的 原型。&lt;/p&gt;
&lt;p&gt;值得注意的是，SubType.prototype 是由 SuperType new 出来的，也就是说前者是后者的实例，而 sub 则是 SubType.prototype 的实例，由此形成一条非常清晰的原型链，我们依此将刚刚的图进行补足。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/javascript-prototype-chain/prototype_02.drawio.png&quot; alt=&quot;prototype02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在刚刚图的结构上稍加修整，不难画出这样的图，在这张图上我们可以清晰地看出 SuperType.prototype 是 SubType.prototype 的原型的原因是后者是前者构造函数 new 出来的，这也与刚刚在代码中所分析的一致。那么 SuperType.prototype 为何是 Object.prototype 的实例此时想必已经呼之欲出了。由于我们并没有明确指定 SuperType 的 prototype，此时其默认原型就是一个 Object 的实例，也就相当于 &lt;code&gt;SuperType.prototype = new Object()&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;与此同时，我们也不难发现，&lt;strong&gt;对于任何一个构造函数 F，使用这个构造函数 new 出来的实例会以 F.prototype 为原型，这就是它们三者之间的关系&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;原型链机制&lt;/h2&gt;
&lt;p&gt;下面我们忽略掉构造函数，只看我们关心的对象：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/javascript-prototype-chain/prototype_03.drawio.png&quot; alt=&quot;prototype03&quot; /&gt;&lt;/p&gt;
&lt;p&gt;很明显，一个原型是可以创造多个实例（如 super1、super2、super3、super4）的，但是有时一个实例（如 super4）会突然不想只做一个平平淡淡的实例啦，然后就自己做起了一个原型，并创造起了自己的实例。&lt;/p&gt;
&lt;p&gt;而对于任何一个实例，都有唯一的一条路径向上寻找自己的原型，甚至原型的原型，这条路径就是专属于它的原型链。&lt;/p&gt;
&lt;p&gt;那么这么一条路径有什么用呢？&lt;/p&gt;
&lt;p&gt;ECMAScript 有一个机制就是，如果访问自身某个属性访问不到时，会去尝试访问其原型的属性，当然，其原型如果还有原型的话还会按照这条规则查找，这就是原型链的作用。&lt;/p&gt;
&lt;p&gt;下面举个例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function SuperType() {}
function SubType() {}

SubType.prototype = new SuperType()
SubType.prototype.constructor = SuperType
const sub = new SubType()

SuperType.prototype.name = &apos;SuperPrototype&apos;
console.log(sub.name) //  SuperPrototype
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里 sub 明明没有 name 属性的，所以会向上查找 SubType.prototype，不过也是没有 name 属性诶～那就继续找 SuperType.prototype 吧，嗯，找到了呢～&lt;/p&gt;
&lt;p&gt;但一个实例应当拥有自己的属性的呀，那要怎么做呢？&lt;/p&gt;
&lt;p&gt;接着上面的代码，在后面添加下面几行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sub.name = &apos;sub&apos;

console.log(sub.name) // sub
console.log(SubType.prototype.name) // SuperPrototype
console.log(SuperType.prototype.name) // SuperPrototype
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一个实例想要自己的属性的话，直接在自己对象上添加属性就好了，此时在对象上已经查找到这个属性值了，所以不会向上查找。当然 SubType.prototype 还是会向上查找的。&lt;/p&gt;
&lt;p&gt;有没有发现，通过原型链机制可以很方便地实现继承？新的实例可以直接到定义在原型上的属性，而且也可以方便地对已有属性进行修改。&lt;/p&gt;
&lt;p&gt;但是，原型链还有一个最大的弊端，就是如果原型上属性的数据类型不是原始类型，而是引用类型时，对该属性的修改会直接影响到原型的属性，下面举个例子：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function Person() {}

Person.prototype.devices = [&apos;Phone&apos;]

const person1 = new Person()
const person2 = new Person()

person1.devices.push(&apos;PC&apos;)
console.log(person1.devices) // [ &apos;Phone&apos;, &apos;PC&apos; ]
console.log(person2.devices) // [ &apos;Phone&apos;, &apos;PC&apos; ]
console.log(Person.prototype.devices) // [ &apos;Phone&apos;, &apos;PC&apos; ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面最终运行的结果是每个人的 devices 都变成了 &lt;code&gt;[ &apos;Phone&apos;, &apos;PC&apos; ]&lt;/code&gt;，究其根本，是直接调用原型上的引用类型属性的方法，改变了其值，这导致所有以其为原型的对象都会受到影响。&lt;/p&gt;
&lt;p&gt;但这个问题还是无法解决的，毕竟原型链与引用类型就是这样的机制，所以说仅仅简单使用原型链机制还是无法实现完美的继承的。&lt;/p&gt;
&lt;p&gt;那么，怎么才能实现我们心目中的继承呢？&lt;/p&gt;
&lt;h2&gt;使用原型链实现继承&lt;/h2&gt;
&lt;p&gt;我们下面一步步修改上面的例子，让它能够实现我们想要的继承。&lt;/p&gt;
&lt;p&gt;为了避免上面的原型链上引用类型数据带来的问题，属性最好不要定义在原型上，如果能定义在每个实例上最好不过了。&lt;/p&gt;
&lt;p&gt;emmm，想要定义在实例上的话，只需要把定义属性这一过程放到构造函数中就好。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function Person() {
   this.devices = [&apos;Phone&apos;]
   this.sayName = function () {
      console.log(&apos;Person&apos;)
   }
}

const person1 = new Person()
const person2 = new Person()
person1.devices.push(&apos;PC&apos;)
console.log(person1.devices) // [ &apos;Phone&apos;, &apos;PC&apos; ]
console.log(person2.devices) // [ &apos;Phone&apos; ]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时，person1 和 person2 在实例对象上就有了各自的属性，因此不需要查找原型上的属性了。&lt;/p&gt;
&lt;p&gt;不过要如何实现继承呢？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function SuperType() {
   this.name = &apos;SuperType&apos;
   this.sayName = function () {
      console.log(this.name)
   }
}

function SubType() {
   SuperType.call(this) // 继承 SuperType
}

SubType.prototype = new SuperType()
SubType.prototype.constructor = SubType
const sub = new SubType()

console.log(sub.name) // SuperType
sub.sayName() // SuperType
sub.name = &apos;sub&apos;
sub.sayName() // sub
console.log(SubType.prototype.name) // SuperType
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 SubType 中将 SuperType 函数作用于自身，就可以将属性和方法继承起来了，这种方式被称作“盗用构造函数”。&lt;/p&gt;
&lt;p&gt;很好，此时已经完成了继承的效果了，但是仍有两处不足：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;方法在每个实例中都定义了一份，然而很明显我们方法只需要共用同一个就行了，这造成了极大的空间浪费。&lt;/li&gt;
&lt;li&gt;明明每个实例上都有各自的属性了，但原型上还是定义了一份属性，这也造成了空间的浪费。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面一一解决这两个问题。&lt;/p&gt;
&lt;p&gt;首先，既然方法只需要一份，那么我们就不在构造函数中定义方法，而在原型上定义。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function SuperType() {
   this.name = &apos;SuperType&apos;
}

SuperType.prototype.sayName = function () {
   console.log(this.name) // 通过构造函数继承 SuperType 的属性
}

function SubType() {
   SuperType.call(this)
}

SubType.prototype = new SuperType() // 通过原型链继承 SuperType 的方法
SubType.prototype.constructor = SubType
const sub = new SubType()

console.log(sub.name) // SuperType
sub.sayName() // SuperType
sub.name = &apos;sub&apos;
sub.sayName() // sub
console.log(SubType.prototype.name) // SuperType
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样，定义在原型上的方法就可以被实例通过原型链获取到，实例本身是没有这个方法的。&lt;/p&gt;
&lt;p&gt;好了，方法的问题解决了，那么在原型对象上的冗余属性要怎么解决呢？&lt;/p&gt;
&lt;p&gt;首先看问题在哪？原型对象的冗余属性就是在构造该原型对象时添加的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SubType.prototype = new SuperType()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这条语句不仅仅实现了搭建了原型链，还让在该原型对象上执行了一遍构造函数，这才使得该原型对象上有着冗余的属性。&lt;/p&gt;
&lt;p&gt;那么有没有办法可以既保留原型链，又能不执行这个构造函数呢？&lt;/p&gt;
&lt;p&gt;当然是有滴～我们这回构造 SubType.prototype 不用 SuperType 就好啦，临时创建一个空的函数 F，并将其 prototype 绑定在 SuperType.prototype 上，不就可以曲线地构造这条原型链了嘛～&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;function F() {}
F.prototype = SuperType.prototype
SubType.prototype = new F()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;把上面那行代码换成这段就可以解决属性的冗余问题啦，由于现在 SubType.prototype 不再是 SuperType 直接构造出来的，之前那张“实例、构造函数、原型对象关系”图也需要更新一下下啦～&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/javascript-prototype-chain/prototype_04.drawio.png&quot; alt=&quot;prototype04&quot; /&gt;&lt;/p&gt;
&lt;p&gt;此时继承时所使用的 prototype 都应当是使用一个临时的构造函数 F new 出来的，这个过程封装成函数就好，出函数后 F 应当就会被自动回收了。&lt;/p&gt;
&lt;h2&gt;语法糖 class&lt;/h2&gt;
&lt;p&gt;虽然我们可以通过原型链机制与亿点点改动实现继承的效果，但每次写个继承都需要一大堆代码，属实令人难以接受。&lt;/p&gt;
&lt;p&gt;好在 ES6 添加了 class 语法糖，让我们能够像写其他语言的类一样写继承啦，不过 class 毕竟只是语法糖，究其根本还是通过原型链实现的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class SuperType {
   constructor() {
      this.name = &apos;SuperType&apos;
   }

   sayName() {
      console.log(this.name)
   }
}

class SubType extends SuperType {
   constructor() {
      super()
   }
}

const sub = new SubType()

console.log(sub.name) // SuperType
sub.sayName() // SuperType
sub.name = &apos;sub&apos;
sub.sayName() // sub
console.log(SubType.prototype.name) // SuperType
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;喏，上面的代码就实现了之前的功能，代码还更加简洁，再也不用头疼什么 prototype 啦原型链什么的了，而且还支持 static 关键字定义类静态方法，比原来的 prototype 方便多啦嘻嘻～&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;《JavaScript 高级程序设计（第四版）》 Matt Frisbie&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>采用 GitHub Action 自动化部署博客</title><link>https://nyakku.moe/posts/deploy-blog-using-github-action/</link><guid isPermaLink="true">https://nyakku.moe/posts/deploy-blog-using-github-action/</guid><pubDate>Mon, 22 Jun 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;博客的部署往往只需要一行命令，但却需要花费我几分钟在本地的构建时间，完成博客内容后本应该放松放松心情，这几分钟的等待显得尤为惹人生厌&lt;/p&gt;
&lt;p&gt;那么如何解决这个问题呐？当然是自动化部署啦，这样我们每次只需要将写完的博客 Push 到 GitHub 上，就可以触发相应的 CI 以完成博客的自动部署咯，所以这里就介绍如何使用 GitHub Action 来自动化部署博客&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;GitHub Action 的使用&lt;/h2&gt;
&lt;p&gt;关于自动化部署，起初我接触的是 Travis CI，配置起来非常简单～&lt;/p&gt;
&lt;p&gt;后来 GitHub Action 完全开放，我就完全转 GitHub Action 这个自定义更加方便的 CI 系统了，起初我的自动化部署脚本也是自己写的 Shell 脚本，因为那时候相关的部署 Action 尚不完善，不支持直接 Push 到根地址，不过前段时间支持了之后我就放弃自己写的脚本咯 (๑˃◡˂๑)&lt;/p&gt;
&lt;p&gt;GitHub Action 的使用方法也非常简单～只需要在项目根目录新建 &lt;code&gt;.github/workflows/&lt;/code&gt; 文件夹，再在其中新建相应的 YAML 配置文件即可，比如 &lt;code&gt;hello-github-action.yml&lt;/code&gt;，名字随意啦，只是为了区分而已～&lt;/p&gt;
&lt;p&gt;文件内写入相应的内容&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# action 名字
name: Hello GitHub Action

on:
   # 触发条件，比如 push pull_request 等
   push:
      branches:
         - main

jobs:
   build-and-deploy:
      # 运行环境
      runs-on: ubuntu-latest
      steps:
         # 各步的任务
         - name: Hello GitHub Action
           run: echo &apos;Hello GitHub Action&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样我们就完成了一个简单的 GitHub Action，它会在我们每次 push 到 main 分支时触发，之后就会打印 &lt;code&gt;Hello GitHub Action&lt;/code&gt;，虽然看不见……&lt;/p&gt;
&lt;h2&gt;自动化部署到 GitHub Pages&lt;/h2&gt;
&lt;p&gt;我们对上面的配置稍作修改，目标就是在源仓库 Push 时触发，此时将博客源码构建成静态文件，并将它们 Push 到 GitHub Pages 仓库即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: VuePress Deploy

on:
   push:
      branches:
         - main

jobs:
   build-and-deploy:
      runs-on: ubuntu-latest
      steps:
         # 使用某个 Repo
         - name: Checkout 🛎️
           uses: actions/checkout@v2

         # 构建静态文件
         - name: Install and Build 🔧
           run: |
              npm install yarn
              yarn
              yarn docs:build

         # 部署到 GitHub Pages
         - name: Deploy 🚀
           uses: peaceiris/actions-gh-pages@v3
           with:
              personal_token: ${{ secrets.PERSONAL_TOKEN }}
              publish_dir: docs/.vuepress/dist
              external_repository: SigureMo/SigureMo.github.io
              publish_branch: main
              cname: nyakku.moe
              user_name: &apos;github-actions[bot]&apos;
              user_email: &apos;github-actions[bot]@users.noreply.github.com&apos;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里第一步是使用你的源代码 repo，其中 uses 是指使用了某个现成的 Action，比如这个 &lt;code&gt;actions/checkout&lt;/code&gt; 就是 &lt;a href=&quot;https://github.com/actions/checkout&quot;&gt;&lt;code&gt;github.com/actions/checkout&lt;/code&gt;&lt;/a&gt; 的 &lt;code&gt;v2&lt;/code&gt; 版本，如果需要 submodule 或者 lfs 可以通过 &lt;code&gt;with&lt;/code&gt; 选项来修改参数&lt;/p&gt;
&lt;p&gt;第二步是将博客源码构建成静态文件，不同工具的构建方法自然不同，我这里是以 VuePress 作为示例&lt;/p&gt;
&lt;p&gt;第三步就是将构建好的静态文件 Push 到目标的 GitHub Pages 对应的 Repo 了，这里使用的是 &lt;a href=&quot;https://github.com/peaceiris/actions-gh-pages&quot;&gt;&lt;code&gt;peaceiris/actions-gh-pages&lt;/code&gt;&lt;/a&gt;，如果你只需要部署到当前 Repo 的 &lt;code&gt;gh-pages&lt;/code&gt; 分支上的话，你只需要配置以下内容即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;- name: Deploy 🚀
  uses: peaceiris/actions-gh-pages@v3
  with:
     github_token: ${{ secrets.GITHUB_TOKEN }}
     publish_dir: docs/.vuepress/dist
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里的 &lt;code&gt;secrets.GITHUB_TOKEN&lt;/code&gt; 不需要配置，GitHub 会自动提供&lt;/p&gt;
&lt;p&gt;但是如果你和我一样想部署到 &lt;code&gt;&amp;lt;username&amp;gt;.github.io&lt;/code&gt; 的话，就需要稍微改动一下啦，该 Action 提供了非常丰富的参数以供配置&lt;/p&gt;
&lt;p&gt;由于目标 Repo 和目标分支都变了，就需要分别设置下 &lt;code&gt;external_repository&lt;/code&gt; 和 &lt;code&gt;publish_branch&lt;/code&gt; 这两个参数咯&lt;/p&gt;
&lt;p&gt;另外，由于 Push 到外部 Repo 的话 &lt;code&gt;GITHUB_TOKEN&lt;/code&gt; 的权限不足，因此需要提供其它的验证方式，比如 &lt;code&gt;personal_token&lt;/code&gt; 和 &lt;code&gt;deploy_key&lt;/code&gt;，这里提一下 &lt;code&gt;personal_token&lt;/code&gt; 的生成与配置方式，该方法相比于后者也更方便一些&lt;/p&gt;
&lt;p&gt;依次进入&lt;code&gt;个人 Settings -&amp;gt; Developer settings -&amp;gt; Personal access tokens&lt;/code&gt; 点击 &lt;code&gt;Generate new token&lt;/code&gt;，随便填写个名字，然后下面勾选 &lt;code&gt;repo&lt;/code&gt;（权限） 后确认 &lt;code&gt;Generate token&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;由于生成的 token 只能看一次，请确定复制后再关闭页面&lt;/p&gt;
&lt;p&gt;之后依次进入 &lt;code&gt;源 repo -&amp;gt; Settings -&amp;gt; Secrets&lt;/code&gt;，点击 &lt;code&gt;New secret&lt;/code&gt;，Name 字段填写 &lt;code&gt;PERSONAL_TOKEN&lt;/code&gt;，Value 字段粘贴刚刚生成的 token 即可&lt;/p&gt;
&lt;p&gt;这样，该 action 在 &lt;code&gt;secrets.PERSONAL_TOKEN&lt;/code&gt; 处就可以获得刚刚生成的拥有读写 repo 权限的 token，然后传入该 action 的 &lt;code&gt;personal_token&lt;/code&gt; 参数，进而完成整个部署过程&lt;/p&gt;
&lt;p&gt;这样就完成了权限的配置啦，该 Action 还提供了很多比较实用的参数，比如 &lt;code&gt;cname&lt;/code&gt;，更多详情去看它的文档吧&lt;/p&gt;
&lt;p&gt;完成这些，就可以重新 push 一下源代码 repo 试一下啦，还可以在源 repo 的 Actions 中可以看到相关进度&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/peaceiris/actions-gh-pages&quot;&gt;actions-gh-pages&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>使用 git-filter-repo 清理 git 历史记录</title><link>https://nyakku.moe/posts/use-git-filter-repo-clean-git-history/</link><guid isPermaLink="true">https://nyakku.moe/posts/use-git-filter-repo-clean-git-history/</guid><pubDate>Fri, 12 Jun 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;Git 并不适合管理二进制文件，但有些情况下又不得不添加一些图片之类的二进制文件，但一旦频繁更改的话，历史记录中将记录着每一个完整的二进制文件，导致 repo 越来越大……为了解决该问题，往往需要一些针对二进制文件的处理手段&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;Git LFS&lt;/h2&gt;
&lt;p&gt;Git LFS 是 GitHub 推出的大文件存储服务，它是让 git 只保存二进制文件的 hash，而二进制文件将会存在 Git LFS 服务器中，当然，这可以有效防止 Git 历史的增长，但……免费只有 1G 空间，而且每月还限 1G 带宽，虽然看起来挺大的，但有一个月我频繁更新博客，CI 频繁地从 LFS 获取图片，结果居然真的差点就用到了 1 个 G 的带宽……之后我就开始另寻他法……&lt;/p&gt;
&lt;h2&gt;定期清理 Git 历史&lt;/h2&gt;
&lt;h3&gt;使用 git-filter-branch&lt;/h3&gt;
&lt;p&gt;定期清理的话，虽然麻烦，但也最实用，在使用 LFS 之前我也定期清理过，是使用的 git-filter-branch，但由于嫌麻烦，就改用 LFS 了，至于为什么不用 BFG，因为懒得装 JDK&lt;/p&gt;
&lt;p&gt;弃用 LFS 后，我仍然使用 git-filter-branch，不过实在是麻烦，每次清理我需要运行好多命令，比如清理全部 &lt;code&gt;*.jpg&lt;/code&gt; 图片，我需要&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git filter-branch --force --index-filter \
&apos;git rm --cached --ignore-unmatch -r *.jpg&apos; \
--prune-empty --tag-name-filter cat -- --all
rm -rf .git/refs/original/
git reflog expire --expire=now --all
git gc --prune=now
git gc --aggressive --prune=now
git push origin main --force
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;emmm，就很麻烦&lt;/p&gt;
&lt;h3&gt;使用 git-filter-repo&lt;/h3&gt;
&lt;p&gt;最近，使用 &lt;code&gt;git filter-branch&lt;/code&gt; 会提示 &lt;code&gt;warning&lt;/code&gt;，推荐使用 &lt;code&gt;git filter-repo&lt;/code&gt;，于是就试着搜了下，这居然是 python 实现的清理器，拥有远比 &lt;code&gt;git filter-branch&lt;/code&gt; 更加方便的使用方法，所以我在尝试了一下下就果断转 &lt;code&gt;git filter-repo&lt;/code&gt; 了&lt;/p&gt;
&lt;p&gt;在使用之前需要先安装一下，参考文档中的&lt;a href=&quot;https://github.com/newren/git-filter-repo/blob/main/INSTALL.md&quot;&gt;安装指南&lt;/a&gt;可以发现大多数包管理器已经可以直接安装 git-filter-repo 了，比如 Homebrew&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew install git-filter-repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，即便没有合适的包管理器我们也可以通过 pip 安装&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install git-filter-repo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;code&gt;git filter-repo&lt;/code&gt; 清理全部 &lt;code&gt;*.jpg&lt;/code&gt; 只需要&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git filter-repo --path-glob &apos;*.jpg&apos; --invert-paths
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;不仅命令简单，而且速度超快，只不过不能像 &lt;code&gt;git filter-branch&lt;/code&gt; 一样清楚地了解都清理了哪些文件了&lt;/p&gt;
&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;如果你不知道哪些历史文件比较大的话，可以运行下面这个命令来查找一下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git rev-list --objects --all | grep &quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk &apos;{print$1}&apos;)&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;当然，这只是 &lt;code&gt;git filter-repo&lt;/code&gt; 的一个最简单的应用啦，更多使用技巧还是要看文档的～&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/newren/git-filter-repo&quot;&gt;git-filter-repo GitHub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://htmlpreview.github.io/?https://github.com/newren/git-filter-repo/blob/docs/html/git-filter-repo.html#EXAMPLES&quot;&gt;git-filter-repo Manual Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://harttle.land/2016/03/22/purge-large-files-in-gitrepo.html&quot;&gt;寻找并删除 Git 记录中的大文件&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>初尝 GAN</title><link>https://nyakku.moe/posts/gan-started/</link><guid isPermaLink="true">https://nyakku.moe/posts/gan-started/</guid><pubDate>Mon, 25 May 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;最近在 DL 的学习方向上稍有迷茫，毕竟有那么多学习的方向嘛。前两天突然翻出来一张猫猫十年前的照片，但分辨率实在太低啦（240 * 320），就想尝试一下超分辨率相关模型，发现最近超分辨率也在用 GAN 啦，所以，就尝试了解一下～&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;何为 GAN？&lt;/h2&gt;
&lt;p&gt;GAN 是 Generative Adversarial Network 的缩写，也即生成对抗网络，那么……生成对抗是指？&lt;/p&gt;
&lt;p&gt;首先，它是一个生成网络，目标是生成数据，所以它首先要有一个 Generator（简称 G），但是如何评判这个 G 的优劣？emmm 貌似不太容易啊，毕竟生成的数据大多比较复杂……&lt;/p&gt;
&lt;p&gt;因此，引入了 Discriminator（简称 D），D 的作用就是用来判别一张图片是否是真实图片，也就是当 D 的输入是 G 生成的图片时就输出 0，当 D 的输入是真实图片时输出就是 1，最小化这个误差即可&lt;/p&gt;
&lt;p&gt;嗯，D 知道怎么训练了，那么 G？嘛，也很简单啦，就是把 G 的输出喂给 D，然后让 D 尽可能输出较大的值就好啦，也就是 G 在这个过程中尽可能地骗过 D&lt;/p&gt;
&lt;p&gt;但是，两者同时训练还是不可取的，我们要交替地训练，具体迭代如下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在每个迭代过程中：
&lt;ul&gt;
&lt;li&gt;下面训练 D，锁定 G 的 Weights&lt;/li&gt;
&lt;li&gt;从真实数据集随便选 m 个数据 ${x^1, x^2, \cdots, x^m}$&lt;/li&gt;
&lt;li&gt;再从某一个分布中选取 m 个噪声数据 ${z^1, z^2, \cdots, z^m}$ 并喂给 G 生成 ${\tilde{x}^1, \tilde{x}^2, \cdots, \tilde{x}^m}$（也即 $\tilde{x}^i = G(z^i)$）&lt;/li&gt;
&lt;li&gt;更新 D 咯，也就是让 D 判断更准确
&lt;ul&gt;
&lt;li&gt;$\tilde{V} = \frac{1}{m} \sum \limits_{i=1}^m \log D(x^i) + \frac{1}{m} \sum \limits_{i=1}^m \log (1 - D(\tilde{x}^i))$&lt;/li&gt;
&lt;li&gt;$\theta_d \leftarrow \theta + \eta \nabla \tilde{V}(\theta_d)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;修炼完毕，可以更精准地分辨真实图片与 G 生成的图片&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;ul&gt;
&lt;li&gt;下面训练 G，锁定 D 的 Weights&lt;/li&gt;
&lt;li&gt;从某一个分布中选取 m 个噪声数据 ${z^1, z^2, \cdots, z^m}$，然后喂给 G，再将 G 的结果喂给 D，G 是想让 D 觉得它们都是 1 咯&lt;/li&gt;
&lt;li&gt;那么我们更新 G 吧
&lt;ul&gt;
&lt;li&gt;$\tilde{V} = \frac{1}{m} \sum \limits_{i=1}^m \log D(G(z^i))$&lt;/li&gt;
&lt;li&gt;$\theta_g \leftarrow \theta_g - \eta \nabla \tilde{V}(\theta_g)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;修炼完毕，可以更容易骗过 D&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;两者在不停地“对抗”过程中完成了进化，两者的模型最后都有着较好的效果&lt;/p&gt;
&lt;h2&gt;GAN 与 AutoEncoder&lt;/h2&gt;
&lt;p&gt;简单地看，GAN 就是个倒过来的 AE 嘛，AE 是 encoder $\to$ decoder，而 GAN 则是 decoder(G) $\to$ encoder(D)，当然细节略有区别&lt;/p&gt;
&lt;p&gt;而效果，AE 自然是远不如 GAN，AE 的要求是 encoder 输入与 decoder 输出尽可能相似，而相似性的比较大多使用的是像素级比较，但这往往并不合适，生成的图像大多比较模糊（类似于多个图片的叠加）&lt;/p&gt;
&lt;h2&gt;Conditional GAN&lt;/h2&gt;
&lt;p&gt;emmmm，虽然 GAN 能够生成图片，但并不能根据我们的要求准确地输出我们想要的东西，Conditional GAN（简称 CGAN） 就是用来解决该问题的&lt;/p&gt;
&lt;p&gt;CGAN 的 G 是同时需要词语 c 和噪声 z 的，词语 c 自然就是我们想要的东西咯&lt;/p&gt;
&lt;p&gt;那么 D 也需要改一下咯，它不仅需要一张图片，还需要词语 c，也就是一方面判别这张图片是否是真实图片，另一方面判别这张图片与 c 描述是否相符&lt;/p&gt;
&lt;p&gt;至于训练过程嘛，D 的训练过程数据由&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正样本真实图片正确标签&lt;/li&gt;
&lt;li&gt;负样本 G 生成图片对应标签&lt;/li&gt;
&lt;li&gt;负样本真实图片错误标签&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三部分组成，G 的不必说了，还是想骗过 D&lt;/p&gt;
&lt;p&gt;另外，D 的结构如何设计比较好呢？比较多的用法像下面这样，直接吞掉 x 和 c 给出 0 或 1&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/CGAN-01.png&quot; alt=&quot;CGAN-01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如果使用上面的结构的话，我们并不知道 0 的情况是因为图片生成的不好还是图片生成错了，为此，我们可以稍微改一下网络结构，就像下面这样，这样看起来会更合理一点&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/CGAN-02.png&quot; alt=&quot;CGAN-02&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Unsupervised Conditional Generation&lt;/h2&gt;
&lt;p&gt;CGAN 的数据是有明确的标签的，每张图片都有相应的文本一一对应，而 Unsupervised CGAN 所处理的任务则是两个没有任何关系的 domain，它们之间没有给出任何对应关系，比如一个是真实世界人物图片，一个是二次元人物图片，Unsupervised CGAN 能做到在没有任何对应关系的前提下学出来给出一个真实人物图片输出这个人的二次元形象（有点像神经网络风格转换）&lt;/p&gt;
&lt;p&gt;那么如何做到？一般有以下两种方法&lt;/p&gt;
&lt;h3&gt;Direct Transformation&lt;/h3&gt;
&lt;p&gt;所谓直接转换，是指直接 train 一个从 Domain X 到 Domain Y 的 Generator $G_{X \to Y}$，当然结果需要一个 Discriminator $D_Y$ 来评判，就像下面这样&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-01.png&quot; alt=&quot;Unsupervised-CGAN-01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;不过这样虽然能够保证生成的图片是接近于 Domain Y 的，但如何保证能够保留原图的语义信息呢？&lt;/p&gt;
&lt;p&gt;最简单的方法就是，什么都不管，当 $G_{x \to Y}$ 足够 Shallow 的情况下，那么原图并不会改变太多的&lt;/p&gt;
&lt;p&gt;但……我们如果需要一个足够 Deep 的 $G_{X \to Y}$ 才能 work 的时候要怎么办呢？&lt;/p&gt;
&lt;p&gt;方式一（添加约束项）：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.02200.pdf&quot;&gt;Yaniv Taigman, et al. Unsupervised Cross-Domain Image Generation, ICLR, 2017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-02.png&quot; alt=&quot;Unsupervised-CGAN-02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;我们用一个 PreTrain 的 CNN backbone 来提取图片中的表示，然后让原图与生成图在表示空间内尽可能地一致&lt;/p&gt;
&lt;p&gt;方式二（Circle GAN）：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.10593.pdf&quot;&gt;Jun-Yan Zhu, et al. Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Network, ICCV, 2017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-03.png&quot; alt=&quot;Unsupervised-CGAN-03&quot; /&gt;&lt;/p&gt;
&lt;p&gt;也就是，除去 $G_{X \to Y}$，再加一个 $G_{Y \to X}$，原图 $x$ 与 $G_{Y \to X}(G_{X \to Y}(x))$ 尽可能相同，以保证这个图片能顺利还原回来&lt;/p&gt;
&lt;p&gt;另外，我们可以同时 train $Y \to X$ 的过程，构成一个 Circle&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-04.png&quot; alt=&quot;Unsupervised-CGAN-04&quot; /&gt;&lt;/p&gt;
&lt;p&gt;大功告成，完美～&lt;/p&gt;
&lt;p&gt;但是 Circle GAN 虽然能够成功将 Domain X 变成 Domain Y，并再解回来，但 Domian Y 的结果可能并不一定能够保证是那么地接近与原图，因为神经网络可能在 Domain Y 图中“隐藏”某些肉眼看不到的信息再解回去，该问题尚待解决&lt;/p&gt;
&lt;h3&gt;Projection to Common Space&lt;/h3&gt;
&lt;p&gt;那么我们能不能直接在表示空间中进行操作呢？将前面的 $G_{X \to Y}$ 拆开变成一个 $Encoder_X$ 和一个 $Decoder_Y$，那么中间的 embedding 就暴露出来了&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-05.png&quot; alt=&quot;Unsupervised-CGAN-05&quot; /&gt;&lt;/p&gt;
&lt;p&gt;可是，这个怎么 train？emmm，分成两个 auto-encoder（$Encoder_X \to Decoder_X$ 和 $Encoder_Y \to Decoder_Y$），各自在自己的 Domain 里 train……但 auto-encoder 的结果非常模糊呀，要如何解决？emmm，我们可以在这里加个 Discriminator&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-06.png&quot; alt=&quot;Unsupervised-CGAN-06&quot; /&gt;&lt;/p&gt;
&lt;p&gt;我们在最后加一个 Discriminator，这样就可以让图片足够清晰啦（这个结构和 VAE-GAN 一样）&lt;/p&gt;
&lt;p&gt;emmmm，还有他们 train 出来的 embedding 完全没有关系啊，语义不一致啊，这要如何解决呢？&lt;/p&gt;
&lt;p&gt;方式一（共享接近于表示那几层的参数）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-07.png&quot; alt=&quot;Unsupervised-CGAN-07&quot; /&gt;&lt;/p&gt;
&lt;p&gt;比较容易理解啦，这个 trick 在 Couple GAN（CoGAN） 中有使用，不过原论文图中 G（Decoder）在左面，D（Encoder）在右面，看起来就像是两侧的参数进行共享，但其实都一样啦，都是在接近特征空间进行 share&lt;/p&gt;
&lt;p&gt;方式二（加一个对 embedding 的 Discirminator）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-08.png&quot; alt=&quot;Unsupervised-CGAN-08&quot; /&gt;&lt;/p&gt;
&lt;p&gt;在 embedding 加一个 Domain Discriminator，用于判断该 embedding 来自 Domain X 还是 Domain Y，而 $Encoder_X$ 和 $Encoder_Y$ 则致力于骗过 Domain Discriminator，让其分不清原图到底来自哪个 Domain&lt;/p&gt;
&lt;p&gt;方式三（能够转一圈再回来的就是好 GAN）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-09.png&quot; alt=&quot;Unsupervised-CGAN-09&quot; /&gt;&lt;/p&gt;
&lt;p&gt;一个小 $x$ 的旅途：$x \to Encoder_X(x) \to Decoder_Y(Encoder_X(x)) \to Encoder_Y(Decoder_Y(Encoder_X(x))) \to Decoder_X(Encoder_Y(Decoder_Y(Encoder_X(x))))$ 然后我还要尽可能和我原来的样子一样……该方法被用于 ComboGAN&lt;/p&gt;
&lt;p&gt;方式三（这次少跑一点就好）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Unsupervised-CGAN-10.png&quot; alt=&quot;Unsupervised-CGAN-10&quot; /&gt;&lt;/p&gt;
&lt;p&gt;转 3/4 圈，然后要求在特征空间尽可能不变，有被用在 DTN 和 XGAN&lt;/p&gt;
&lt;h2&gt;GAN 背后的理论&lt;/h2&gt;
&lt;p&gt;那么 GAN 为什么是真的可行的呢？GAN 并不是简单的启发式算法，它也是有理论依据的哟&lt;/p&gt;
&lt;h3&gt;Generator&lt;/h3&gt;
&lt;p&gt;如果我们将已有数据看作一个 distribution 的，并将其记为 $P_{data}(x)$，那么我们所 train 的 G 生成的数据应当尽可能都在 $P_{data}$ 中，或者说 G 映射的目标 distribution $P_G$ 应当尽可能地贴近 $P_{data}$&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/GAN-Theory-01.png&quot; alt=&quot;GAN-Theory-01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;如何让它们尽可能贴近？最大化 Likelihood，也即从 $P_{data}$ 里 sample 出来一些数据 ${x^1, x^2, \cdots, x^m}$，既然它们 Likelihood 相似，那么 $L = \prod \limits_{i=1}^m P_G(x_i; \theta)$ 也应当取得最大值，那么我们就要找到使得这个 Likelihood 最大的参数 $\theta^*$，也即&lt;/p&gt;
&lt;p&gt;$$
\theta^* = arg\max\limits_\theta \prod\limits_{i=1}^m P_G(x^i; \theta)
$$&lt;/p&gt;
&lt;p&gt;经过一点点推导，我们发现最大化这个 Likelihood 等价于最小化两个分布之间的 KL Divergence（还是蛮直觉的）&lt;/p&gt;
&lt;p&gt;$$
\theta^* = arg\min\limits_\theta KL(P_{data} || P_G)
$$&lt;/p&gt;
&lt;p&gt;也即&lt;/p&gt;
&lt;p&gt;$$
G^* = arg\min\limits_G KL(P_{data} || P_G)
$$&lt;/p&gt;
&lt;p&gt;那么如何计算这个 Divergence，我们的 G 是一个复杂的 network，它的分布并不能直接衡量，当然 $P_{data}$ 也不能直接衡量，emmm，那么第二个主角就该登场了&lt;/p&gt;
&lt;h3&gt;Discriminator&lt;/h3&gt;
&lt;p&gt;我们训练一个 D 来告诉我们 Divergence 有多大，之前已经知道训练它是使用二分类的方法，此时相当于最大化下式&lt;/p&gt;
&lt;p&gt;$V(G, D) = E_{x~P_{data}}[\log D(x)] + E_{x~P_G}[\log (1 - D(x))]$&lt;/p&gt;
&lt;p&gt;其中 G 是 fixed 住的&lt;/p&gt;
&lt;p&gt;也就是说&lt;/p&gt;
&lt;p&gt;$$
D^* = arg\max\limits_{D} V(G, D)
$$&lt;/p&gt;
&lt;p&gt;那么……为什么这样是可以的？&lt;/p&gt;
&lt;p&gt;经过亿点推算，我们可以得到&lt;/p&gt;
&lt;p&gt;$$
\max\limits_D V(G, D) = -2\log 2 + 2JSD(P_{data} || P_G)
$$&lt;/p&gt;
&lt;p&gt;其中，$JSD(P_{data}||P_G)$ 是指 $P_{data}$ 和 $P_G$ 之间的 JS Divergence，那么……我们是不是可以用 JS Divergence 替换之前的 KL Divergence？emmm，其实不能直接替换，JS Divergence 和 KL Divergence 是不同的衡量标准，但……它们确实也都是衡量标准，先换上试试看&lt;/p&gt;
&lt;p&gt;$$
G^* = arg\min\limits_G\max\limits_D V(G, D)
$$&lt;/p&gt;
&lt;p&gt;也就是说，在每个 G 中，我们先找到 V(G, D) 的最大值 $V(G_i, D^&lt;em&gt;)$，然后从这些 G 中挑选出使得各自 $V(G_i, D^&lt;/em&gt;)$最小的 $G^*$&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/GAN-Theory-02.png&quot; alt=&quot;GAN-Theory-02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;从上图而言，就是各个 G 先找出最大值，然后再取这些值之中的最小值对应的 G&lt;/p&gt;
&lt;h3&gt;Algorithm&lt;/h3&gt;
&lt;p&gt;那么为什么我们的 GAN 是用最开始那种算法的呢？我们的算法过程是在解 $G^* = arg\min\limits_G\max\limits_D V(G, D)$，也就是首先训练一个能够表征 JS Divergence 的 D，D 需要越精确越好，因此这个过程需要重复多次，尽可能收敛&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在每个迭代中，更新 D，重复以下过程 k 次
&lt;ul&gt;
&lt;li&gt;从 $P_{data}$ 中选取 ${x^1, x^2, \cdots, x^m}$&lt;/li&gt;
&lt;li&gt;从 $P_{prior}(z)$ 中选取 ${z^1, z^2, \cdots, z^m}$，喂给 $G$ 获得 ${\tilde{x}^1, \tilde{x}^2, \cdots, \tilde{x}^m}$，其中 $\tilde{x}^i = G(z^i)$&lt;/li&gt;
&lt;li&gt;更新 D 的参数 $\theta_d$
&lt;ul&gt;
&lt;li&gt;$\tilde{V} = \frac{1}{m} \sum\limits_{i=1}^m \log D(x^i) + \frac{1}{m} \log (1 - D(\tilde{x}^i))$&lt;/li&gt;
&lt;li&gt;$\theta_d \leftarrow \theta_d + \eta \nabla \tilde{V}(\theta_d)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么，我们就认为这个 D 能够代表 JS Divergence，更新一下 G，但不能更新太多，当 G 过度更新时，$V(G, D)$ 也被更新，而 JS Divergence 是 $\max V(G, D)$，可能此时的 D 已经不能代表 JS Divergence 了，因此 G 的更新比较少，可能只有一次&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在每个迭代中，更新 G，重复以下过程 1 次
&lt;ul&gt;
&lt;li&gt;从 $P_{prior}(z)$ 中选取 ${z^1, z^2, \cdots, z^m}$&lt;/li&gt;
&lt;li&gt;更新 G 的参数 $\theta_g$
&lt;ul&gt;
&lt;li&gt;$\tilde{V} = \sout{\frac{1}{m} \sum\limits_{i=1}^m \log D(x^i) +} \frac{1}{m} \log (1 - D(G(z^i)))$&lt;/li&gt;
&lt;li&gt;$\theta_g \leftarrow \theta_g - \eta \nabla \tilde{V}(\theta_g)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ian Goodfellow 在 G 的更新中使用 $\tilde{V} = \frac{1}{m} (- \log (D(x)))$ 替换了原式的 $\tilde{V} = \frac{1}{m} \log (1 - D(x))$，这样……在实际操作时就变得更加简单了，训练 G 时只需要将 G 生成的标签翻转改为 1 即可，G 和 D 可以直接使用同一个 Loss 函数&lt;/p&gt;
&lt;p&gt;为了区分两者，Ian Goodfellow 将原始的式子 $\tilde{V} = \frac{1}{m} \log (1 - D(x))$ 称为 Minimax GAN（MMGAN），将修改后的 $\tilde{V} = \frac{1}{m} (- \log (D(x)))$ 称为 Non-saturating GAN（NSGAN）&lt;/p&gt;
&lt;h2&gt;算法改进&lt;/h2&gt;
&lt;p&gt;通常，JS Divergence 并不是特别合适，因为它对两个无重叠的两个分布的测度永远为 $\log 2$，因此梯度永远为 0，G 无法得到更新&lt;/p&gt;
&lt;p&gt;换言之，它并不能评估两个无重叠分布之间的“距离”，然而 G 生成分布和真实分布在训练之初基本上不可能重叠，这就导致了当 D 训练地太好时，G 将会没有梯度，训练无法进行下去&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Improving-GAN-01.png&quot; alt=&quot;Improving-GAN-01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;为了使 GAN 能够正常训练，就需要一些算法上的一些技巧以及理论改进&lt;/p&gt;
&lt;h3&gt;LSGAN（Least Square GAN）&lt;/h3&gt;
&lt;p&gt;LSGAN 从 D 的分类器角度来进行改进，它认为 D 最终使用的是 Sigmoid 进行激活，会导致两侧梯度较小，进而发生梯度消失的现象，因此……就直接改成线性的了&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Improving-GAN-02.png&quot; alt=&quot;Improving-GAN-02&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;fgan: General Framework of GAN&lt;/h3&gt;
&lt;p&gt;如果不想使用 JS Divergence 的话，fGAN 从理论上给出了其它各种 Divergence 在 GAN 中的使用方法&lt;/p&gt;
&lt;h3&gt;WGAN（Wasserstein GAN）&lt;/h3&gt;
&lt;p&gt;WGAN 用了一种新的评估距离方式——Wasserstein 距离，由于它并不是 Divergence，因此 fGAN 中并没有该方式&lt;/p&gt;
&lt;p&gt;该方式可以理解为将其中一个分布变成另一个分布所需最少移动次数，它能够表征两个无重叠分布之间的距离&lt;/p&gt;
&lt;p&gt;那么，Wasserstein 距离到底要如何计算呢？emm，就像这样&lt;/p&gt;
&lt;p&gt;$V(G, D) = \max\limits_{D \in 1-Lipschitz} { E_{x \sim P_{data}} [D(x)] - E_{x \sim P_G} [D(x)]}$&lt;/p&gt;
&lt;p&gt;这里 $1-Lipschitz$ 是约束 D 为一个光滑的函数，它不能变化地太快，那么……如何约束它呢&lt;/p&gt;
&lt;p&gt;一是 WGAN 中提出的方法，Weight Clipping，也就是将 weights 截断在某个范围内，防止 weights 太大，从而保证函数不会变化太快&lt;/p&gt;
&lt;p&gt;另一个是 WGAN-GP 中提出的方法，是从梯度的角度进行约束，因为 $1-Lipschitz$ 函数满足任意位置导数不大于 1，因此我们可以通过一点约束以使得 D 的导数不大于 1 即可&lt;/p&gt;
&lt;p&gt;$V(G, D) = \max\limits_{D \in 1-Lipschitz} { E_{x \sim P_{data}} [D(x)] - E_{x \sim P_G} [D(x)] - \lambda \int_x \max(0, || \nabla_x D(x) || - 1) dx }$&lt;/p&gt;
&lt;p&gt;最后一项的补偿能够保证 D 不大于 1，但……最后一项的要求是对于全部 x 都满足才可以，事实上这也是不可能的，WGAN-GP 中提出只需要使得 $P_{penalty}$ 全部满足就好了，并将从 $P_{data}$ 和 $P_G$ 中 Sample 出来的样本之间连线上随机取样作为 $P_{penalty}$&lt;/p&gt;
&lt;p&gt;$V(G, D) = \max\limits_{D \in 1-Lipschitz} { E_{x \sim P_{data}} [D(x)] - E_{x \sim P_G} [D(x)] - \lambda E_{x \sim P_{penalty}} \max(0, || \nabla_x D(x) || - 1) }$&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/Improving-GAN-03.png&quot; alt=&quot;Improving-GAN-02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;WGAN-GP 在实际应用中使用的是&lt;/p&gt;
&lt;p&gt;$V(G, D) = \max\limits_{D \in 1-Lipschitz} { E_{x \sim P_{data}} [D(x)] - E_{x \sim P_G} [D(x)] - \lambda E_{x \sim P_{penalty}} (|| \nabla_x D(x) || - 1)^2 }$&lt;/p&gt;
&lt;p&gt;因为效果更好一些&lt;/p&gt;
&lt;p&gt;算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在每个迭代&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更新 D，重复以下过程 k 次
&lt;ul&gt;
&lt;li&gt;从 $P_{data}$ 中选取 ${x^1, x^2, \cdots, x^m}$&lt;/li&gt;
&lt;li&gt;从 $P_{prior}(z)$ 中选取 ${z^1, z^2, \cdots, z^m}$，喂给 $G$ 获得 ${\tilde{x}^1, \tilde{x}^2, \cdots, \tilde{x}^m}$，其中 $\tilde{x}^i = G(z^i)$&lt;/li&gt;
&lt;li&gt;更新 D 的参数 $\theta_d$
&lt;ul&gt;
&lt;li&gt;$\tilde{V} = \frac{1}{m} \sum\limits_{i=1}^m D(x^i) - \frac{1}{m} D(\tilde{x}^i)$&lt;/li&gt;
&lt;li&gt;$\theta_d \leftarrow \theta_d + \eta \nabla \tilde{V}(\theta_d)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;ul&gt;
&lt;li&gt;更新 G，重复以下过程 1 次
&lt;ul&gt;
&lt;li&gt;从 $P_{prior}(z)$ 中选取 ${z^1, z^2, \cdots, z^m}$&lt;/li&gt;
&lt;li&gt;更新 G 的参数 $\theta_g$
&lt;ul&gt;
&lt;li&gt;$\tilde{V} = -\frac{1}{m} D(G(z^i))$&lt;/li&gt;
&lt;li&gt;$\theta_g \leftarrow \theta_g - \eta \nabla \tilde{V}(\theta_g)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;D 最后不要用 Sigmoid，直接输出即可
另外，记得使用 Weight clipping 或者 Gradient Penalty&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;More GANs&lt;/h2&gt;
&lt;h3&gt;Stack GAN&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_StackGAN_Text_to_ICCV_2017_paper.pdf&quot;&gt;Han Zhang, Tao Xu, Hongsheng Li, et al. StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks”, ICCV, 2017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;直接 Generate 一个较为大的图往往是不容易的，StackGAN 将该过程分解为多步，先让 $G_1$ 生成一个较为小的图，然后再将这个小的图喂给 $G_2$，让 $G_2$ 据此生成一个较为大的图&lt;/p&gt;
&lt;h3&gt;Patch GAN&lt;/h3&gt;
&lt;p&gt;D 有时不太容易直接判别图片是否为真实，但我们可以让 D 每次只判断图片的某一块&lt;/p&gt;
&lt;h3&gt;EBGAN（Energy-based GAN）&lt;/h3&gt;
&lt;p&gt;使用 Auto Encoder 作为 D，这样使得 D 可以 pretrain，所以在训练之初就可以获得比较好的 G&lt;/p&gt;
&lt;h3&gt;Info GAN&lt;/h3&gt;
&lt;p&gt;使 GAN 的输入 code 各个维度更加正交，将输入 code 分为两部分，一部分带有分类信息 $c$，这个分类信息要求后续 Classifier 能够还原出来，另外一部分就是噪声 $z&apos;$&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/InfoGAN.png&quot; alt=&quot;InfoGAN&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;VAE-GAN&lt;/h3&gt;
&lt;p&gt;VAE 与 GAN 的结合，D 需要能够分辨&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从真实图片经过 VAE 重构后的图片&lt;/li&gt;
&lt;li&gt;从噪声经过 G 生成的图片&lt;/li&gt;
&lt;li&gt;真实图片&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;三者&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/VAE-GAN.png&quot; alt=&quot;VAE-GAN&quot; /&gt;&lt;/p&gt;
&lt;h3&gt;BiGAN&lt;/h3&gt;
&lt;p&gt;有一个 Encoder，输入图片，输出 code&lt;/p&gt;
&lt;p&gt;有一个 Decoder，输入 code，输出图片&lt;/p&gt;
&lt;p&gt;有一个 D，输入一对图片与 code，然后判断它们是经由 Encoder 生成还是经由 Decoder 生成&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/gan-started/BiGAN.png&quot; alt=&quot;BiGAN&quot; /&gt;&lt;/p&gt;
&lt;p&gt;至于为什么有效，D 使得 Encoder 对应的 distribution $P(x, z)$ 与 Decoder 的 distribution $Q(x, z)$ 尽可能地接近&lt;/p&gt;
&lt;p&gt;BiGAN 的训练类似于同时训练一个 Decoder $\to$ Encoder，与一个反向的 Encoder $\to$ Decoder，而 BiGAN 的效果会更好些&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLDS18.html&quot;&gt;Hung-yi Lee MLDS18&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/76340704&quot;&gt;基于 GAN 的动漫头像生成&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zxth93.github.io/2017/09/27/KL%E6%95%A3%E5%BA%A6JS%E6%95%A3%E5%BA%A6Wasserstein%E8%B7%9D%E7%A6%BB/index.html&quot;&gt;KL 散度、JS 散度、Wasserstein 距离&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>TensorFlow 踩坑记：训练状态的设置</title><link>https://nyakku.moe/posts/tensorflow-learning-phase-setting/</link><guid isPermaLink="true">https://nyakku.moe/posts/tensorflow-learning-phase-setting/</guid><pubDate>Wed, 08 Apr 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;虽然说 TensorFlow V2 比 V1 易用性提高了很多，但杂乱的 API 还是让人抓狂，特别是 Keras 中有着多种多样的模型实现方式（最简单的 Sequential、最灵活的 Functional、最规整的 SubClass）以及训练方式（fit 和自己写训练循环），fit 过于封装，有时候想加点东西都挺麻烦，而自己写循环又怕效率较低，也可能会忽略点什么，果不其然，最近又发现了训练状态的设置问题，于是它差点又把我推向了 PyTorch 的怀抱&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;为什么要设定训练状态&lt;/h2&gt;
&lt;p&gt;由于某些层在训练时会使用与测试时不一致的行为（主要指 BN 层与 Dropout 层），所以自己写训练 Loop 时候需要设定一下训练状态，但要如何改变这个状态？？？嗯由于 TensorFlow 文档基本都用的 fit 方式，所以……基本没有看到与状态设定有关的 API&lt;/p&gt;
&lt;p&gt;之后我看到了 [1] 这篇文章才了解到训练状态的指定方式，但原文中涵盖不太全面，我稍微进一步进行了测试（由于基本不用 fit 方式，而且 fit 方式也没这方面的问题，所以仅针对自写循环方式进行测试）&lt;/p&gt;
&lt;h2&gt;三种模型定义方式&lt;/h2&gt;
&lt;p&gt;对于三种模型定义方式，并没有什么不同，并不需要修改 SubClass 的定义方式&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Sequential
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, 3),
    tf.keras.layers.BatchNormalization()
])

# Functional
inputs = tf.keras.Input(shape=data.shape[1: ])
x = inputs
x = tf.keras.layers.Conv2D(16, 3)(x)
x = tf.keras.layers.BatchNormalization()(x)
outputs = x
model = tf.keras.Model(inputs=inputs, outputs=outputs)

# SubClass
class Model(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.conv = tf.keras.layers.Conv2D(16, 3)
        self.bn = tf.keras.layers.BatchNormalization()

    def call(self, input):
        x = input
        x = self.conv(x)
        x = self.bn(x)
        output = x
        return output
model = Model()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;模型在训练时候需要指定 &lt;code&gt;training=True&lt;/code&gt;（默认值是 &lt;code&gt;None&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model(data, training=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样，训练时 BN 才能更新 &lt;code&gt;moving_mean&lt;/code&gt; 和 &lt;code&gt;moving_variance&lt;/code&gt;，相应地，如果是 Dropout，这样才会 dropout 掉部分 neurons&lt;/p&gt;
&lt;h2&gt;tf.keras.backend.set_learning_phase&lt;/h2&gt;
&lt;p&gt;那么，另外一种改变状态的方式 &lt;code&gt;tf.keras.backend.set_learning_phase&lt;/code&gt; 是否有效呢？经过测试也是可以的，但是要注意一个问题，当在 &lt;code&gt;model&lt;/code&gt; 中指定训练状态时，会忽略掉这个设置&lt;/p&gt;
&lt;p&gt;这使得即便之前指定了 &lt;code&gt;tf.keras.backend.set_learning_phase(True)&lt;/code&gt;，若同时使用了 &lt;code&gt;model(data, training=False)&lt;/code&gt; 的话，实际执行的仍然是非训练状态&lt;/p&gt;
&lt;p&gt;也就是说，只有当 &lt;code&gt;training&lt;/code&gt; 没有指定（&lt;code&gt;None&lt;/code&gt;）的时候，才会使用 &lt;code&gt;tf.keras.backend.set_learning_phase&lt;/code&gt; 的值，而指定后则忽略 &lt;code&gt;tf.keras.backend.set_learning_phase&lt;/code&gt; 的值&lt;/p&gt;
&lt;h2&gt;所以要怎么训练？&lt;/h2&gt;
&lt;p&gt;还是有两种方式耶，喜欢哪种就用哪种吧&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# training
tf.keras.backend.set_learning_phase(True)
model(data)

# testing
tf.keras.backend.set_learning_phase(False)
model(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# training
model(data, training=True)

# testing
model(data)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于后者更方便一些，所以我一般选用后者&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/64310188&quot;&gt;TensorFlow 2.0+Keras 防坑指南&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>Manjaro 初体验</title><link>https://nyakku.moe/posts/first-experience-for-manjaro/</link><guid isPermaLink="true">https://nyakku.moe/posts/first-experience-for-manjaro/</guid><pubDate>Mon, 06 Apr 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;虽然此前也接触 Linux 很久了，但平时也只是作为备用系统偶尔用用罢了，之前也用过一段时间 deepin，但是有很多细节上有 bug，一段时间后还是将 Windows 作为我的主力系统了。&lt;/p&gt;
&lt;p&gt;前段时间了解到了 Manjaro 这个 Linux 发行版，可以非常方便地安装软件，所以决定尝试一下下～&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
 ██████████████████  ████████     nyakku@shigure-yuu
 ██████████████████  ████████     OS: Manjaro 21.3.5 Ruah
 ██████████████████  ████████     Kernel: x86_64 Linux 5.15.55-1-MANJARO
 ██████████████████  ████████     Uptime: 4m
 ████████            ████████     Packages: 1175
 ████████  ████████  ████████     Shell: zsh 5.9
 ████████  ████████  ████████     Disk: 13G / 94G (14%)
 ████████  ████████  ████████     CPU: Intel Core i5-7500 @ 4x 3.8GHz [35.0°C]
 ████████  ████████  ████████     GPU: NVIDIA GeForce GTX 1050
 ████████  ████████  ████████     RAM: 964MiB / 7913MiB
 ████████  ████████  ████████
 ████████  ████████  ████████
 ████████  ████████  ████████
 ████████  ████████  ████████

&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Manjaro 的安装&lt;/h2&gt;
&lt;p&gt;首先在&lt;a href=&quot;https://manjaro.org/download/&quot;&gt;官网下载&lt;/a&gt;镜像，我选择的桌面环境是 KDE Plasma。使用 &lt;a href=&quot;https://github.com/ventoy/Ventoy&quot;&gt;Ventoy&lt;/a&gt; 制作一个启动盘，然后用 U 盘启动即可。&lt;/p&gt;
&lt;p&gt;U 盘启动后会有时区、键盘、语言的配置，之后的 Boot 不是配置项，在选择它之前先修改下前几项&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tz = Asia/Shanghai
keytable = us
lang = zh_CN
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于深度学习的显卡加速需要闭源驱动，因此选择 &lt;code&gt;Boot with proprietary drivers&lt;/code&gt; 来启动&lt;/p&gt;
&lt;p&gt;之后会进入桌面环境，会有些配置选项，这些简单配置下就好，其中分区需要注意一下，最好手动分区一下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/&lt;/code&gt; 15-20GB 根目录，由于包含 &lt;code&gt;/usr&lt;/code&gt; 所以会有安装的各种软件，不能太小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/boot&lt;/code&gt; 512MB&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/var&lt;/code&gt; 8-12GB，主要是缓存，读写频繁&lt;/li&gt;
&lt;li&gt;&lt;code&gt;swap&lt;/code&gt; 4GB，交换分区&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/home&lt;/code&gt; 剩余全部&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;再之后直接安装就好啦～静待片刻，Manjaro 之旅就正式开始啦～&lt;/p&gt;
&lt;h2&gt;换源&lt;/h2&gt;
&lt;p&gt;二话不说，先换个源&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman-mirrors -i -c China -m rank   # 更新镜像排名
sudo pacman -Syy                          # 更新数据源
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;添加 &lt;code&gt;archlinuxcn&lt;/code&gt; 镜像，在 &lt;code&gt;/etc/pacman.conf&lt;/code&gt; 中添加以下内容&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[archlinuxcn]
Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;更多镜像见 &lt;a href=&quot;https://github.com/archlinuxcn/mirrorlist-repo&quot;&gt;mirrorlist-repo&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;安装软件&lt;/h2&gt;
&lt;h3&gt;使用 pacman 安装&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;pacman&lt;/code&gt; 是 Manjaro 下的软件包管理器，有点类似于 Ubuntu 下的 &lt;code&gt;apt&lt;/code&gt;，只不过参数稍稍不一样，安装软件需要这样&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S &amp;lt;package_names&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;使用 yay 安装&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;yay&lt;/code&gt; 是 AUR 仓库的包管理器，那么什么是 AUR 呢？AUR 是 Arch 的社区维护软件仓库，而不是官方的，所以如果 &lt;code&gt;pacman&lt;/code&gt; 有下不到的软件可以使用 &lt;code&gt;yay&lt;/code&gt; 试一下&lt;/p&gt;
&lt;p&gt;用 &lt;code&gt;yay&lt;/code&gt; 之前先开启 AUR，软件包管理器 -&amp;gt; 首选项 -&amp;gt; 第三方 -&amp;gt; 启用 AUR 支持&lt;/p&gt;
&lt;p&gt;之后需要安装 &lt;code&gt;yay&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S yay
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后就可以使用 &lt;code&gt;yay&lt;/code&gt; 愉快地安装各种软件啦&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S &amp;lt;package_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;安装 deb 包&lt;/h3&gt;
&lt;p&gt;有些软件只提供 debian 系的包，但我们可以使用 debtap 将其转换为 Arch package（debtap 是 DEB To Arch (Linux) Package 的缩写），然后再进行安装&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 安装 debtap
yay -S debtap
# 更新 debtap
sudo debtap -u
# 使用 debtap 进行转换（Licence 可以填 GPL）
sudo debtap &amp;lt;package_name&amp;gt;.deb
# 使用 pacman 安装
sudo pacman -U &amp;lt;package_name&amp;gt;.tar.xz
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;一些常用软件及安装方式&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;vim&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S vim
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sunpinyin&lt;/p&gt;
&lt;p&gt;听说 Linux 版搜狗输入法有点问题，之前在 Deepin 下确实遇到些 Bug，所以就不选了，这里用 &lt;code&gt;Sunpinyin&lt;/code&gt; 配合 &lt;code&gt;Cloudpinyin&lt;/code&gt;，在那之前需要先安装输入法管理器 &lt;code&gt;fcitx&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S fcitx-im
sudo pacman -S fcitx-configtool
sudo pacman -S fcitx-sunpinyin
sudo pacman -S fcitx-cloudpinyin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;并将以下内容添加到 &lt;code&gt;/etc/profile&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export GTK_IM_MODULE=fcitx
export QT_IM_MODULE=fcitx
export XMODIFIERS=&quot;@im=fcitx&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后在 fcitx 将 &lt;code&gt;Sunpinyin&lt;/code&gt; 调整为第二输入法并移除多余输入法即可&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;chrome&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S google-chrome
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;spotify&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S spotify
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vscode&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S visual-studio-code-bin
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;WPS&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S wps-office
yay -S ttf-wps-fonts
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;flameshot&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S flameshot
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;simplescreenrecorder&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yay -S simplescreenrecorder
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;美化&lt;/h2&gt;
&lt;h3&gt;Shell 美化&lt;/h3&gt;
&lt;p&gt;zsh 相对于 bash 拥有更强的功能，而且也更加美观&lt;/p&gt;
&lt;p&gt;参考 &lt;a href=&quot;https://ohmyz.sh/&quot;&gt;&lt;code&gt;os-my-zsh&lt;/code&gt; 官网&lt;/a&gt;，输入下面的命令就可以美化优化 zsh 了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后编辑 &lt;code&gt;~/.zshrc&lt;/code&gt;，修改下主题就能拥有更加美观的 zsh 了（暂时使用的是 &lt;code&gt;agnoster&lt;/code&gt;）&lt;/p&gt;
&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;有些主题在 VS Code 里不能正确显示，需要修改下 Terminal 的字体，我改成了 &lt;code&gt;Menlo for Powerline&lt;/code&gt;，如果没有该字体，下载并安装下即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/abertsch/Menlo-for-Powerline.git  # 下载字体
cd Menlo-for-Powerline
sudo cp *.ttf* /usr/share/fonts/TTF/                           # 手动安装到字体文件夹
sudo fc-cache -f -v                                            # 刷新字体
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后修改 VS Code Settings 中 Terminal 的 Font Family 即可&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;h3&gt;Dock&lt;/h3&gt;
&lt;p&gt;首先安装一个 &lt;code&gt;Dock&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pacman -S latte-dock
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;略作配置即可&lt;/p&gt;
&lt;p&gt;现在底部的面板就有点多余了，移到上面去～然后将无用的部件也都去掉&lt;/p&gt;
&lt;h3&gt;主题更换&lt;/h3&gt;
&lt;p&gt;KDE 的主题更换都超简单，直接在设置里就能完成&lt;/p&gt;
&lt;p&gt;设置 -&amp;gt; 系统设置 -&amp;gt; 外观 -&amp;gt; 全局主题&lt;/p&gt;
&lt;p&gt;在这里不仅可以修改主题，还可以在主题库中搜索主题哦，更重要的是，不止全局主题可以，鼠标样式、图标样式等等都可以在丰富的库中寻找资源，一键即可美化系统～&lt;/p&gt;
&lt;h2&gt;一些小问题&lt;/h2&gt;
&lt;h3&gt;双系统时间差问题&lt;/h3&gt;
&lt;p&gt;由于 Windows 与 Linux 显示时间的方式不太一样，所以每次切换系统总是需要改一下时间，如果让这两个系统任意一个妥协使用对方的计时标准即可，这里因为 Manjaro 操作方便，就在 Manjaro 修改了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo timedatectl set-local-rtc true
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;卡在开机界面&lt;/h3&gt;
&lt;p&gt;emmmm，刚折腾一天把所有基本该折腾的折腾完了，我突然想把 Krunner 给卸了，然后居然把整个 KDE 给卸了，结果再开机我就卡在登陆界面了&lt;/p&gt;
&lt;p&gt;为了能够重新安装 KDE，首先需要进入终端，在卡住的界面按 &amp;lt;kbd&amp;gt;Ctrl&amp;lt;/kbd&amp;gt; + &amp;lt;kbd&amp;gt;Alt&amp;lt;/kbd&amp;gt; + &amp;lt;kbd&amp;gt;F4&amp;lt;/kbd&amp;gt; 进入 tty4，然后输入用户名和密码登陆&lt;/p&gt;
&lt;p&gt;为了能够联网下载，需要使用 &lt;code&gt;ifconfig&lt;/code&gt; 开启无线网卡，但如果 &lt;code&gt;ifconfig&lt;/code&gt; 也没有安装怎么办……一种解决方法是通过数据线将 Android 手机与电脑相连接，在手机上开启 USB 共享网络即可&lt;/p&gt;
&lt;p&gt;之后重装 KDE 并重启就又看到了熟悉的开机界面了&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://juejin.im/post/5c6d0a1051882561ad329255&quot;&gt;Manjaro 美化与调优&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1pJ411N75i&quot;&gt;Manjaro-KDE 美化&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/83335242&quot;&gt;manjaro 安装 deb 包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.itdaan.com/blog/2017/12/02/2be8e9eaf332561e7ed94c35ba57e757.html&quot;&gt;如何解决 Windows 和 Manjaro 双系统时间差 8 小时的问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://ywnz.com/linuxaz/3504.html&quot;&gt;安装 Manjaro Linux 的详细步骤&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/comixH/p/12232252.html&quot;&gt;记 manjaro 图形驱动删除后的一次补救&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/lj402159806/article/details/80218360&quot;&gt;manjaro 安装分区以及配置方案&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.bilibili.com/video/av60476406/&quot;&gt;调教你的 manjaro，配合微信、TIM 食用，让它比 windows 还好用！&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/c2f8bc4e19c0&quot;&gt;Manjaro 下 vscode 中 zsh 乱码&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>模拟退火算法</title><link>https://nyakku.moe/posts/simulate-anneal/</link><guid isPermaLink="true">https://nyakku.moe/posts/simulate-anneal/</guid><pubDate>Sun, 22 Mar 2020 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;神经网络优化的最大难题就是很容易陷入局部最优，前段时间考虑神经网络优化方法的时候偶然考虑到了这样一个问题：能量为什么总是能达到最低呢？该问题促使我展开了一系列的思（xia）考（xiang），当然，瞎想也没想出个啥，直到今天遇到了模拟退火算法……&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;为什么能量总能达到最低？&lt;/h2&gt;
&lt;p&gt;这是一个热力学问题，能量也是有着局部最优的，但由于分子的热运动导致一部分分子能够跨越势垒进而达到更低的能量状态，而跨越势垒的分子数满足一定的概率分布（阿伦尼乌兹公式）&lt;/p&gt;
&lt;p&gt;（这段纯属胡说八道，可以跳过）咦？原来是这样呀，我想了一段时间后得出了结论：概率分布嘛，那感觉有点 Monte Carlo 的感觉了，分子是比较多的嘛，那么整体的能量总会是最低的，就类似于 Ensemble 那样咯，网络宽一些会更好？&lt;/p&gt;
&lt;p&gt;咳咳，好了进入正题，今天才发现根据前面的阿伦尼乌兹公式，有着一种启发式搜索算法，其名为模拟退火算法，嗯，一听名字倍感亲切啊，这不就是我专业学的吗~那么到底什么是模拟退火算法呢？这到底是不是金属热处理中所说的那种退火呢？&lt;/p&gt;
&lt;h2&gt;啥是退火？&lt;/h2&gt;
&lt;p&gt;就材料加工而言，工业上常说有四把火，分别是退火、正火、淬火、回火，这里举两个极端的例子&lt;/p&gt;
&lt;p&gt;一是淬火，这个大家应该也不会陌生，应该都有见过将烧热的金属放入冷水中淬炼的相关场景。很明显，这是使得金属温度骤降，进而内部发生某些变化以达到更高的硬度（具体原因不详细说明），但是这对于金属本身而言，它的能量并不是最低的（稳定相），而是陷入某些局部最低点（亚稳相），这有点像我们使用 BP 等优化算法陷入的局部最优解&lt;/p&gt;
&lt;p&gt;另一个就是今天的主角退火啦，虽然淬火后有些性能（比如硬度）是比较好的，但其他性能可能会很差，退火是为了让金属达到能量最低的状态（稳定相），与淬火相反的是，我们只需要缓慢地降低温度，它总能达到能量最低的状态（稳定相）&lt;/p&gt;
&lt;p&gt;那么为什么只要温度降低的足够慢它就能达到能量最低的状态呢？这还要从热力学说起&lt;/p&gt;
&lt;h2&gt;相变势垒&lt;/h2&gt;
&lt;p&gt;我们优化时最大的障碍就是局部最优与全局最优之间的一个或多个“势垒”，热力学中也是这样，但分子（或原子）是有能力跨过这个势垒的，如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/simulate-anneal/SPT02.png&quot; alt=&quot;SPT02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;当分子处于 $\gamma$ 相时，每个分子并不会乖乖地待在原地不动，而是会根据分子的热运动以一定的概率跨过壁垒到达 $\alpha$ 相，这个现象使用阿伦尼乌兹公式描述&lt;/p&gt;
&lt;p&gt;$$
K = K_0 exp[-\frac{Q}{kT}]
$$&lt;/p&gt;
&lt;p&gt;其中 $K_0$ 是原 $\gamma$ 相的总分子数，$K$ 是其中转变为 $\alpha$ 相的分子数，由于是分子热运动，$T$ 自然就是温度，另外，由于势垒越高越难以跨越，所以这里的 $Q$ 就是势垒能量值，也就是上图中的 $\Delta g$， $k$ 是一个常数，当然，我们“爬山”的概率就是后面的 $exp[-\frac{Q}{kT}]$ 这一部分&lt;/p&gt;
&lt;p&gt;emmmm，那么退火时候为什么总能收敛到全局最优呢？这样看的话，最主要的原因就是其拥有以一定概率跨过壁垒的能力&lt;/p&gt;
&lt;h2&gt;一般的优化算法&lt;/h2&gt;
&lt;p&gt;在说退火在优化算法上的应用之前，先说一下其他的优化算法&lt;/p&gt;
&lt;h3&gt;Monte Carlo&lt;/h3&gt;
&lt;p&gt;第一种是一种最最最简单的算法，就是在可行解空间内不断地随机 sample 一些点出来，然后找到一个最小值就好了嘛，emmm，它的优点是没什么陷入全局最优的问题，但缺陷也很明显，当可行解空间比较大时，能 sample 到什么样的点就只能看脸了&lt;/p&gt;
&lt;h3&gt;爬山算法&lt;/h3&gt;
&lt;p&gt;然后我们使用稍微高级一点的，爬山算法（为了保持一致，我这里是向全局最小优化的，或者我们可以叫作“爬坑算法”），这个有点类似于 BP，但是并不需要求梯度，它只不过是将 BP 优化中的“向梯度最小的方向移动一步”改成了“随机看看周围某一个位置的情况，如果比当前位置低则移到该位置”，实现起来非常简单，就像这样&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
import numpy as np
import matplotlib.pyplot as plt

X_BOUND = [-2, 5]

def F(x):
    return x*(x-1)*(x-2)*(x-4)

num_epochs = 10000
x_set = []
initial_value = np.random.uniform(*X_BOUND, size=1)

x = initial_value.copy()
y = F(x)

for i in range(num_epochs):
    # 随机移动的方向
    dx = learning_rate * (X_BOUND[1] - X_BOUND[0]) * (2*np.random.random()-1)
    y_new = F(x+dx)
    # 如果更低则移动
    if y_new &amp;lt; y:
        y = y_new
        x += dx
        x_set.append(x.copy())
best = x + dx

x = np.linspace(*X_BOUND, 200)
plt.plot(x, F(x))
plt.scatter(np.array(x_set), F(np.array(x_set)), c=&apos;r&apos;)
plt.scatter(initial_value, F(initial_value), c=&apos;white&apos;)
plt.scatter(best,F(best), c=&apos;black&apos;)
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/simulate-anneal/SA01.png&quot; alt=&quot;SA01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;实现是很简单，但是这样很容易陷入局部最优，然后就再也跳不粗来了~&lt;/p&gt;
&lt;h2&gt;模拟退火算法&lt;/h2&gt;
&lt;p&gt;如果我们给爬山算法一种以一定概率走向能量更高的位置的能力，是不是就很像分子热运动了？至于概率嘛，就是前面的阿伦尼乌兹公式里的 $exp[-\frac{Q}{kT}]$ 啦，不过由于 $k$ 只是一个常数，我们可以合并到 $T$ 中，由于我们要模拟金属的缓慢冷却，温度是需要缓慢衰减的，至于衰减方法嘛是有很多的，比如每次变成上次的 0.99 倍之类，这里使用 $T(k) = \frac{T(0)}{\ln (1 + k)}$ 这种衰减方案，其中 $k$ 表示迭代次数&lt;/p&gt;
&lt;p&gt;代码很简单，简单改改就好了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- sa01.py             2021-01-04 17:04:26.000000000 +0800
+++ sa02.py             2021-01-04 17:06:18.000000000 +0800
@@ -6,6 +6,8 @@
 def F(x):
     return x*(x-1)*(x-2)*(x-4)

+t0 = 5.0
+t = t0
 num_epochs = 10000
 learning_rate = 0.01
 x_set = []
@@ -23,6 +25,17 @@
         y = y_new
         x += dx
         x_set.append(x.copy())
+    # 如果更高则以一定概率移动
+    else:
+        prob = 1.
+        if t != 0:
+            prob = np.exp((y - y_new) / t)
+        if prob &amp;gt;= np.random.random():
+            y = y_new
+            x += dx
+            x_set.append(x.copy())
+    # 冷却
+    t = t0 / np.log(1 + i)

 best = x + dx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/simulate-anneal/SA02.png&quot; alt=&quot;SA02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;从图中确实可以看出，模拟退火算法有着更好的跳出局部最优的能力（图中白点为起始点，黑点为最终点）&lt;/p&gt;
&lt;h2&gt;更一般的猜想&lt;/h2&gt;
&lt;p&gt;为什么分子热运动会以那样的概率跨过势垒呢？是不是因为每个分子都会以一定的概率跳到某个能量的位置呢？如果这么想的话，便有&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
P(E &amp;gt; E_0 + Q) &amp;amp;= e^{-\frac{Q}{kT}} \
P(E \leq E_0 + Q) &amp;amp;= 1 - e^{-\frac{Q}{kT}}
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;嘛，这不是指数分布嘛，那么我们完全可以算出达到某一能量的概率&lt;/p&gt;
&lt;p&gt;$$
P(E = E_0 + Q) = -\frac{1}{kT} e^{-\frac{Q}{kT}}
$$&lt;/p&gt;
&lt;p&gt;那么，我们以指数分布得到一个能量值 $Q$ ，将 $E_0 + Q$ 作为当前可能达到的能量值，直接与 sample 到的下一个位置真实能量值作比较，如果比它大则移动，这样实现的话会更加简单些，这里展示下与爬山算法不同的地方&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- sa01.py             2021-01-04 17:04:26.000000000 +0800
+++ sa03.py             2021-01-04 17:07:19.000000000 +0800
@@ -6,6 +6,8 @@
 def F(x):
     return x*(x-1)*(x-2)*(x-4)

+t0 = 5.0
+t = t0
 num_epochs = 10000
 learning_rate = 0.01
 x_set = []
@@ -18,11 +20,15 @@
     # 随机移动的方向
     dx = learning_rate * (X_BOUND[1] - X_BOUND[0]) * (2*np.random.random()-1)
     y_new = F(x+dx)
+    # 分子热运动所带来的“能量”，sample 自指数分布
+    delta_y = np.random.exponential(t, size=1)
     # 如果更低则移动
-    if y_new &amp;lt; y:
+    if y_new &amp;lt; y + delta_y:
         y = y_new
         x += dx
         x_set.append(x.copy())
+    # 冷却
+    t = t0 / np.log(1 + i)

 best = x + dx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/simulate-anneal/SA03.png&quot; alt=&quot;SA03&quot; /&gt;&lt;/p&gt;
&lt;p&gt;是不是非常简单，而且效果确实和模拟退火算法一样呢，这样的话，也许这种实现能够很容易地和其它优化算法相结合（替换掉爬山算法），以达到更好的效果&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://drivingc.com/p/5c3f25614b0f2b766c70fd13&quot;&gt;模拟退火算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/47628209&quot;&gt;兄弟，退火吗？—— 初窥模拟退火算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/heaad/archive/2010/12/20/1911614.html&quot;&gt;大白话解析模拟退火算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;机器学习 - 周志华&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>Git 协作模式</title><link>https://nyakku.moe/posts/git-collaboration/</link><guid isPermaLink="true">https://nyakku.moe/posts/git-collaboration/</guid><pubDate>Sat, 26 Oct 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;虽然平时写个笔记都会使用 Git 来保存，但常用的也就只有 &lt;code&gt;add&lt;/code&gt;、&lt;code&gt;commit&lt;/code&gt;、&lt;code&gt;push&lt;/code&gt; 等等简单的命令啦，偶尔出点问题都需要去现查，为了提高效率，我在这里整理一下简单的 Git 协作命令，以备不时之需ヽ(✿ ﾟ ▽ ﾟ)ノ&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预备知识
&lt;ul&gt;
&lt;li&gt;Git 基本命令&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;开发环境
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Git&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;单人的工作模式&lt;/h2&gt;
&lt;p&gt;首先从最基本的简单单人工作模式，渐进地增加一些指令&lt;/p&gt;
&lt;h3&gt;暂存文件&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git add *
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;提交文件&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git commit
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;推送到远程&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git push
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;使用 dev 分支&lt;/h3&gt;
&lt;p&gt;如果有一个需要做很久的功能，应当新建一个分支，以保证 &lt;code&gt;main&lt;/code&gt; 的稳定性&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout -b dev
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;合并其余分支内容&lt;/h3&gt;
&lt;p&gt;当在 &lt;code&gt;dev&lt;/code&gt; 分支上的工作完成后，回到 &lt;code&gt;main&lt;/code&gt; 并合并&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout main
git merge --no-ff dev            # 将 dev 合并回 main
git branch -d dev                # 移除无用的 dev 分支
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;:::tip[参数 --no-ff 的作用]&lt;/p&gt;
&lt;p&gt;如果你想保留下来临时分支的信息，可以增加 &lt;code&gt;--no-ff&lt;/code&gt; 参数，这将把临时分支的信息作为一次 commit 合并到目标分支，但同时也会保留临时分支的过程，下面的图一目了然&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/git-collaboration/git-collaboration01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;h2&gt;如何提交 PR&lt;/h2&gt;
&lt;p&gt;提交 PR 的最佳实践是现将原仓库 fork 到自己的账户下，然后&lt;strong&gt;新建一个分支&lt;/strong&gt;进行修改&lt;/p&gt;
&lt;h3&gt;首先 clone 下来你 fork 的 repo&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git clone git@github.com:SigureMo/vuepress.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然，该 &lt;code&gt;repo&lt;/code&gt; 已经绑定在远程仓库 &lt;code&gt;origin&lt;/code&gt; 上了&lt;/p&gt;
&lt;h3&gt;将原仓库绑定在 upstream&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git remote add upstream git@github.com:vuejs/vuepress.git
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样，你的 &lt;code&gt;upstream&lt;/code&gt; 就代表了原作者的远程分支，而 &lt;code&gt;origin&lt;/code&gt; 就代表了你 fork 后的远程分支&lt;/p&gt;
&lt;h3&gt;新建一个自己的分支&lt;/h3&gt;
&lt;p&gt;比如你想修改 &lt;code&gt;main&lt;/code&gt; 分支，那么直接以此为基础新建分支就好&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout main                # 如果已经在 main 则跳过
git checkout -b feature-xxx      # 新建一个分支，名称随意
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在再 &lt;code&gt;git branch&lt;/code&gt; 一下就可以发现新建了一个 &lt;code&gt;feature-xxx&lt;/code&gt; 分支，并且已经切换到该分支了&lt;/p&gt;
&lt;h3&gt;改动提交并推送&lt;/h3&gt;
&lt;p&gt;在你的 &lt;code&gt;feature-xxx&lt;/code&gt; 上进行修改，并 &lt;code&gt;commit&lt;/code&gt; 以及推送，推送的时候最好指定分支&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git push origin feature-xxx   # 将 feature-xxx 推送到 origin（也就是你 fork 后的 repo）
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;在 GitHub 发起 PR&lt;/h3&gt;
&lt;p&gt;如果你的修改想要合并回原作者分支，那么就发起 PR 吧，如果原作者 merge 了，你的 &lt;code&gt;feature-xxx&lt;/code&gt; 也可以删除了，后续从原作者那里重新获取 &lt;code&gt;main&lt;/code&gt; 就能拥有你的改动了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git branch -d feature-xxx              # 如果该分支已经没有作用了，可以直接删除
git push origin --delete feature-xxx   # 同时删除远程分支
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;解决冲突&lt;/h3&gt;
&lt;p&gt;如果你的 PR 与原作者的默认分支修改发生了冲突，那么最佳实践是我们基于原作者最新修改 rebase 一下。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git fetch upstream
git rebase upstream/main
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时应当会提示有冲突，我们手动将所有冲突解决后，add 它们，比如这里发生冲突的是 &lt;code&gt;conflicted.md&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git add conflicted.md
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后我们让 rebase 继续下去&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git rebase --continue
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;现在，我们的修改就会变成基于原作者最新进度的修改了。我们 push 一下，当然，由于我们本次改动对历史有影响，因此需要 force 一下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git push --force-with-lease
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;同步原作者更改&lt;/h3&gt;
&lt;p&gt;如果原作者更新了原来的分支，总不能每次都重新 fork 一下仓库吧，如果之前没有在原有分支上进行修改的话，现在就可以在避免手动合并的情况下同步原作者后续修改了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git checkout main                # 切换到 main
git fetch upstream               # 将原作者分支下载到本地
git merge upstream/main          # 将原作者 main 分支最新内容合并到本地 main
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;如何合并 PR&lt;/h2&gt;
&lt;p&gt;既然你能发起一个 PR ，那么你也有可能收到一个 PR ，如果发起 PR 的人能够按照上面的规范来做，并且能规范书写代码、规范提交 commit 的话，你可以很容易地在 GitHub 上判断是 close 还是直接 merge ，但如果对方的代码稍有欠缺，就需要手动对代码进行 merge&lt;/p&gt;
&lt;h3&gt;拉取目标用户分支&lt;/h3&gt;
&lt;p&gt;比如有这样的一个 PR &lt;a href=&quot;https://github.com/SigureMo/bilili/pull/89&quot;&gt;https://github.com/SigureMo/bilili/pull/89&lt;/a&gt; ，它是由用户 @vx13 创建的，为了能够在 GitHub 直接进行后续 Review 等操作，我们需要直接对该用户的该分支进行修改&lt;/p&gt;
&lt;p&gt;为了实现这一点，我们可以这样做&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git remote add vx13 https://github.com/vx13/bilili.git
git fetch vx13
git checkout -b feature-with-section vx13/feature-with-section
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样就将该用户的 PR 分支保存到 &lt;code&gt;feature-with-section&lt;/code&gt; 分支了，之后进行各种修改后 push 即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git push vx16 HEAD:feature-with-section
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;值得注意的是，这需要该用户在提交 PR 时勾选 &lt;code&gt;Allow edits from maintainers&lt;/code&gt;，该选项默认是勾选的，当然也不排除该用户取消勾选的可能&lt;/p&gt;
&lt;h3&gt;在 GitHub 交互式合并&lt;/h3&gt;
&lt;p&gt;GitHub 可以轻松对代码进行 Review，在整个 PR 完成之后，我们可以直接点击绿色的合并按钮右侧的下拉菜单，选择 &lt;code&gt;Squash and merge&lt;/code&gt; 来对整个 PR 进行合并，这样就可以将多个 commit 合并成一条 &lt;code&gt;main&lt;/code&gt; 分支的 commit 了，保证了主线清爽的线性结构，也保证了主线的一个 commit 对应一个完整的功能（一次 PR）&lt;/p&gt;
&lt;h2&gt;团队协作模式&lt;/h2&gt;
&lt;p&gt;团队协作应当不止建立 &lt;code&gt;main&lt;/code&gt; 与 &lt;code&gt;dev&lt;/code&gt;，抛开额外的功能分支，每个人都应当从 &lt;code&gt;dev&lt;/code&gt; 建立自己的分支&lt;/p&gt;
&lt;p&gt;&lt;code&gt;main&lt;/code&gt; 应当是一个相当稳定的分支，只有在 &lt;code&gt;dev&lt;/code&gt; 新功能基本稳定后，才合并回 &lt;code&gt;main&lt;/code&gt; 发版，团队各成员平时只允许向 &lt;code&gt;dev&lt;/code&gt; merge&lt;/p&gt;
&lt;h3&gt;建立你自己的分支&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git checkout dev
git checkout -b feature-xxx     # 新建一个你自己的分支
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;完成你的工作，并发起 PR&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;git commit
git push origin feature-xxx
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;之后在 GitHub 上向 &lt;code&gt;dev&lt;/code&gt; 发起 PR 即可&lt;/p&gt;
&lt;h3&gt;同步更改&lt;/h3&gt;
&lt;p&gt;由于你的 &lt;code&gt;main&lt;/code&gt; 与 &lt;code&gt;dev&lt;/code&gt; 都是相当干净（自己没做过改动）的，你可以和前面一样 &lt;code&gt;fetch&lt;/code&gt; 并 &lt;code&gt;merge&lt;/code&gt; 即可&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/ldy-blogs/p/10529946.html#4416607&quot;&gt;Git 常用命令和 Git Flow 梳理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/684a8ae9dcf1&quot;&gt;git merge squash 和 rebase 区别&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://liuyib.github.io/2020/09/19/add-commits-to-others-pr&quot;&gt;优雅地修改他人贡献的 Pull Request&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>用可爱的插件装饰你的 VuePress~</title><link>https://nyakku.moe/posts/moefy-your-vuepress-blog/</link><guid isPermaLink="true">https://nyakku.moe/posts/moefy-your-vuepress-blog/</guid><pubDate>Mon, 21 Oct 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;早在一年多以前我就喜欢上了 &lt;code&gt;hexo-theme-sagiri&lt;/code&gt; 这个主题（效果可以参见 &lt;a href=&quot;https://diygod.me/&quot;&gt;diygod.me&lt;/a&gt;），不过当时还什么都不懂啦，不会用 GitHub ，更不知道这居然是静态博客做出来的效果（如果当时知道那么简单的话，我也许现在用的就是 hexo 了 :joy:）&lt;/p&gt;
&lt;p&gt;前些日子因为机缘巧合发现了 &lt;code&gt;sagiri&lt;/code&gt; 中的彩带背景的开源实现，原来其出自若干年前 Evan 的个人主页背景，之后我试着简单阅读 &lt;code&gt;vuepress-plugin-nest&lt;/code&gt; 插件源码，照喵画虎地摹了个 &lt;code&gt;vuepress-plugin-ribbon&lt;/code&gt; 插件，居然真的成功了！这使我萌生了把 &lt;code&gt;sagiri&lt;/code&gt; 中一些小组件作为 VuePress 插件实现的想法，之后的几天……&lt;/p&gt;
&lt;p&gt;废话说太多了，还是说说怎么用吧 :joy:&lt;/p&gt;
&lt;p&gt;:warning: 本文章仅针对 VuePress V1，对于 VuePress V2 及 VitePress 没有太多参考意义&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;在背景添加一条彩带&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/moefyit/vuepress-plugin-ribbon&quot;&gt;vuepress-plugin-ribbon&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;只需要简单的配置就可以在你的 VuePress 中添加一条背景彩带~&lt;/p&gt;
&lt;p&gt;首先使用 yarn 安装~&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yarn add vuepress-plugin-ribbon -D
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后在 &lt;code&gt;config.js&lt;/code&gt; 中添加以下配置~&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = {
   plugins: [
      [
         &apos;ribbon&apos;,
         {
            size: 90, // 彩带的宽度，默认为 90
            opacity: 0.8, // 彩带的不透明度，默认为 0.3
            zIndex: -1, // 彩带的 z-index 属性，默认值为 -1
         },
      ],
   ],
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后再次 &lt;code&gt;dev&lt;/code&gt; 你就可以发现你的背景多一条彩带啦~&lt;/p&gt;
&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;如果你的彩带会把博客文字覆盖掉，请先尝试调整 &lt;code&gt;z-index&lt;/code&gt; 属性，如果无论如何调整都不能有合适的效果，请使用 CSS 为你的主题添加样式覆盖，最简单的方法就是为不想显示彩带的位置添加背景，因为博客主题样式大多不一致，这里就不贴具体修改方式了&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;h2&gt;添加一个动态的标题&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/moefyit/vuepress-plugin-dynamic-title&quot;&gt;vuepress-plugin-dynamic-title&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果你现在使用的是 PC 端的话，试着切换浏览器到其它标签页~&lt;/p&gt;
&lt;p&gt;唔，欢迎回来，你应该已经看到效果了~这就是 &lt;code&gt;dynamic-title&lt;/code&gt; 的效果~&lt;/p&gt;
&lt;p&gt;想要把它装到你的 VuePress 的话，就 yarn 一下吧~&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yarn add vuepress-plugin-dynamic-title -D
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;配置稍微有点麻烦，需要提供图标以及相应的文字，不提供时默认是不显示图标的，图标放在 &lt;code&gt;.vuepress/public/&lt;/code&gt; 下就好&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = {
   plugins: [
      [
         &apos;dynamic-title&apos;,
         {
            showIcon: &apos;/favicon.ico&apos;,
            showText: &apos;(/≧▽≦/)咦！又好了！&apos;,
            hideIcon: &apos;/failure.ico&apos;,
            hideText: &apos;(●—●)喔哟，崩溃啦！&apos;,
            recoverTime: 2000,
         },
      ],
   ],
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;增加鼠标点击动效&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/moefyit/vuepress-plugin-cursor-effects&quot;&gt;vuepress-plugin-cursor-effects&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;只需要简单的安装就可以在你的 VuePress 添加鼠标点击后散落彩色粒子的效果~&lt;/p&gt;
&lt;p&gt;插件名是 &lt;code&gt;vuepress-plugin-cursor-effects&lt;/code&gt;，安装方法应该不用说了吧，配置也很简单，按照下面配置就好&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = {
   plugins: [
      [
         &apos;cursor-effects&apos;,
         {
            size: 2, // 粒子大小
            shape: &apos;star&apos;, // 粒子形状（可选 &apos;star&apos; 和 &apos;circle&apos;）
            zIndex: 999999999,
         },
      ],
   ],
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;修改你的鼠标为更可爱的样式&lt;/h2&gt;
&lt;p&gt;这个就不用插件实现了，自己配置下 &lt;code&gt;style/index.styl&lt;/code&gt; 就可以了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;body {
  cursor: url(&apos;/cursor.ico&apos;), auto;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;找一个你喜欢的鼠标指针放在 &lt;code&gt;public&lt;/code&gt; 下就好，当然图片名也记得修改&lt;/p&gt;
&lt;h2&gt;使用悬挂喵作为返回顶部按钮&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/moefyit/vuepress-plugin-go-top&quot;&gt;vuepress-plugin-go-top&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;相信你看到这个位置应该已经能看到它啦，点一下就可以返回顶部哦~&lt;/p&gt;
&lt;p&gt;安装方法就不必说了，由于没什么配置项，直接像下面这样就行&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = {
   plugins: [&apos;go-top&apos;],
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;值得注意的是，由于猫猫在窄屏设备上很容易遮挡内容，因此设计了两个响应式变化点，当屏幕变窄时会依次显示“猫猫” -&amp;gt; 显示“猫爪爪” -&amp;gt; 不显示，具体的响应式变化点你可以在 &lt;code&gt;.vuepress/styles/palette.styl&lt;/code&gt; 中自行修改&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// 显示猫猫
$MQWide ?= 1440px
// 显示猫爪爪
$MQMobile ?= 768px
// 啥都不显示
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;添加一个萌萌哒看板娘&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/yanjun0501/vuepress-plugin-live2d&quot;&gt;vuepress-plugin-live2d&lt;/a&gt; &lt;a href=&quot;https://github.com/yanjun0501/vuepress-plugin-live2d&quot;&gt;Author 聆歌&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;plugins: [
   [
      &apos;vuepress-plugin-live2d&apos;,
      {
         modelName: &apos;&apos;, // 模型名称，可传入一个字符串或者数组
         mobileShow: false, // 是否在移动设备上显示
         position: &apos;right&apos;, // 显示在左下角还是右下角
      },
   ],
]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;配置详情请在&lt;a href=&quot;https://github.com/yanjun0501/vuepress-plugin-live2d&quot;&gt;项目主页&lt;/a&gt;查看&lt;/p&gt;
&lt;p&gt;感谢聆歌提供本插件，感觉效果不错的可以给他一个 Star 哟~&lt;/p&gt;
&lt;h2&gt;添加一个漂亮的音乐播放器&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/moefyit/vuepress-plugin-meting&quot;&gt;vuepress-plugin-meting&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个插件是利用 Meting 接口来获取音乐资源，传入 Vue-APlayer，解决 APlayer 的音源问题，当然如果你有合适的音源也可以直接用 Vue-APlayer 哒~&lt;/p&gt;
&lt;p&gt;如果你想添加一个全局的吸底播放器，直接在 &lt;code&gt;config.js&lt;/code&gt; 中配置即可&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;module.exports = {
   plugins: [
      &apos;meting&apos;,
      {
         meting: {
            server: &apos;netease&apos;, // 音乐源
            type: &apos;playlist&apos;, // 资源类型
            mid: &apos;2539599584&apos;, // 资源 id
         },
         aplayer: {
            lrcType: 3,
         },
      },
   ],
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;另外，它也支持在任何页面单独引入播放器，当然你需要首先在 &lt;code&gt;config.js&lt;/code&gt; 启用它（但不必填写配置项，配置项只与全局吸底播放器有关，不配置便不会出现该播放器）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;!-- my-music.md --&amp;gt;

&amp;lt;Meting server=&quot;netease&quot;
        type=&quot;playlist&quot;
        mid=&quot;2539599584&quot;
        :lrc-type=&quot;3&quot;/&amp;gt;

&amp;lt;!-- 这样就可以在 my-music.html 页面单独引入一个播放器咯～ --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;最后&lt;/h2&gt;
&lt;p&gt;再次感谢 &lt;a href=&quot;https://github.com/DIYgod&quot;&gt;DIYGod&lt;/a&gt;~&lt;/p&gt;
</content:encoded></item><item><title>初识图卷积神经网络（GCN）</title><link>https://nyakku.moe/posts/hello-gcn/</link><guid isPermaLink="true">https://nyakku.moe/posts/hello-gcn/</guid><pubDate>Fri, 16 Aug 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip
随着深度学习的快速发展，传统神经网络结构的弊端也日益凸显，无论是 $CNN$ 还是 $RNN$ ，处理的数据仅限于欧式空间，而对于拓扑结构的数据就手足无措了，然而我们我们生活的世界更多的数据还是拓扑结构数据，至于表示拓扑结构的最好方法，非图莫属了，那么如何利用图的结构进行学习呢，下面让我们一探 $GCN$ 的究竟
:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预备知识
&lt;ul&gt;
&lt;li&gt;传统 $NN$ 的连接结构&lt;/li&gt;
&lt;li&gt;$CNN$ 基本卷积方式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;开发环境
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;python 3.6&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;格式使用 &lt;code&gt;Jupyter Notebook&lt;/code&gt; ，&lt;code&gt;Out&lt;/code&gt; 部分放于块尾注释中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;:::tip
本文不深究公式细节，主要是为了更轻松地从传统神经网络过渡到 $GCN$ ，主要代码及结构参考 &lt;a href=&quot;#reference&quot;&gt;Ref1&lt;/a&gt; ，文字部分主要为自己的理解，如果有不当之处，还请指正
:::&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import numpy as np
import networkx
from matplotlib import pyplot as plt

def ReLU(x):
    return (abs(x) + x) / 2
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;GCN 的输入&lt;/h2&gt;
&lt;p&gt;与传统网络不同的是，$GCN$ 的输入并不只是特征，它额外包含了图中各个结点之间的关系，那么关系用什么表征呢？显而易见，邻接矩阵是一个非常简单易行的表示方法，这里&lt;strong&gt;使用邻接矩阵 $A$ 来表示各个顶点之间的关系&lt;/strong&gt;，显然 $A.shape = (N, N)$&lt;/p&gt;
&lt;p&gt;相应地，各个顶点的特征使用矩阵组织起来就好啦，这里使用 $X$ 表示输入层特征矩阵， $H^i$ 表示第 $i$ 隐藏层特征矩阵，当然 $X = H^0$ ，显然 $H^i.shape = (N, F^i)$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$F^i$ 表示第 $i$ 层的特征维度，$N$ 表示顶点个数&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;与 CNN 的相似性&lt;/h3&gt;
&lt;p&gt;我们知道，普通 $CNN$ 的卷积是同时对空间与通道进行卷积，而 $Xception$ 和 $MobileNet$ 所使用的深度可分离卷积是对空间卷积与通道的全连接进行的分离，而且深度可分离卷积确实比普通卷积有着更少的参数，在等量参数下，深度可分离卷积有着更好的效果&lt;/p&gt;
&lt;p&gt;深度可分离卷积将一个卷积层分成两个子层，第一步是对每个通道进行空间上的卷积，各个通道独立操作，第二步是对通道进行线性组合，也就是传统神经网络所做的事，那么对于一个图数据，是否也可以这样做呢？&lt;/p&gt;
&lt;p&gt;假如一张图也是可以卷积的，那么我们首先对它进行卷积，之后对特征进行全连接，这便是 $GCN$ 的基本结构了&lt;/p&gt;
&lt;p&gt;相应的，特征的维度便是传统网络的某一层结点单元数，特征维度的变换便是各层结点之间的全连接，当然这也说明了为何 $W^i.shape = (F^i, F^{i+1})$ ，当然，$W^i$ 的所有参数都用在了两层之间全连接上了，图卷积并无参数（区别于 $CNN$ 卷积核需要参数）&lt;/p&gt;
&lt;h2&gt;图卷积网络层的构建&lt;/h2&gt;
&lt;p&gt;首先考虑一种非常非常简单的传播方式&lt;/p&gt;
&lt;p&gt;$$
H^{i+1} = g(A H^i W^i)
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$g$ 为激活函数，$W^i$ 为第 $i$ 层的参数，$W^i.shape = (F^i, F^{i+1})$，另外值得注意的是，这里的乘法均为矩阵乘法，仅仅看 $shape$ 便可以知道这种变幻的合理性了， $(N, N) \cdot (N, F^i) \cdot (F^i, F^{i+1}) = (N, F^{i+1})$ ，但是究竟为什么这样会有效呢？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面考虑一个非常简单的示例，图结构如下($N = 4$)，&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/hello-gcn/gcn-01.drawio.png&quot; alt=&quot;GCN_01&quot; /&gt;&lt;/p&gt;
&lt;p&gt;首先写出邻接矩阵 $A$ ($shape=(4, 4)$)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A = np.matrix([
        [0, 1, 0, 0],
        [0, 0, 1, 1],
        [0, 1, 0, 0],
        [1, 0, 1, 0]
    ],dtype=np.float64
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;然后写出表示输入特征的 $X$ ($shape=(4, 2)$) （这里输入特征维度为 $2$）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;X = np.matrix([
        [i, -i] for i in range(A.shape[0])
    ], dtype=np.float64)
X
# matrix([[ 0.,  0.],
#         [ 1., -1.],
#         [ 2., -2.],
#         [ 3., -3.]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;应用图卷积&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A * X
# matrix([[ 1., -1.],
#         [ 5., -5.],
#         [ 1., -1.],
#         [ 2., -2.]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们可以发现，原始特征在经过第一步图卷积之后在图上发生了传播，比如顶点 1 ，聚合了邻居 2 和 3 的特征&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果存在从 $u$ 到 $v$ 的边，则 $v$ 是 $u$ 的邻居，也即有向图沿着箭头的反方向传播，无向图沿着边传播&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;但是这样就会产生两个问题&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;首先，每个顶点特征在传播后自身的信息会丢失，为了避免这一问题，可以通过&lt;strong&gt;在图上增加自环&lt;/strong&gt;来解决，具体方法就是在 $A$ 的基础上增加单位矩阵 $I$ ，得到的修正结果为 $\hat{A}$&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;I = np.matrix(np.eye(A.shape[0]))
(A + I) * X
# matrix([[ 1., -1.],
#         [ 6., -6.],
#         [ 3., -3.],
#         [ 5., -5.]])
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另外还有一个问题就是，各个特征在聚合的过程中传播的次数取决于顶点度的大小，度大的顶点会使得特征的在整体表征所占权重更大，这可能会引发梯度消失或梯度爆炸，一种简单的想法就是&lt;strong&gt;对度进行归一化&lt;/strong&gt;，至于归一化的方法，可以使用 $D^{-1} A$ ，论文中使用 $D^{-\frac{1}{2}} A D^{-\frac{1}{2}}$，道理都一样，本文暂时不涉及后者&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;$D$ 为矩阵 $A$ 的度矩阵&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先写出获取一个矩阵的度矩阵的函数，并求得矩阵 $A$ 的度矩阵 $D$&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def get_degree_matrix(A):
   D = np.array(np.sum(A, axis=0))[0]
   D = np.matrix(np.diag(D))
   return D
D = get_degree_matrix(A)
D
# matrix([[1., 0., 0., 0.],
#         [0., 2., 0., 0.],
#         [0., 0., 2., 0.],
#         [0., 0., 0., 1.]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面求出归一化的邻接矩阵&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D**-1 * A
# matrix([[ 0. , 1. , 0. , 0. ],
#         [ 0. , 0. , 0.5, 0.5],
#         [ 0. , 0.5, 0. , 0. ],
#         [ 1. , 0. , 1. , 0. ]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;很明显，邻接矩阵在度大的方向减小了链接权重（除以对应的度）&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;D**-1 * A * X
# matrix([[ 1. , -1. ],
#      [ 2.5, -2.5],
#      [ 0.5, -0.5],
#      [ 2. , -2. ]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;相应地，聚合时传播效果也是归一化的结果&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面，将上述两个问题结合起来，首先求得 $\hat{A}$ ，之后对 $\hat{A}$ 进行归一化，当然，$\hat{D}$ 是 $\hat{A}$ 的度矩阵&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A_hat = A + I
D_hat = get_degree_matrix(A_hat)
D_hat**-1 * A_hat * X
# matrix([[ 0.5, -0.5],
#         [ 2. , -2. ],
#         [ 1. , -1. ],
#         [ 2.5, -2.5]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;至于后面的参数，乘一下就好了，然后加上激活函数便完成一层图卷积网络层了&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;W = np.matrix([
             [1, -1],
             [-1, 1]
         ])
ReLU(D_hat**-1 * A_hat * X * W)
# matrix([[1., 0.],
#         [4., 0.],
#         [2., 0.],
#         [5., 0.]])
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;何谓卷积&lt;/h2&gt;
&lt;p&gt;回顾传统卷积，可以看做是每个卷积核处，不同像素点的特征聚合于卷积核中心处而已&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/hello-gcn/GCN_02.png&quot; alt=&quot;GCN_02&quot; /&gt;&lt;/p&gt;
&lt;p&gt;而图卷积，是沿着图的边，将邻居的特征聚合于自身&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/hello-gcn/GCN_03.png&quot; alt=&quot;GCN_03&quot; /&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本图为无向图，若为有向图，聚合方向沿着箭头的反方向&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然，前者发生在欧式空间，后者是在拓扑结构上，所谓卷积，可以说是相邻结点的一次信息聚合，而信息的聚合，&lt;a href=&quot;https://www.zhihu.com/question/54504471&quot;&gt;Ref3&lt;/a&gt;一文中首先使用了温度场模型的热量传播进行比拟，之后推到图模型，由浅及深地进行了解释&lt;/p&gt;
&lt;p&gt;对于一个连续的模型，$t$ 时刻的结果就是 $f(x, y, z, t)$ ，而一个离散的结构，每一时刻的结果都与前一时刻相关联，每一位置的结果都与周围位置相关联，在求得了前一时刻各位置的结果后，下一时刻任何一个位置都可以求得，每一个位置的结果取决于其相邻结点，具体关系可对原来的连续模型下的公式进行离散化，化微分为差分，便可得到相邻结点传播公式&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;聚合针对某一结点，传播针对整个结构
另外，由于本学期有一门专业课恰好学习并实践温度场模型的有限差分模拟，所以看到这篇文章倍感亲切~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;图卷积的优点&lt;/h2&gt;
&lt;p&gt;图卷积是在传统网络的基础上增加了图的结构，增加的信息当然不是毫无用处，因为图的存在，使用随机初始化的参数便可完成初步的聚类，而且只需要较少的标签便可完成学习，因此 $GCN$ 也被称为是一种&lt;strong&gt;半监督学习&lt;/strong&gt;方式&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;整个图卷积网络层，可以分为两步，第一步是图卷积，第二步是层与层之间的连接&lt;/p&gt;
&lt;p&gt;前者使用邻接矩阵 $A$ ，使得特征沿着图的边进行传播，得到 $A H^i$ ，考虑到自环问题和归一化问题的话，改为 $\hat{D}^{-1} \hat{A} H^i$ 或者 $D^{-\frac{1}{2}} A D^{-\frac{1}{2}} \hat{A} H^i$ 即可&lt;/p&gt;
&lt;p&gt;后者使用链接权重 $W^i$ ，与传统网络并无不同，其 $shape$ 依然为 $(f^{in}, f^{out})$ （这里 $in$ 和 $out$ 用来表示层的输入与输出），之后激活一下就好啦&lt;/p&gt;
&lt;p&gt;总的来说，图卷积不过是在前层特征计算完之后再整张图上传播一下（第一步），之后和传统网络并无区别&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/sg9O761F0KHAmCPOfMW_kQ&quot;&gt;图卷积网络到底怎么做，这是一份极简的 Numpy 实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://mp.weixin.qq.com/s/I3MsVSR0SNIKe-a9WRhGPQ&quot;&gt;何时能懂你的心——图卷积神经网络（GCN）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/54504471&quot;&gt;如何理解 Graph Convolutional Network（GCN）？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/guotong1988/article/details/82628156&quot;&gt;GCN graph convolutional networks 详解&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>Maxout 的简单理解与实现</title><link>https://nyakku.moe/posts/maxout/</link><guid isPermaLink="true">https://nyakku.moe/posts/maxout/</guid><pubDate>Mon, 01 Jul 2019 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip
Maxout 是 Goodfellow 在 2013 年提出的一个新的激活函数，相比于其它的激活函数，Maxout 本身是需要参数的，参数可以通过网络的反向传播得到学习，相应地，它比其它激活函数有着更好的性能，理论上可以拟合任意凸函数，进而使得网络取得更好的性能
:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;预备知识
&lt;ul&gt;
&lt;li&gt;基本全连接与卷积网络连接方式&lt;/li&gt;
&lt;li&gt;&lt;code&gt;TensorFlow V2&lt;/code&gt; 的基本使用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;开发环境
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;python 3.6&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;1 什么是 Maxout&lt;/h2&gt;
&lt;p&gt;Maxout 可以说是一个激活函数，但与其他激活函数所不同的是，它本身是拥有参数的，正因为此，它可以拟合任意的凸函数，那么它是如何实现的呢？&lt;/p&gt;
&lt;p&gt;首先我们弄清一个问题，&lt;strong&gt;卷积层在通道阶上和全连接层并没有任何区别&lt;/strong&gt;，只是额外在图像的两个阶增加了卷积核的稀疏连接，但这往往是很小的（$3 \times 3$ ，$5 \times 5$ 这样），所以说我们只考虑卷积网络的最后一个阶的话，它与全连接并无区别，这里就直接使用全连接网络作为例子，当然，卷积网络也是适用的&lt;/p&gt;
&lt;p&gt;我们网络前层进行 $WX + b$ 的线性变换后，是需要增加激活函数进行非线性变换的，但是具体怎么选择激活函数呢？我们可不可以让网络自己学习这个呢？&lt;/p&gt;
&lt;p&gt;&amp;lt;div class=&quot;img-center&quot;&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/maxout/maxout-01.png&quot; alt=&quot;maxout-01.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;
&lt;p&gt;上图便是最基本的 $Maxout$ 连接示意图，前面与普通的全连接并无区别，之后每两个单元“连接”到一个单元上，当然，这里不是真的连接，因为该条线上并不涉及参数，那么如何从两个单元得到一个单元的值呢？其实只需要比较两个单元的值即可，大的值便可以通过~也便是 $Max\ Out$&lt;/p&gt;
&lt;p&gt;&amp;lt;div class=&quot;img-center&quot;&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/maxout/maxout-02.png&quot; alt=&quot;maxout-02.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;
&lt;p&gt;结果便如上图所示，每两个单元中较大的值会被激活&lt;/p&gt;
&lt;p&gt;&amp;lt;div class=&quot;img-center&quot;&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../../assets/img/maxout/maxout-03.png&quot; alt=&quot;maxout-03.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;&amp;lt;/div&amp;gt;&lt;/p&gt;
&lt;p&gt;我们知道每个单元都是前层特征的线性组合，那么比如上图中第一个单元学习到了 $y = 0$ ，而第二个单元学习到了 $y = x$ ，那么这两个单元学习到的激活函数便是 $ReLU$ 激活函数&lt;/p&gt;
&lt;p&gt;更一般地，我们使每 $k$ （前面的例子 $k = 2$）个单元“连接”到一个单元上，那么 $Maxout$ 可以学习到更多段的分段函数作为激活函数，当 $k$ 足够大时，理论上可以拟合任何凸函数&lt;/p&gt;
&lt;h2&gt;2 如何实现 Maxout&lt;/h2&gt;
&lt;p&gt;一种很直觉的方法就是，我们先将原本的 $m$ 个参数改为 $m \times k$ 个参数，之后每组挑取最大的，但是这样的话，就需要预先用一个矩阵对原先的参数进行线性变换，增加了实现的复杂性&lt;/p&gt;
&lt;p&gt;我们反过来想，如果前一层的输出已经是 $m \times k$ 个参数了呢？很简单。我们 $Maxout$ 只需要分组并每个组选一个最大值就好了嘛~这里参考 TensorFlow1.13 版本的 &lt;code&gt;tf.contrib.layers.maxout&lt;/code&gt; ，使用 TensorFlow V2 的 &lt;code&gt;tf.keras.layers.Layer&lt;/code&gt; API 重写了下&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import tensorflow as tf

class Maxout(tf.keras.layers.Layer):
    def __init__(self, units, axis=None):
        super().__init__()
        self.units = units
        self.axis = axis
        if axis is None:
            self.axis = -1

    def build(self, input_shape):

        self.num_channels = input_shape[self.axis]
        assert self.num_channels % self.units == 0
        self.out_shape = input_shape.as_list()
        self.out_shape[self.axis] = self.units
        self.out_shape += [self.num_channels // self.units]
        for i in range(len(self.out_shape)):
            if self.out_shape[i] is None:
                self.out_shape[i] = -1

    def call(self, inputs):

        x = tf.reduce_max(tf.reshape(inputs, self.out_shape), axis=-1)
        return x

# x.shape = (..., d)
x = tf.keras.layers.Conv2d(k * m, kernel_size, strides, padding)(x)
# x.shape = (..., m*k)
x = Maxout(num_units=m)(x)
# x.shape = (..., m)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这种实现方式可以让我们像加一个激活函数一样把 $Maxout$ 加到网络中，但是值得注意的是，这样的 $Maxout$ 实现会将 $m \times k$ 个单元减少为 $m$ 个&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://tensorflow.google.cn/api_docs/python/tf/contrib/layers/maxout?hl=en&quot;&gt;TensorFlow 文档 Maxout&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1302.4389&quot;&gt;Paper: Maxout Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.jianshu.com/p/710fd5d6d640&quot;&gt;Maxout 激活函数原理及实现&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item><item><title>Git 提交信息规范</title><link>https://nyakku.moe/posts/git-commit-message-convention/</link><guid isPermaLink="true">https://nyakku.moe/posts/git-commit-message-convention/</guid><pubDate>Sun, 16 Sep 2018 00:00:00 GMT</pubDate><content:encoded>&lt;p&gt;:::tip&lt;/p&gt;
&lt;p&gt;Git Commit Message 虽然可以随意描述，但使用没有意义的描述对于后续 review 代码以及理解代码用途等方面都会造成巨大的影响。因此 Commit Message 具有意义是最基本的要求，此外，你还应该遵守一定的格式规范，这样能够让大家更快更清晰地了解该 Commit 的详情。这里我主要介绍下常规的 Git Commit 规范和 Gitmoji 规范，最后介绍下我常用的相关配置。&lt;/p&gt;
&lt;p&gt;:::&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- more --&amp;gt;&lt;/p&gt;
&lt;h2&gt;常规 Commit Message 规范&lt;/h2&gt;
&lt;p&gt;一个 Commit Message 最基本的组成为： &lt;code&gt;header&lt;/code&gt;、&lt;code&gt;body&lt;/code&gt;、&lt;code&gt;footer&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;书写起来就是下面这样&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;type&amp;gt;(&amp;lt;scope&amp;gt;): &amp;lt;subject&amp;gt;
&amp;lt;BLANK LINE&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;BLANK LINE&amp;gt;
&amp;lt;footer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当然 &lt;code&gt;header&lt;/code&gt; 就是第一行的内容，它包含了 &lt;code&gt;type&lt;/code&gt;、&lt;code&gt;scope&lt;/code&gt; 和 &lt;code&gt;subject&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;Header&lt;/h3&gt;
&lt;h4&gt;type&lt;/h4&gt;
&lt;p&gt;根据 &lt;a href=&quot;https://github.com/commitizen/conventional-commit-types&quot;&gt;conventional-commit-types&lt;/a&gt;, &lt;code&gt;type&lt;/code&gt; 的可选值一般来说是有下面几种，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;feat: 添加新功能&lt;/li&gt;
&lt;li&gt;fix: 修复 bug&lt;/li&gt;
&lt;li&gt;docs: 仅对文档进行修改&lt;/li&gt;
&lt;li&gt;style: 对代码语义无影响的格式修改（如去除无用空格、格式化等等修改）&lt;/li&gt;
&lt;li&gt;refactor: 代码重构（既不是新增功能，也不是修改 bug 的代码变动）&lt;/li&gt;
&lt;li&gt;perf: 提高性能的代码修改&lt;/li&gt;
&lt;li&gt;test: 测试用例添加及修改&lt;/li&gt;
&lt;li&gt;build: 影响构建系统或外部依赖关系的更改&lt;/li&gt;
&lt;li&gt;ci: 更改 CI 配置文件和脚本&lt;/li&gt;
&lt;li&gt;chore: 其它不涉及源码以及测试的修改&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;scope&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;scope&lt;/code&gt; 用于说明 commit 影响的范围，如果你的修改影响了不止一个 scope ，你可以使用 &lt;code&gt;*&lt;/code&gt; 代替，该字段一般可以省略&lt;/p&gt;
&lt;h4&gt;subject&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;subject&lt;/code&gt; 是 commit 目的的简短描述，不超过 50 个字符&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;以动词开头，使用第一人称现在时，比如 change，而不是 changed 或 changes&lt;/li&gt;
&lt;li&gt;第一个字母小写&lt;/li&gt;
&lt;li&gt;结尾不加句号（.）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Body&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Body&lt;/code&gt; 是详细描述，在这里可以详细介绍该次改动的具体修改内容&lt;/p&gt;
&lt;h3&gt;Footer&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Footer&lt;/code&gt; 一般只包含以下两种情况&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不兼容变动（BREAKING CHANGE）&lt;/li&gt;
&lt;li&gt;关闭 Issue 如 &lt;code&gt;Closes #234&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Revert&lt;/h3&gt;
&lt;p&gt;此外，当你使用 &lt;code&gt;git revert&lt;/code&gt; 撤销之前的某次 commit 时，该次的 Commit Message 应当以 &lt;code&gt;revert&lt;/code&gt; 开头，后面跟着被撤销 Commit 的 Header ，如&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;revert: feat(pencil): add &apos;graphiteWidth&apos; option

This reverts commit 667ecc1654a317a13331b17617d973392f415f02.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Gitmoji 规范&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://gitmoji.carloscuesta.me/&quot;&gt;Gitmoji&lt;/a&gt; 规范允许你在 Commit Message 中使用 &lt;a href=&quot;https://emojipedia.org/&quot;&gt;Emoji&lt;/a&gt;，简单的说，你可以用生动形象的 Emoji 来表示该次 Commit 的 type，Gitmoji 推荐的 &lt;code&gt;header&lt;/code&gt; 格式是&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;gitmoji&amp;gt;: &amp;lt;subject&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里的 subject 首字母仍是大写字母，其它倒与常规的规范没什么区别，&lt;code&gt;gitmoji&lt;/code&gt; 的具体选值如下&lt;/p&gt;
&lt;p&gt;&amp;lt;!-- prettier-ignore --&amp;gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;view&lt;/th&gt;
&lt;th&gt;code&lt;/th&gt;
&lt;th&gt;mean&lt;/th&gt;
&lt;th&gt;translate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;:art:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:art:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Improve structure / format of the code.&lt;/td&gt;
&lt;td&gt;改良结构和代码格式&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:zap:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:zap:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Improve performance.&lt;/td&gt;
&lt;td&gt;优化性能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:fire:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:fire:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Remove code or files.&lt;/td&gt;
&lt;td&gt;移除代码或文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:bug:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:bug:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fix a bug.&lt;/td&gt;
&lt;td&gt;修复 bug&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:ambulance:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:ambulance:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Critical hotfix.&lt;/td&gt;
&lt;td&gt;紧急的热修复&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:sparkles:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:sparkles:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Introduce new features.&lt;/td&gt;
&lt;td&gt;引入新功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:memo:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:memo:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update documentation.&lt;/td&gt;
&lt;td&gt;添加或更新文档&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:rocket:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:rocket:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deploy stuff.&lt;/td&gt;
&lt;td&gt;部署&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:lipstick:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:lipstick:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update the UI and style files.&lt;/td&gt;
&lt;td&gt;添加或更新 UI 和样式文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:tada:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:tada:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Begin a project.&lt;/td&gt;
&lt;td&gt;开始一个全新的项目～&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:white_check_mark:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:white_check_mark:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update tests.&lt;/td&gt;
&lt;td&gt;添加或更新测试用例&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:lock:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:lock:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fix security issues.&lt;/td&gt;
&lt;td&gt;修复安全问题&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:bookmark:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:bookmark:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Release / Version tags.&lt;/td&gt;
&lt;td&gt;发版 / 版本标签&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:rotating_light:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:rotating_light:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fix compiler / linter warnings.&lt;/td&gt;
&lt;td&gt;修复编译器或者 linter 的 warning&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:construction:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:construction:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Work in progress.&lt;/td&gt;
&lt;td&gt;工作在进行中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:green_heart:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:green_heart:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fix CI Build.&lt;/td&gt;
&lt;td&gt;修复 CI 构建问题&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:arrow_down:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:arrow_down:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Downgrade dependencies.&lt;/td&gt;
&lt;td&gt;降级依赖库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:arrow_up:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:arrow_up:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Upgrade dependencies.&lt;/td&gt;
&lt;td&gt;升级依赖库&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:pushpin:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:pushpin:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Pin dependencies to specific versions.&lt;/td&gt;
&lt;td&gt;将依赖库固定到特定版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:construction_worker:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:construction_worker:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update CI build system.&lt;/td&gt;
&lt;td&gt;添加或更新 CI 构建系统&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:chart_with_upwards_trend:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:chart_with_upwards_trend:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update analytics or track code.&lt;/td&gt;
&lt;td&gt;添加或更新分析或跟踪代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:recycle:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:recycle:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Refactor code.&lt;/td&gt;
&lt;td&gt;重构代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:heavy_plus_sign:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:heavy_plus_sign:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add a dependency.&lt;/td&gt;
&lt;td&gt;添加一个依赖项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:heavy_minus_sign:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:heavy_minus_sign:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Remove a dependency.&lt;/td&gt;
&lt;td&gt;删除一个依赖项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:wrench:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:wrench:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update configuration files.&lt;/td&gt;
&lt;td&gt;添加或改变配置文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:hammer:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:hammer:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update development scripts.&lt;/td&gt;
&lt;td&gt;添加或更新构开发脚本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:globe_with_meridians:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:globe_with_meridians:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Internationalization and localization.&lt;/td&gt;
&lt;td&gt;国际化和本地化（i18n）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:pencil2:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:pencil2:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Fix typos.&lt;/td&gt;
&lt;td&gt;修复拼写错误&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:poop:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:poop:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Write bad code that needs to be improved.&lt;/td&gt;
&lt;td&gt;当前代码尚需优化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:rewind:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:rewind:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Revert changes.&lt;/td&gt;
&lt;td&gt;撤销之前的修改&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:twisted_rightwards_arrows:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:twisted_rightwards_arrows:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Merge branches.&lt;/td&gt;
&lt;td&gt;合并分支&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:package:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:package:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update compiled files or packages.&lt;/td&gt;
&lt;td&gt;添加或更新编译的文件或包&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:alien:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:alien:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Update code due to external API changes.&lt;/td&gt;
&lt;td&gt;由于外部 API 更改而更新代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:truck:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:truck:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Move or rename resources (e.g.: files, paths, routes).&lt;/td&gt;
&lt;td&gt;移动或重命名资源（诸如：文件、路径、路由）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:page_facing_up:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:page_facing_up:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update license.&lt;/td&gt;
&lt;td&gt;添加或更新 LICENSE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:boom:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:boom:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Introduce breaking changes.&lt;/td&gt;
&lt;td&gt;引入不兼容的变动&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:bento:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:bento:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update assets.&lt;/td&gt;
&lt;td&gt;添加或更新静态资源&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:wheelchair:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:wheelchair:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Improve accessibility.&lt;/td&gt;
&lt;td&gt;提高可访问性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:bulb:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:bulb:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update comments in source code.&lt;/td&gt;
&lt;td&gt;在源代码中添加或更新注释&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:beers:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:beers:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Write code drunkenly.&lt;/td&gt;
&lt;td&gt;醉醺醺地编写代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:speech_balloon:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:speech_balloon:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update text and literals.&lt;/td&gt;
&lt;td&gt;添加或更新用于文本、对话框等文本字面量相关的更改&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:card_file_box:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:card_file_box:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Perform database related changes.&lt;/td&gt;
&lt;td&gt;执行与数据库相关的更改&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:loud_sound:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:loud_sound:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update logs.&lt;/td&gt;
&lt;td&gt;添加或更新日志&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:mute:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:mute:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Remove logs.&lt;/td&gt;
&lt;td&gt;删除日志&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:busts_in_silhouette:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:busts_in_silhouette:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update contributor(s).&lt;/td&gt;
&lt;td&gt;添加或更新贡献者&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:children_crossing:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:children_crossing:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Improve user experience / usability.&lt;/td&gt;
&lt;td&gt;改善用户体验/可用性&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:building_construction:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:building_construction:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Make architectural changes.&lt;/td&gt;
&lt;td&gt;改变架构&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:iphone:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:iphone:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Work on responsive design.&lt;/td&gt;
&lt;td&gt;进行响应式设计&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:clown_face:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:clown_face:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Mock things.&lt;/td&gt;
&lt;td&gt;添加或更改 mock&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:egg:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:egg:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update an easter egg.&lt;/td&gt;
&lt;td&gt;添加或更新彩蛋内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:see_no_evil:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:see_no_evil:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update a .gitignore file.&lt;/td&gt;
&lt;td&gt;添加或更新 .gitignore 文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:camera_flash:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:camera_flash:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or updatesnapshots.&lt;/td&gt;
&lt;td&gt;添加或更新快照&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:alembic:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:alembic:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Perform experiments.&lt;/td&gt;
&lt;td&gt;实验性内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:mag:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:mag:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Improve SEO.&lt;/td&gt;
&lt;td&gt;提高 SEO&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:label:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:label:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update types.&lt;/td&gt;
&lt;td&gt;添加或更新类型声明&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:seedling:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:seedling:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update seed files.&lt;/td&gt;
&lt;td&gt;添加或更新种子文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:triangular_flag_on_post:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:triangular_flag_on_post:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add, update, or remove feature flags.&lt;/td&gt;
&lt;td&gt;添加、更新或删除功能标志&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:goal_net:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:goal_net:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Catch errors.&lt;/td&gt;
&lt;td&gt;捕获错误&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:dizzy:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:dizzy:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update animations and transitions.&lt;/td&gt;
&lt;td&gt;添加或更新动画和过渡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:wastebasket:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:wastebasket:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Deprecate code that needs to be cleaned up.&lt;/td&gt;
&lt;td&gt;清理冗余代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:passport_control:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:passport_control:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Work on code related to authorization, roles and permissions.&lt;/td&gt;
&lt;td&gt;处理与授权、账户和权限相关的代码   ｜&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🩹 &amp;lt;!-- :adhesive_bandage: (need markdown-it-emoji 2.0)--&amp;gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:adhesive_bandage:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Simple fix for a non-critical issue.&lt;/td&gt;
&lt;td&gt;简单修复一个非关键问题&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🧐 &amp;lt;!-- :monocle_face: (need markdown-it-emoji 2.0)--&amp;gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:monocle_face:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Data exploration/inspection.&lt;/td&gt;
&lt;td&gt;数据探索/检查&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:coffin:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:coffin:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Remove dead code.&lt;/td&gt;
&lt;td&gt;清除无效代码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🧪 &amp;lt;!-- :test_tube: --&amp;gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:test_tube:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add a failing test.&lt;/td&gt;
&lt;td&gt;添加一个运行失败的测试用例（TDD 第一步）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;:necktie:&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:necktie:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update business logic.&lt;/td&gt;
&lt;td&gt;添加或更新业务逻辑&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🩺&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:stethoscope:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update healthcheck.&lt;/td&gt;
&lt;td&gt;添加或更新健康检查&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🧱&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:bricks:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Infrastructure related changes.&lt;/td&gt;
&lt;td&gt;基础设施相关改动&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🧑‍💻&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:technologist:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Improve developer experience.&lt;/td&gt;
&lt;td&gt;提升开发体验&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🔐&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:closed_lock_with_key:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update secrets.&lt;/td&gt;
&lt;td&gt;添加或更新加密内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;💸&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:money_with_wings:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add sponsorships or money related infrastructure.&lt;/td&gt;
&lt;td&gt;添加赞助商或者资金支持相关内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;🧵&lt;/td&gt;
&lt;td&gt;&lt;code&gt;:thread:&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;Add or update code related to multithreading or concurrency.&lt;/td&gt;
&lt;td&gt;添加或更新多线程或与并发相关的代码&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;在提交时你可以按照喜好使用其 code 或者直接使用 emoji，因为 GitHub 是能够正确将这些 code 渲染为对应的 emoji 的。&lt;/p&gt;
&lt;p&gt;由于 &lt;code&gt;gitmoji&lt;/code&gt; 有着丰富的类型，因此其可以表达的信息会更多一些，这使得你能在 &lt;code&gt;&amp;lt;subject&amp;gt;&lt;/code&gt; 中省去一些内容。但相对的，由于类型实在太多，记忆起来也是相当地麻烦，起初我基本每次提交都来查一下表格，所以如果你使用的是 VS Code，建议使用 &lt;a href=&quot;https://github.com/vtrois/gitmoji-vscode&quot;&gt;gitmoji-vscode&lt;/a&gt; 插件以简化这一过程。&lt;/p&gt;
&lt;h2&gt;我自己常用的规范&lt;/h2&gt;
&lt;p&gt;虽然 gitmoji 很可爱，但总觉得与常规兼容性太差，因此我平时使用的规范是常规规范前面加上一个 &lt;code&gt;gitmoji&lt;/code&gt;，也就是&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;gitmoji&amp;gt; &amp;lt;type&amp;gt;(&amp;lt;scope&amp;gt;): &amp;lt;subject&amp;gt;
&amp;lt;BLANK LINE&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;BLANK LINE&amp;gt;
&amp;lt;footer&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在 &lt;code&gt;scope&lt;/code&gt; 不太重要的情况，我一般都把 &lt;code&gt;scope&lt;/code&gt; 省略掉，以免长度过长&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://gitmoji.dev/&quot;&gt;gitmoji&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/carloscuesta/gitmoji/commits/master/src/data/gitmojis.json&quot;&gt;gitmoji 改动追踪&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://segmentfault.com/a/1190000009048911?utm_source=tag-newest&quot;&gt;git commit 规范指南&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content:encoded></item></channel></rss>